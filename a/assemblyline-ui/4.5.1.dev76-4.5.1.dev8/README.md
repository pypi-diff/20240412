# Comparing `tmp/assemblyline_ui-4.5.1.dev76-py3-none-any.whl.zip` & `tmp/assemblyline_ui-4.5.1.dev8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,79 +1,76 @@
-Zip file size: 175533 bytes, number of entries: 77
--rw-r--r--  2.0 unx       12 b- defN 24-Apr-11 13:59 assemblyline_ui/VERSION
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 13:59 assemblyline_ui/__init__.py
--rw-r--r--  2.0 unx     6736 b- defN 24-Apr-11 13:59 assemblyline_ui/app.py
--rw-r--r--  2.0 unx     5957 b- defN 24-Apr-11 13:59 assemblyline_ui/config.py
--rw-r--r--  2.0 unx     3690 b- defN 24-Apr-11 13:59 assemblyline_ui/error.py
--rw-r--r--  2.0 unx      740 b- defN 24-Apr-11 13:59 assemblyline_ui/gunicorn_config.py
--rw-r--r--  2.0 unx      115 b- defN 24-Apr-11 13:59 assemblyline_ui/gunicorn_config_socketio.py
--rw-r--r--  2.0 unx      777 b- defN 24-Apr-11 13:59 assemblyline_ui/healthz.py
--rw-r--r--  2.0 unx      199 b- defN 24-Apr-11 13:59 assemblyline_ui/http_exceptions.py
--rw-r--r--  2.0 unx     2322 b- defN 24-Apr-11 13:59 assemblyline_ui/logger.py
--rw-r--r--  2.0 unx       85 b- defN 24-Apr-11 13:59 assemblyline_ui/patched.py
--rw-r--r--  2.0 unx     2596 b- defN 24-Apr-11 13:59 assemblyline_ui/socketsrv.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 13:59 assemblyline_ui/api/__init__.py
--rw-r--r--  2.0 unx    14502 b- defN 24-Apr-11 13:59 assemblyline_ui/api/base.py
--rw-r--r--  2.0 unx     3915 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/__init__.py
--rw-r--r--  2.0 unx    37510 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/alert.py
--rw-r--r--  2.0 unx    24904 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/archive.py
--rw-r--r--  2.0 unx     1866 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/assistant.py
--rw-r--r--  2.0 unx    33569 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/authentication.py
--rw-r--r--  2.0 unx    32455 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/badlist.py
--rw-r--r--  2.0 unx     5141 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/bundle.py
--rw-r--r--  2.0 unx     2560 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/error.py
--rw-r--r--  2.0 unx    12508 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/federated_lookup.py
--rw-r--r--  2.0 unx    55854 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/file.py
--rw-r--r--  2.0 unx    11900 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/hash_search.py
--rw-r--r--  2.0 unx     6367 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/help.py
--rw-r--r--  2.0 unx     2910 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/heuristics.py
--rw-r--r--  2.0 unx    20441 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/ingest.py
--rw-r--r--  2.0 unx     5477 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/live.py
--rw-r--r--  2.0 unx    13223 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/ontology.py
--rw-r--r--  2.0 unx     7985 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/replay.py
--rw-r--r--  2.0 unx     6203 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/result.py
--rw-r--r--  2.0 unx    23121 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/retrohunt.py
--rw-r--r--  2.0 unx    23196 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/safelist.py
--rw-r--r--  2.0 unx    20528 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/search.py
--rw-r--r--  2.0 unx    39389 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/service.py
--rw-r--r--  2.0 unx    26966 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/signature.py
--rw-r--r--  2.0 unx    46126 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/submission.py
--rw-r--r--  2.0 unx    20443 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/submit.py
--rw-r--r--  2.0 unx    20730 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/system.py
--rw-r--r--  2.0 unx    11728 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/ui.py
--rw-r--r--  2.0 unx    40316 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/user.py
--rw-r--r--  2.0 unx     4734 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/webauthn.py
--rw-r--r--  2.0 unx    10308 b- defN 24-Apr-11 13:59 assemblyline_ui/api/v4/workflow.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/__init__.py
--rw-r--r--  2.0 unx     1686 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/discover.py
--rw-r--r--  2.0 unx     8154 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/oauth.py
--rw-r--r--  2.0 unx     4926 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/result.py
--rw-r--r--  2.0 unx     1686 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/search.py
--rw-r--r--  2.0 unx     3260 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/service.py
--rw-r--r--  2.0 unx      899 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/signature.py
--rw-r--r--  2.0 unx     6835 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/submission.py
--rw-r--r--  2.0 unx     7628 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/user.py
--rw-r--r--  2.0 unx      443 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/ai/__init__.py
--rw-r--r--  2.0 unx      895 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/ai/base.py
--rw-r--r--  2.0 unx     5569 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/ai/cohere.py
--rw-r--r--  2.0 unx     5267 b- defN 24-Apr-11 13:59 assemblyline_ui/helper/ai/openai.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 13:59 assemblyline_ui/security/__init__.py
--rw-r--r--  2.0 unx     1410 b- defN 24-Apr-11 13:59 assemblyline_ui/security/apikey_auth.py
--rw-r--r--  2.0 unx    10116 b- defN 24-Apr-11 13:59 assemblyline_ui/security/authenticator.py
--rw-r--r--  2.0 unx    13749 b- defN 24-Apr-11 13:59 assemblyline_ui/security/ldap_auth.py
--rw-r--r--  2.0 unx     3074 b- defN 24-Apr-11 13:59 assemblyline_ui/security/oauth_auth.py
--rw-r--r--  2.0 unx     2951 b- defN 24-Apr-11 13:59 assemblyline_ui/security/second_factor_auth.py
--rw-r--r--  2.0 unx      750 b- defN 24-Apr-11 13:59 assemblyline_ui/security/userpass_auth.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/__init__.py
--rw-r--r--  2.0 unx     2170 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/alert.py
--rw-r--r--  2.0 unx     3529 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/base.py
--rw-r--r--  2.0 unx     2041 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/file.py
--rw-r--r--  2.0 unx     4158 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/live_submission.py
--rw-r--r--  2.0 unx     2146 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/retrohunt.py
--rw-r--r--  2.0 unx     1980 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/status.py
--rw-r--r--  2.0 unx     2222 b- defN 24-Apr-11 13:59 assemblyline_ui/sio/submission.py
--rw-r--r--  2.0 unx     1396 b- defN 24-Apr-11 13:59 assemblyline_ui-4.5.1.dev76.dist-info/LICENCE.md
--rw-r--r--  2.0 unx     2898 b- defN 24-Apr-11 13:59 assemblyline_ui-4.5.1.dev76.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-11 13:59 assemblyline_ui-4.5.1.dev76.dist-info/WHEEL
--rw-r--r--  2.0 unx       16 b- defN 24-Apr-11 13:59 assemblyline_ui-4.5.1.dev76.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6913 b- defN 24-Apr-11 13:59 assemblyline_ui-4.5.1.dev76.dist-info/RECORD
-77 files, 718963 bytes uncompressed, 164487 bytes compressed:  77.1%
+Zip file size: 171166 bytes, number of entries: 74
+-rw-r--r--  2.0 unx       11 b- defN 24-Feb-22 20:16 assemblyline_ui/VERSION
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-22 20:16 assemblyline_ui/__init__.py
+-rw-r--r--  2.0 unx     6606 b- defN 24-Feb-22 20:16 assemblyline_ui/app.py
+-rw-r--r--  2.0 unx     5709 b- defN 24-Feb-22 20:16 assemblyline_ui/config.py
+-rw-r--r--  2.0 unx     3690 b- defN 24-Feb-22 20:16 assemblyline_ui/error.py
+-rw-r--r--  2.0 unx      740 b- defN 24-Feb-22 20:16 assemblyline_ui/gunicorn_config.py
+-rw-r--r--  2.0 unx      115 b- defN 24-Feb-22 20:16 assemblyline_ui/gunicorn_config_socketio.py
+-rw-r--r--  2.0 unx      777 b- defN 24-Feb-22 20:16 assemblyline_ui/healthz.py
+-rw-r--r--  2.0 unx      199 b- defN 24-Feb-22 20:16 assemblyline_ui/http_exceptions.py
+-rw-r--r--  2.0 unx     2322 b- defN 24-Feb-22 20:16 assemblyline_ui/logger.py
+-rw-r--r--  2.0 unx       85 b- defN 24-Feb-22 20:16 assemblyline_ui/patched.py
+-rw-r--r--  2.0 unx     2596 b- defN 24-Feb-22 20:16 assemblyline_ui/socketsrv.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-22 20:16 assemblyline_ui/api/__init__.py
+-rw-r--r--  2.0 unx    14502 b- defN 24-Feb-22 20:16 assemblyline_ui/api/base.py
+-rw-r--r--  2.0 unx     3915 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/__init__.py
+-rw-r--r--  2.0 unx    34480 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/alert.py
+-rw-r--r--  2.0 unx    24438 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/archive.py
+-rw-r--r--  2.0 unx    33569 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/authentication.py
+-rw-r--r--  2.0 unx    32455 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/badlist.py
+-rw-r--r--  2.0 unx     5141 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/bundle.py
+-rw-r--r--  2.0 unx     2560 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/error.py
+-rw-r--r--  2.0 unx    12508 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/federated_lookup.py
+-rw-r--r--  2.0 unx    55345 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/file.py
+-rw-r--r--  2.0 unx    11452 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/hash_search.py
+-rw-r--r--  2.0 unx     6367 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/help.py
+-rw-r--r--  2.0 unx     2910 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/heuristics.py
+-rw-r--r--  2.0 unx    19980 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/ingest.py
+-rw-r--r--  2.0 unx     5477 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/live.py
+-rw-r--r--  2.0 unx    13223 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/ontology.py
+-rw-r--r--  2.0 unx     7985 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/replay.py
+-rw-r--r--  2.0 unx     6203 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/result.py
+-rw-r--r--  2.0 unx    23028 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/retrohunt.py
+-rw-r--r--  2.0 unx    23196 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/safelist.py
+-rw-r--r--  2.0 unx    20528 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/search.py
+-rw-r--r--  2.0 unx    40038 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/service.py
+-rw-r--r--  2.0 unx    26966 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/signature.py
+-rw-r--r--  2.0 unx    45803 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/submission.py
+-rw-r--r--  2.0 unx    20197 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/submit.py
+-rw-r--r--  2.0 unx    20730 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/system.py
+-rw-r--r--  2.0 unx    11728 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/ui.py
+-rw-r--r--  2.0 unx    39953 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/user.py
+-rw-r--r--  2.0 unx     4734 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/webauthn.py
+-rw-r--r--  2.0 unx    10308 b- defN 24-Feb-22 20:16 assemblyline_ui/api/v4/workflow.py
+-rw-r--r--  2.0 unx        1 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/__init__.py
+-rw-r--r--  2.0 unx     2224 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/ai.py
+-rw-r--r--  2.0 unx     1686 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/discover.py
+-rw-r--r--  2.0 unx     7435 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/oauth.py
+-rw-r--r--  2.0 unx     4926 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/result.py
+-rw-r--r--  2.0 unx      500 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/retrohunt.py
+-rw-r--r--  2.0 unx     1681 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/search.py
+-rw-r--r--  2.0 unx     3218 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/service.py
+-rw-r--r--  2.0 unx      899 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/signature.py
+-rw-r--r--  2.0 unx     6835 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/submission.py
+-rw-r--r--  2.0 unx     7628 b- defN 24-Feb-22 20:16 assemblyline_ui/helper/user.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-22 20:16 assemblyline_ui/security/__init__.py
+-rw-r--r--  2.0 unx     1410 b- defN 24-Feb-22 20:16 assemblyline_ui/security/apikey_auth.py
+-rw-r--r--  2.0 unx    10116 b- defN 24-Feb-22 20:16 assemblyline_ui/security/authenticator.py
+-rw-r--r--  2.0 unx    13749 b- defN 24-Feb-22 20:16 assemblyline_ui/security/ldap_auth.py
+-rw-r--r--  2.0 unx     3074 b- defN 24-Feb-22 20:16 assemblyline_ui/security/oauth_auth.py
+-rw-r--r--  2.0 unx     2951 b- defN 24-Feb-22 20:16 assemblyline_ui/security/second_factor_auth.py
+-rw-r--r--  2.0 unx      750 b- defN 24-Feb-22 20:16 assemblyline_ui/security/userpass_auth.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/__init__.py
+-rw-r--r--  2.0 unx     2170 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/alert.py
+-rw-r--r--  2.0 unx     3529 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/base.py
+-rw-r--r--  2.0 unx     2041 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/file.py
+-rw-r--r--  2.0 unx     4158 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/live_submission.py
+-rw-r--r--  2.0 unx     2153 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/retrohunt.py
+-rw-r--r--  2.0 unx     1980 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/status.py
+-rw-r--r--  2.0 unx     2222 b- defN 24-Feb-22 20:16 assemblyline_ui/sio/submission.py
+-rw-r--r--  2.0 unx     1396 b- defN 24-Feb-22 20:16 assemblyline_ui-4.5.1.dev8.dist-info/LICENCE.md
+-rw-r--r--  2.0 unx     2933 b- defN 24-Feb-22 20:16 assemblyline_ui-4.5.1.dev8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Feb-22 20:16 assemblyline_ui-4.5.1.dev8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       16 b- defN 24-Feb-22 20:16 assemblyline_ui-4.5.1.dev8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6626 b- defN 24-Feb-22 20:16 assemblyline_ui-4.5.1.dev8.dist-info/RECORD
+74 files, 700968 bytes uncompressed, 160582 bytes compressed:  77.1%
```

## zipnote {}

```diff
@@ -45,17 +45,14 @@
 
 Filename: assemblyline_ui/api/v4/alert.py
 Comment: 
 
 Filename: assemblyline_ui/api/v4/archive.py
 Comment: 
 
-Filename: assemblyline_ui/api/v4/assistant.py
-Comment: 
-
 Filename: assemblyline_ui/api/v4/authentication.py
 Comment: 
 
 Filename: assemblyline_ui/api/v4/badlist.py
 Comment: 
 
 Filename: assemblyline_ui/api/v4/bundle.py
@@ -129,23 +126,29 @@
 
 Filename: assemblyline_ui/api/v4/workflow.py
 Comment: 
 
 Filename: assemblyline_ui/helper/__init__.py
 Comment: 
 
+Filename: assemblyline_ui/helper/ai.py
+Comment: 
+
 Filename: assemblyline_ui/helper/discover.py
 Comment: 
 
 Filename: assemblyline_ui/helper/oauth.py
 Comment: 
 
 Filename: assemblyline_ui/helper/result.py
 Comment: 
 
+Filename: assemblyline_ui/helper/retrohunt.py
+Comment: 
+
 Filename: assemblyline_ui/helper/search.py
 Comment: 
 
 Filename: assemblyline_ui/helper/service.py
 Comment: 
 
 Filename: assemblyline_ui/helper/signature.py
@@ -153,26 +156,14 @@
 
 Filename: assemblyline_ui/helper/submission.py
 Comment: 
 
 Filename: assemblyline_ui/helper/user.py
 Comment: 
 
-Filename: assemblyline_ui/helper/ai/__init__.py
-Comment: 
-
-Filename: assemblyline_ui/helper/ai/base.py
-Comment: 
-
-Filename: assemblyline_ui/helper/ai/cohere.py
-Comment: 
-
-Filename: assemblyline_ui/helper/ai/openai.py
-Comment: 
-
 Filename: assemblyline_ui/security/__init__.py
 Comment: 
 
 Filename: assemblyline_ui/security/apikey_auth.py
 Comment: 
 
 Filename: assemblyline_ui/security/authenticator.py
@@ -210,23 +201,23 @@
 
 Filename: assemblyline_ui/sio/status.py
 Comment: 
 
 Filename: assemblyline_ui/sio/submission.py
 Comment: 
 
-Filename: assemblyline_ui-4.5.1.dev76.dist-info/LICENCE.md
+Filename: assemblyline_ui-4.5.1.dev8.dist-info/LICENCE.md
 Comment: 
 
-Filename: assemblyline_ui-4.5.1.dev76.dist-info/METADATA
+Filename: assemblyline_ui-4.5.1.dev8.dist-info/METADATA
 Comment: 
 
-Filename: assemblyline_ui-4.5.1.dev76.dist-info/WHEEL
+Filename: assemblyline_ui-4.5.1.dev8.dist-info/WHEEL
 Comment: 
 
-Filename: assemblyline_ui-4.5.1.dev76.dist-info/top_level.txt
+Filename: assemblyline_ui-4.5.1.dev8.dist-info/top_level.txt
 Comment: 
 
-Filename: assemblyline_ui-4.5.1.dev76.dist-info/RECORD
+Filename: assemblyline_ui-4.5.1.dev8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## assemblyline_ui/VERSION

```diff
@@ -1 +1 @@
-4.5.1.dev76
+4.5.1.dev8
```

## assemblyline_ui/app.py

```diff
@@ -6,15 +6,14 @@
 from flask import Flask
 from flask.logging import default_handler
 
 from assemblyline_ui.api.base import api
 from assemblyline_ui.api.v4 import apiv4
 from assemblyline_ui.api.v4.alert import alert_api
 from assemblyline_ui.api.v4.archive import archive_api
-from assemblyline_ui.api.v4.assistant import assistant_api
 from assemblyline_ui.api.v4.authentication import auth_api
 from assemblyline_ui.api.v4.badlist import badlist_api
 from assemblyline_ui.api.v4.bundle import bundle_api
 from assemblyline_ui.api.v4.error import error_api
 from assemblyline_ui.api.v4.federated_lookup import federated_lookup_api
 from assemblyline_ui.api.v4.file import file_api
 from assemblyline_ui.api.v4.hash_search import hash_search_api
@@ -80,28 +79,28 @@
     ssl_context = CERT_BUNDLE
     if AL_HSTS_MAX_AGE is not None:
         try:
             int(AL_HSTS_MAX_AGE)
         except:
             raise ValueError("AL_HSTS_MAX_AGE must be set to an integer")
 
+
         def include_hsts_header(response):
             response.headers['Strict-Transport-Security'] = f"max-age={AL_HSTS_MAX_AGE}; includeSubdomains"
             return response
 
+
         app.after_request(include_hsts_header)
 
 app.register_blueprint(healthz)
 app.register_blueprint(api)
 app.register_blueprint(apiv4)
 app.register_blueprint(alert_api)
 if config.config.datastore.archive.enabled:
     app.register_blueprint(archive_api)
-if config.config.ui.ai.enabled:
-    app.register_blueprint(assistant_api)
 app.register_blueprint(auth_api)
 app.register_blueprint(badlist_api)
 app.register_blueprint(bundle_api)
 app.register_blueprint(errors)
 app.register_blueprint(error_api)
 app.register_blueprint(federated_lookup_api)
 app.register_blueprint(file_api)
@@ -176,8 +175,8 @@
         wlog.addHandler(h)
 
     app.jinja_env.cache = {}
     app.run(host="0.0.0.0", debug=False, ssl_context=ssl_context)
 
 
 if __name__ == '__main__':
-    main()
+    main()
```

## assemblyline_ui/config.py

```diff
@@ -2,25 +2,23 @@
 import os
 
 from assemblyline.common.archiving import ArchiveManager
 from assemblyline.common.identify import Identify
 from assemblyline.common.version import BUILD_MINOR, FRAMEWORK_VERSION, SYSTEM_VERSION
 from assemblyline.common.logformat import AL_LOG_FORMAT
 from assemblyline.common import forge, log as al_log
-from assemblyline.datastore.helper import AssemblylineDatastore, MetadataValidator
+from assemblyline.datastore.helper import AssemblylineDatastore
 from assemblyline.filestore import FileStore
 from assemblyline.remote.datatypes import get_client
 from assemblyline.remote.datatypes.cache import Cache
 from assemblyline.remote.datatypes.hash import Hash
 from assemblyline.remote.datatypes.queues.comms import CommsQueue
 from assemblyline.remote.datatypes.queues.named import NamedQueue
 from assemblyline.remote.datatypes.set import ExpiringSet
 from assemblyline.remote.datatypes.user_quota_tracker import UserQuotaTracker
-from assemblyline_ui.helper.ai import get_ai_agent
-from assemblyline_ui.helper.ai.base import AIAgent
 from assemblyline_ui.helper.discover import get_apps_list
 
 config = forge.get_config()
 
 #################################################################
 # Configuration
 
@@ -143,19 +141,16 @@
 FILESTORE: FileStore = forge.get_filestore(config=config)
 if config.datastore.archive.enabled:
     ARCHIVESTORE: FileStore = forge.get_archivestore(config=config)
 else:
     ARCHIVESTORE = None
 if config.ui.ai.enabled:
     AI_CACHE: Cache = Cache(prefix="ai_cache", host=redis, ttl=24 * 60 * 60)
-    AI_AGENT: AIAgent = get_ai_agent(config.ui.ai, LOGGER)
 else:
     AI_CACHE = None
-    AI_AGENT = None
 STORAGE: AssemblylineDatastore = forge.get_datastore(config=config, archive_access=True)
-metadata_validator = MetadataValidator(STORAGE)
 IDENTIFY: Identify = forge.get_identify(config=config, datastore=STORAGE, use_cache=True)
 ARCHIVE_MANAGER: ArchiveManager = ArchiveManager(
     config=config, datastore=STORAGE, filestore=FILESTORE, identify=IDENTIFY)
 SERVICE_LIST = forge.CachedObject(STORAGE.list_all_services, kwargs=dict(as_obj=False, full=True))
 # End global
 #################################################################
```

## assemblyline_ui/api/v4/alert.py

```diff
@@ -12,35 +12,32 @@
 
 SUB_API = 'alert'
 
 alert_api = make_subapi_blueprint(SUB_API, api_version=4)
 alert_api._doc = "Perform operations on alerts"
 
 
-def get_alert_update_ops(user_id: str, status: str = None, priority: str = None, labels=[], labels_removed=[]) -> dict:
+def get_alert_update_ops(user_id: str, status: str = None, priority: str = None, labels=[]) -> dict:
     operations = []
     if status:
         operations.append((STORAGE.alert.UPDATE_SET, 'status', status))
     if priority:
         operations.append((STORAGE.alert.UPDATE_SET, 'priority', priority))
     for label in labels:
         operations.append((STORAGE.alert.UPDATE_APPEND_IF_MISSING, 'label', label))
-    for label in labels_removed:
-        operations.append((STORAGE.alert.UPDATE_REMOVE, 'label', label))
 
     # Make sure operations get audited
     if operations:
         operations.append((STORAGE.alert.UPDATE_APPEND, 'events', AlertEvent({
             'entity_type': 'user',
             'entity_id': user_id,
             'entity_name': STORAGE.user.get(user_id, as_obj=False)['name'],
             'status': status,
             'priority': priority,
-            'labels': labels,
-            'labels_removed': labels_removed
+            'labels': labels or None,
         })))
 
     return operations
 
 
 def get_timming_filter(tc_start, tc):
     if tc:
@@ -424,27 +421,32 @@
         return make_api_response(res)
     except SearchException as e:
         return make_api_response("", f"SearchException: {e}", 400)
 
 
 @alert_api.route("/all/<alert_id>/", methods=["POST"])
 @api_login(allow_readonly=False, require_role=[ROLES.alert_manage])
-def run_workflow(alert_id, **kwargs):
+def run_workflow(**kwargs):
     """
     Apply one-time workflow to specified alert
 
     Variables:
     alert_id                         => ID of the alert to add the label to
 
+    Arguments:
+    q                                => Main query to filter the data [REQUIRED]
+    tc_start                         => Time offset at which we start the time constraint
+    tc                               => Time constraint applied to the API
+    fq                               => Filter query applied to the data
+
     Data Block:
     {
         "priority": "HIGH"           => New priority for the alert
         "status": "MALICIOUS"        => New status for the alert
         "labels": ["LBL1", "LBL2"]   => List of labels to add as comma separated string
-        "removed_labels": ["LBL3", "LBL4"]  => List of labels to remove as a comma separated string
     }
 
     API call example:
     /api/v4/alert/label/batch/?q=protocol:SMTP
 
     Result example:
     { "success": true }
@@ -459,17 +461,28 @@
         status = request.json.get('status')
         status = status.upper() if status else None
         if status not in STATUSES:
             raise ValueError(f"Status '{status}' not in statuses")
     except ValueError as e:
         return make_api_response({"success": False}, err=str(e), status_code=400)
 
+    query = request.args.get('q', "alert_id:*") or "alert_id:*"
+    tc_start = request.args.get('tc_start', None)
+    tc = request.args.get('tc', None)
+    if tc and config.ui.read_only:
+        tc += config.ui.read_only_offset
+    timming_filter = get_timming_filter(tc_start, tc)
+
+    filters = [x for x in request.args.getlist("fq") if x != ""]
+    if timming_filter:
+        filters.append(timming_filter)
+
     operations = get_alert_update_ops(user['uname'], labels=labels, priority=priority, status=status)
     return make_api_response({
-        "success": STORAGE.alert.update(alert_id, operations, access_control=user['access_control'])
+        "success": STORAGE.alert.update_by_query(query, operations, filters, access_control=user['access_control'])
     })
 
 
 @alert_api.route("/all/batch/", methods=["POST"])
 @api_login(allow_readonly=False, require_role=[ROLES.alert_manage])
 def run_workflow_by_batch(**kwargs):
     """
@@ -482,30 +495,28 @@
     q                                 =>  Main query to filter the data [REQUIRED]
     tc_start                          => Time offset at which we start the time constraint
     tc                                => Time constraint applied to the API
     fq                                =>  Filter query applied to the data
 
     Data Block:
     {
-        "priority": "HIGH"                  => New priority for the alert
-        "status": "MALICIOUS"               => New status for the alert
-        "labels": ["LBL1", "LBL2"]          => List of labels to add as comma separated string
-        "removed_labels": ["LBL3", "LBL4"]  => List of labels to remove as a comma separated string
+        "priority": "HIGH"           => New priority for the alert
+        "status": "MALICIOUS"        => New status for the alert
+        "labels": ["LBL1", "LBL2"]   => List of labels to add as comma separated string
     }
 
     API call example:
     /api/v4/alert/label/batch/?q=protocol:SMTP
 
     Result example:
     { "success": true }
     """
     user = kwargs['user']
     try:
-        labels = set([label.upper() for label in request.json.get('labels', [])])
-        removed_labels = set([label.upper() for label in request.json.get('removed_labels', [])])
+        labels = set(request.json.get('labels', []))
         priority = request.json.get('priority')
         priority = priority.upper() if priority else None
         if priority not in PRIORITIES:
             raise ValueError(f"Priority {priority} not in priorities")
         status = request.json.get('status')
         status = status.upper() if status else None
         if status not in STATUSES:
@@ -520,16 +531,15 @@
         tc += config.ui.read_only_offset
     timming_filter = get_timming_filter(tc_start, tc)
 
     filters = [x for x in request.args.getlist("fq") if x != ""]
     if timming_filter:
         filters.append(timming_filter)
 
-    operations = get_alert_update_ops(user['uname'], labels=labels, priority=priority,
-                                      status=status, labels_removed=removed_labels)
+    operations = get_alert_update_ops(user['uname'], labels=labels, priority=priority, status=status)
     return make_api_response({
         "success": STORAGE.alert.update_by_query(query, operations, filters, access_control=user['access_control'])
     })
 
 
 @alert_api.route("/label/<alert_id>/", methods=["POST"])
 @api_login(allow_readonly=False, require_role=[ROLES.alert_manage])
@@ -550,15 +560,15 @@
     /api/v4/alert/label/12345...67890/
 
     Result example:
     {"success": true}
     """
     user = kwargs['user']
     try:
-        labels = set([label.upper() for label in request.json])
+        labels = set(request.json)
     except ValueError:
         return make_api_response({"success": False}, err="Invalid list of labels received.", status_code=400)
 
     alert = STORAGE.alert.get(alert_id, as_obj=False)
 
     if not alert:
         return make_api_response({"success": False}, err="Alert ID %s not found" % alert_id, status_code=404)
@@ -598,15 +608,15 @@
     /api/v4/alert/label/batch/?q=protocol:SMTP
 
     Result example:
     { "success": true }
     """
     user = kwargs['user']
     try:
-        labels = set([label.upper() for label in request.json])
+        labels = set(request.json)
     except ValueError:
         return make_api_response({"success": False}, err="Invalid list of labels received.", status_code=400)
 
     query = request.args.get('q', "alert_id:*") or "alert_id:*"
     tc_start = request.args.get('tc_start', None)
     tc = request.args.get('tc', None)
     if tc and config.ui.read_only:
@@ -619,107 +629,14 @@
 
     operations = get_alert_update_ops(user['uname'], labels=labels)
     return make_api_response({
         "success": STORAGE.alert.update_by_query(query, operations, filters, access_control=user['access_control'])
     })
 
 
-@alert_api.route("/label/<alert_id>/", methods=["DELETE"])
-@api_login(allow_readonly=False, require_role=[ROLES.alert_manage])
-def remove_labels(alert_id, **kwargs):
-    """
-    Remove one or multiple labels to a given alert
-
-    Variables:
-    alert_id           => ID of the alert to remove the label to
-
-    Arguments:
-    None
-
-    Data Block:
-    ["LBL1", "LBL2"]   => List of labels to remove as comma separated string
-
-    API call example:
-    /api/v4/alert/label/12345...67890/
-
-    Result example:
-    {"success": true}
-    """
-    user = kwargs['user']
-    try:
-        labels = set([label.upper() for label in request.json])
-    except ValueError:
-        return make_api_response({"success": False}, err="Invalid list of labels received.", status_code=400)
-
-    alert = STORAGE.alert.get(alert_id, as_obj=False)
-
-    if not alert:
-        return make_api_response({"success": False}, err="Alert ID %s not found" % alert_id, status_code=404)
-
-    if not Classification.is_accessible(user['classification'], alert['classification']):
-        return make_api_response("", "You are not allowed to see this alert...", 403)
-
-    cur_label = set(alert.get('label', []))
-    # Check to see if any of the labels being proposed to be removed exists
-    label_inter = cur_label.intersection(labels)
-    if label_inter:
-        return make_api_response({
-            "success": STORAGE.alert.update(alert_id, get_alert_update_ops(user['uname'], labels_removed=label_inter))
-        })
-    else:
-        return make_api_response({"success": True})
-
-
-@alert_api.route("/label/batch/", methods=["DELETE"])
-@api_login(allow_readonly=False, require_role=[ROLES.alert_manage])
-def remove_labels_by_batch(**kwargs):
-    """
-    Remove labels to all alerts matching the given filters
-
-    Variables:
-    None
-
-    Arguments:
-    q          =>  Main query to filter the data [REQUIRED]
-    tc_start   => Time offset at which we start the time constraint
-    tc         => Time constraint applied to the API
-    fq         =>  Filter query applied to the data
-
-    Data Block:
-    ["LBL1", "LBL2"]   => List of labels to remove as comma separated string
-
-    API call example:
-    /api/v4/alert/label/batch/?q=protocol:SMTP
-
-    Result example:
-    { "success": true }
-    """
-    user = kwargs['user']
-    try:
-        labels = set([label.upper() for label in request.json])
-    except ValueError:
-        return make_api_response({"success": False}, err="Invalid list of labels received.", status_code=400)
-
-    query = request.args.get('q', "alert_id:*") or "alert_id:*"
-    tc_start = request.args.get('tc_start', None)
-    tc = request.args.get('tc', None)
-    if tc and config.ui.read_only:
-        tc += config.ui.read_only_offset
-    timming_filter = get_timming_filter(tc_start, tc)
-
-    filters = [x for x in request.args.getlist("fq") if x != ""]
-    if timming_filter:
-        filters.append(timming_filter)
-
-    operations = get_alert_update_ops(user['uname'], labels_removed=labels)
-    return make_api_response({
-        "success": STORAGE.alert.update_by_query(query, operations, filters, access_control=user['access_control'])
-    })
-
-
 @alert_api.route("/priority/<alert_id>/", methods=["POST"])
 @api_login(allow_readonly=False, require_role=[ROLES.alert_manage])
 def change_priority(alert_id, **kwargs):
     """
     Change the priority of a given alert
 
     Variables:
```

## assemblyline_ui/api/v4/archive.py

```diff
@@ -26,20 +26,17 @@
     Send a submission to the permanent archive
 
     Variables:
     sid         => ID of the submission to send to the archive
 
     Arguments:
     delete_after     => Delete data from hot storage after the move ? (Default: False)
-    skip_hook        => Skip webhook, if there is a webhook (Default: False)
 
-    Data Block (Optional):
-    {                                   # Optional metadata block to be added to the submission while archiving
-     "meta_key": "Metadata value!"
-    }
+    Data Block:
+    None
 
     API call example:
     /api/v4/archive/12345...67890/
 
     Result example:
     {
      "success": True,      # Was the archiving operation successful
@@ -49,31 +46,24 @@
     }
     """
     if not config.datastore.archive.enabled:
         return make_api_response({"success": False}, "Archiving is disabled on the server.", 403)
 
     user = kwargs['user']
     delete_after = request.args.get('delete_after', 'false').lower() in ['true', '']
-    skip_hook = request.args.get('skip_hook', 'false').lower() in ['true', '']
     submission = STORAGE.submission.get_if_exists(sid, as_obj=False)
     if not submission:
         return make_api_response({"success": False}, f"The submission '{sid}' was not found in the system", 404)
 
     if not user or not Classification.is_accessible(user['classification'], submission['classification']):
         return make_api_response({"success": False}, f"The submission '{sid}' is not accessible by this user", 403)
 
     try:
-        metadata = request.json
-    except Exception as e:
-        LOGGER.warning(f"Invalid metadata [{e}]")
-        metadata = None
-
-    try:
-        archive_action = ARCHIVE_MANAGER.archive_submission(
-            submission=submission, delete_after=delete_after, metadata=metadata, skip_hook=skip_hook)
+        archive_action = ARCHIVE_MANAGER.archive_submission(submission=submission, delete_after=delete_after)
+        archive_action['success'] = True
         return make_api_response(archive_action)
 
     except SubmissionException as se:
         return make_api_response({"success": False}, err=str(se), status_code=400)
 
 
 @archive_api.route("/comment/<sha256>/", methods=["GET"])
```

## assemblyline_ui/api/v4/file.py

```diff
@@ -15,16 +15,17 @@
 from assemblyline.common.str_utils import safe_str
 from assemblyline.datastore.collection import Index
 from assemblyline.datastore.exceptions import DataStoreException
 from assemblyline.filestore import FileStoreException
 from assemblyline.odm.models.user import ROLES
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint, stream_file_response
 from assemblyline_ui.config import AI_CACHE, ALLOW_ZIP_DOWNLOADS, ALLOW_RAW_DOWNLOADS, FILESTORE, STORAGE, config, \
-    CLASSIFICATION as Classification, ARCHIVESTORE, AI_AGENT
-from assemblyline_ui.helper.ai.base import APIException, EmptyAIResponse
+    CLASSIFICATION as Classification, ARCHIVESTORE
+from assemblyline_ui.helper.ai import APIException, EmptyAIResponse, \
+    summarize_code_snippet as ai_code, summarized_al_submission
 from assemblyline_ui.helper.result import format_result
 from assemblyline_ui.helper.user import load_user_settings
 from assemblyline.datastore.collection import Index
 
 LABEL_CATEGORIES = ['attribution', 'technique', 'info']
 MAX_CONCURRENT_VECTORS = 5
 
@@ -475,15 +476,14 @@
 
     Variables:
     sha256       => A resource locator for the file (sha256)
 
     Arguments:
     archive_only   => Only use the archive data to generate the summary
     no_cache       => Caching for the output of this API will be disabled
-    with_trace     => Should the AI call return the full trace of the conversation?
 
     Data Block:
     None
 
     API call example:
     /api/v4/file/ai/123456...654321/
 
@@ -494,44 +494,42 @@
     }
     """
     if not config.ui.ai.enabled:
         return make_api_response({}, "AI Support is disabled on this system.", 400)
 
     archive_only = request.args.get('archive_only', 'false').lower() in ['true', '']
     no_cache = request.args.get('no_cache', 'false').lower() in ['true', '']
-    lang = request.args.get('lang', 'english')
-    with_trace = request.args.get('with_trace', 'false').lower() in ['true', '']
 
     index_type = None
     if archive_only:
         if not config.datastore.archive.enabled:
             return make_api_response({}, "Archive Support is disabled on this system.", 400)
         index_type = Index.ARCHIVE
 
     user = kwargs['user']
 
     if archive_only and ROLES.archive_view not in user['roles']:
         return make_api_response({}, "User is not allowed to view the archive", 403)
 
     # Create the cache key
-    cache_key = AI_CACHE.create_key(sha256, user['classification'], index_type, archive_only, lang, with_trace, "file")
+    cache_key = AI_CACHE.create_key(sha256, user['classification'], index_type, archive_only, "file")
     ai_summary = None
     if (not no_cache):
         # Get the summary from cache
         ai_summary = AI_CACHE.get(cache_key)
 
     if not ai_summary:
         data = STORAGE.get_ai_formatted_file_results_data(
             sha256, user_classification=user['classification'],
             user_access_control=user['access_control'], cl_engine=Classification, index_type=index_type)
         if data is None:
             return make_api_response("", "The file was not found in the system.", 404)
 
         try:
-            ai_summary = AI_AGENT.summarized_al_submission(data, lang=lang, with_trace=with_trace)
+            ai_summary = summarized_al_submission(data)
 
             # Save to cache
             AI_CACHE.set(cache_key, ai_summary)
         except (APIException, EmptyAIResponse) as e:
             return make_api_response("", str(e), 400)
 
     return make_api_response(ai_summary)
@@ -545,15 +543,14 @@
     If the file is not a code snippet, returns a 406 error code.
 
     Variables:
     sha256       => A resource locator for the file (sha256)
 
     Arguments:
     no_cache       => Caching for the output of this API will be disabled
-    with_trace     => Should the AI call return the full trace of the conversation?
 
     Data Block:
     None
 
     API call example:
     /api/v4/file/code_summary/123456...654321/
 
@@ -563,21 +560,19 @@
       "truncated": false
     }
     """
     if not config.ui.ai.enabled:
         return make_api_response({}, "AI Support is disabled on this system.", 400)
 
     no_cache = request.args.get('no_cache', 'false').lower() in ['true', '']
-    lang = request.args.get('lang', 'english')
-    with_trace = request.args.get('with_trace', 'false').lower() in ['true', '']
 
     user = kwargs['user']
 
     # Create the cache key
-    cache_key = AI_CACHE.create_key(sha256, user['classification'], lang, with_trace, "code")
+    cache_key = AI_CACHE.create_key(sha256, user['classification'], "code")
     ai_summary = None
     if (not no_cache):
         # Get the summary from cache
         ai_summary = AI_CACHE.get(cache_key)
 
     if not ai_summary:
         file_obj = STORAGE.file.get(sha256, as_obj=False)
@@ -608,15 +603,15 @@
                 except FileStoreException:
                     data = None
 
             if not data:
                 return make_api_response({}, "The file was not found in the system.", 404)
 
             try:
-                ai_summary = AI_AGENT.summarize_code_snippet(data, lang=lang, with_trace=with_trace)
+                ai_summary = ai_code(data)
 
                 # Save to cache
                 AI_CACHE.set(cache_key, ai_summary)
             except (APIException, EmptyAIResponse) as e:
                 return make_api_response("", str(e), 400)
         else:
             return make_api_response({}, "You are not allowed to view this file.", 403)
```

## assemblyline_ui/api/v4/hash_search.py

```diff
@@ -193,29 +193,15 @@
           ...
           ]
         },
         ...
     }
     """
     user = kwargs['user']
-
-    submitted_hash_type = None
-
-    for h_type, hash_pattern in HASH_MAP.items():
-        if h_type in ["sha256", "sha1", "md5"] and hash_pattern.match(file_hash.lower()):
-                # Normalize file_hash input to expected format and set the hash type
-                file_hash = file_hash.lower()
-                submitted_hash_type = h_type
-        elif hash_pattern.match(file_hash):
-            submitted_hash_type = h_type
-
-        if submitted_hash_type:
-            # We've determined the submitted hash type
-            break
-
+    submitted_hash_type = next((x for x, y in HASH_MAP.items() if y.match(file_hash)), None)
     if not submitted_hash_type:
         return make_api_response("", f"Invalid hash. This API only supports {', '.join(HASH_MAP.keys())}.", 400)
 
     # default to the submitters classification to prevent accidental data leak by forgetting to set a classification
     # but also allowing classification to be optional for when classification engine is disabled.
     hash_classification = request.args.get("classification", user["classification"])
     limit = request.args.get("limit", "500")
```

## assemblyline_ui/api/v4/ingest.py

```diff
@@ -16,15 +16,15 @@
 from assemblyline.common.str_utils import safe_str
 from assemblyline.common.uid import get_random_id
 from assemblyline.odm.messages.submission import Submission
 from assemblyline.odm.models.user import ROLES
 from assemblyline.remote.datatypes.queues.named import NamedQueue
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint
 from assemblyline_ui.config import ARCHIVESTORE, CLASSIFICATION as Classification, IDENTIFY, TEMP_SUBMIT_DIR, \
-    STORAGE, config, FILESTORE, metadata_validator
+    STORAGE, config, FILESTORE
 from assemblyline_ui.helper.service import ui_to_submission_params
 from assemblyline_ui.helper.submission import download_from_url, FileTooBigException, submission_received, refang_url
 from assemblyline_ui.helper.user import load_user_settings
 
 
 SUB_API = 'ingest'
 ingest_api = make_subapi_blueprint(SUB_API, api_version=4)
@@ -32,23 +32,24 @@
 
 ingest = NamedQueue(
     "m-ingest",
     host=config.core.redis.persistent.host,
     port=config.core.redis.persistent.port)
 MAX_SIZE = config.submission.max_file_size
 
+
 # noinspection PyUnusedLocal
 @ingest_api.route("/get_message/<notification_queue>/", methods=["GET"])
 @api_login(allow_readonly=False, require_role=[ROLES.submission_create])
 def get_message(notification_queue, **kwargs):
     """
     Get one message on the specified notification queue
 
     Variables:
-    notification_queue       => Queue to get the message from
+    complete_queue       => Queue to get the message from
 
     Arguments:
     None
 
     Data Block:
     None
 
@@ -68,35 +69,31 @@
 @ingest_api.route("/get_message_list/<notification_queue>/", methods=["GET"])
 @api_login(allow_readonly=False, require_role=[ROLES.submission_create])
 def get_all_messages(notification_queue, **kwargs):
     """
     Get all messages on the specified notification queue
 
     Variables:
-    notification_queue       => Queue to get the message from
+    complete_queue       => Queue to get the message from
 
     Arguments:
-    page_size                => Number of messages to get back from queue
+    None
 
     Data Block:
     None
 
     Result example:
     []            # List of messages
     """
     resp_list = []
-
-    # Default page_size will return all the messages within the queue
-    page_size = int(request.args.get("page_size", -1))
-
     u = NamedQueue("nq-%s" % notification_queue,
                    host=config.core.redis.persistent.host,
                    port=config.core.redis.persistent.port)
 
-    while True and len(resp_list) != page_size:
+    while True:
         msg = u.pop(blocking=False)
 
         if msg is None:
             break
 
         resp_list.append(msg)
 
@@ -417,19 +414,14 @@
         metadata['ingest_id'] = ingest_id
         metadata['type'] = s_params['type']
         metadata.update(al_meta)
         if 'ts' not in metadata:
             metadata['ts'] = now_as_iso()
         metadata.update(extra_meta)
 
-        # Validate the metadata
-        metadata_error = metadata_validator.check_metadata(metadata)
-        if metadata_error:
-            return make_api_response({}, err=metadata_error[1], status_code=400)
-
         # Set description if it does not exists
         if fileinfo["type"].startswith("uri/") and "uri_info" in fileinfo and "uri" in fileinfo["uri_info"]:
             default_description = f"Inspection of URL: {fileinfo['uri_info']['uri']}"
         s_params['description'] = s_params['description'] or f"[{s_params['type']}] {default_description}"
         # Create submission object
         try:
             submission_obj = Submission({
```

## assemblyline_ui/api/v4/retrohunt.py

```diff
@@ -1,16 +1,16 @@
 import typing
 
 from assemblyline.common.isotime import now_as_iso
-from assemblyline.common.forge import get_hauntedhouse_client
 # from assemblyline.common.threading import APMAwareThreadPoolExecutor
 from assemblyline.datastore.collection import Index
 from assemblyline.datastore.exceptions import SearchException
 from assemblyline.odm.models.user import ROLES
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint
+from assemblyline_ui.helper.retrohunt import get_hauntedhouse_client
 from assemblyline_ui.config import CLASSIFICATION, STORAGE, config, LOGGER
 from flask import request, Response
 
 SUB_API = 'retrohunt'
 retrohunt_api = make_subapi_blueprint(SUB_API, api_version=4)
 retrohunt_api._doc = "Run yara signatures over all files."
 
@@ -22,15 +22,15 @@
 @retrohunt_api.route("/", methods=["PUT"])
 @api_login(require_role=[ROLES.retrohunt_run])
 def create_retrohunt_job(**kwargs):
     """
     Create a new search over file storage.
 
     Arguments:
-        indices               => One of 'hot', 'archive', or 'hot_and_archive'
+        archive_only          => Should the search only be run on archived files
         classification        => Classification level for the search/rule
         search_classification => Classification visibility search is run with
         description           => Textual description of this search
         yara_signature        => YARA signature to search with
         ttl                   => Time to live for this retrohunt job
 
     Response Fields:    => Body of retrohunt object
@@ -44,15 +44,15 @@
     if haunted_house_client is None:
         return make_api_response({}, err="retrohunt not configured for this system", status_code=501)
 
     # Parse the input document
     try:
         signature = str(body['yara_signature'])
         description = str(body['description'])
-        indices = str(body['indices'])
+        archive_only = bool(body['archive_only'])
         classification = str(body['classification'])
         search_classification = str(body['search_classification'])
     except KeyError as err:
         return make_api_response({}, err=f"Missing required argument: {err}", status_code=400)
 
     # Make sure the user has high enough access
     classification = CLASSIFICATION.normalize_classification(classification)
@@ -72,29 +72,29 @@
         
     try:
         # Parse the signature and send it to the retrohunt api
         key = haunted_house_client.start_search(
             yara_rule=signature,
             rule_classification=classification,
             search_classification=search_classification,
-            indices=indices,
+            archive_only=archive_only,
             creator=user['uname'],
             description=description,
             expiry=max_expiry,
         )
 
         # Fetch the details after the retrohunt server has parsed them and saved them to elasticsearch
         doc = STORAGE.retrohunt.get(key, as_obj=False)
 
         return make_api_response(doc)
     except Exception as e:
         return make_api_response("", f"{e}", 400)
 
 
-@retrohunt_api.route("/repeat/", methods=["POST"])
+@retrohunt_api.route("/repeat", methods=["POST"])
 @api_login(require_role=[ROLES.retrohunt_run])
 def repeat_retrohunt_job(**kwargs):
     """
     Repeat a search over file storage.
 
     Arguments:
         key                    => Key of the job to repeat
@@ -230,15 +230,15 @@
 
         if items:
             query = 'search: (' + ' OR '.join(item['key'] for item in items) + ')'
             counts = STORAGE.retrohunt_hit.facet("search", query=query,
                                                  access_control=user['access_control'], size=len(items))
             for item in items:
                 item['total_hits'] = counts.get(item['key'], 0)
-
+                
         return make_api_response(result)
     except SearchException as e:
         return make_api_response("", f"SearchException: {e}", 400)
 
 
 @retrohunt_api.route("/<id>/", methods=["GET", "POST"])
 @api_login(require_role=[ROLES.retrohunt_view])
@@ -247,26 +247,29 @@
     Get the details of a completed or an in progress retrohunt job.
 
     Variables:
         id                => ID of the retrohunt job to be retrieved
 
     Response Fields:
     {
+        "archive_only": False,                      #   Defines the indices used for this retrohunt job
         "classification": "TLP:WHITE",              #   Classification string for the retrohunt job and results list
         "code": "0x",                               #   Unique code identifying this retrohunt job
         "created": "2023-01-01T00:00:00.000000Z",   #   Timestamp when this retrohunt job started
         "creator": "admin",                         #   User who created this retrohunt job
         "description": "This is the description",   #   Human readable description of this retrohunt job
         "finished": True,                           #   Boolean indicating if this retrohunt job is finished
         "id": "0x",                                 #   Unique code identifying this retrohunt job
+        "phase": "finished",                        #   Phase the job is on : 'filtering' | 'yara' | 'finished'
+        "percentage": 0,                            #   Percentage of completion the phase is at
+        "progress": [1, 1],                         #   Progress values when the job is running
         "raw_query": "(min 1 of (100))",            #   Text of filter query derived from yara signature
         "tags": {},                                 #   Tags describing this retrohunt job
         "total_hits": 100,                          #   Total number of hits when the job first ran
         "total_errors": 80,                         #   Total number of errors encountered during the job
-        "total_warnings": 80,                       #   Total number of warnings encountered during the job
         "truncated": False,                         #   Indicates if the list of hits been truncated at some limit
         "yara_signature":                           #   Text of original yara signature run
                             rule my_rule {
                                 meta:
                                     KEY = "VALUE"
                                 strings:
                                     $name = "string"
@@ -280,15 +283,15 @@
     # Make sure retrohunt is configured
     if haunted_house_client is None:
         return make_api_response({}, err="retrohunt not configured for this system", status_code=501)
 
     doc = STORAGE.retrohunt.get(id, as_obj=False)
     if not doc:
         return make_api_response({}, "This retrohunt job does not exist...", 404)
-
+    
     if not user or not CLASSIFICATION.is_accessible(user['classification'], doc['classification']):
         return make_api_response({}, err="Access denied.", status_code=403)
 
     doc['total_errors'] = len(doc['errors'])
     doc['total_warnings'] = len(doc['warnings'])
     doc.pop('warnings', None)
     doc.pop('errors', None)
@@ -367,15 +370,15 @@
 
     doc = STORAGE.retrohunt.get(id, as_obj=False)
     if not doc:
         return make_api_response({}, "This retrohunt job does not exist...", 404)
 
     if not user or not CLASSIFICATION.is_accessible(user['classification'], doc['classification']):
         return make_api_response({}, err="Access denied.", status_code=403)
-
+    
     try:
         params = {
             'query': f"search:{id}",
             'offset': 0,
             'rows': 10000,
             'fl': 'sha256',
             'as_obj': False,
@@ -401,28 +404,28 @@
         multi_fields = ['filters']
         if request.method == "POST":
             req_data = request.json
             params.update({k: req_data.get(k, None) for k in multi_fields if req_data.get(k, None) is not None})
         else:
             req_data = request.args
             params.update({k: req_data.getlist(k, None) for k in multi_fields if req_data.get(k, None) is not None})
-
+            
         fields = ["query", "offset", "rows", "sort", "fl", 'track_total_hits']
         params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
 
         return make_api_response(STORAGE.file.search(**params))
     except SearchException as e:
         return make_api_response("", f"SearchException: {e}", 400)
 
 
 @retrohunt_api.route("/errors/<code>/", methods=["GET", "POST"])
 @api_login(require_role=[ROLES.retrohunt_view])
 def get_retrohunt_job_errors(code, **kwargs):
     """
-    Get warnings and errors of a retrohunt job completed or in progress.
+    Get errors of a retrohunt job completed or in progress.
 
     Variables:
         code                    =>  Search code of the retrohunt job to be retrieved
 
     Optional Arguments:
         offset                  =>  Offset at which we start giving error messages
         rows                    =>  Number of error messages to return
@@ -433,71 +436,61 @@
         "offset": "0",          =>  Offset at which we start giving error messages
         "rows": "25",           =>  Number of error messages to return
         "sort": "asc",          =>  How to sort the error messages
     }
 
     Response Fields:
     {
-        "total": 200,           #   Total warnings and errors found
+        "total": 200,           #   Total errors found
         "offset": 0,            #   Offset in the error list
-        "rows": 100,            #   Number of warnings and errors returned
-        "items": [              #   List of warnings and errors
+        "rows": 100,            #   Number of errors returned
+        "items": [              #   List of errors
             "File not available: channel closed",
             ...
         ]
     }
     """
     user = kwargs['user']
 
     # Make sure retrohunt is configured
     if haunted_house_client is None:
         return make_api_response({}, err="retrohunt not configured for this system", status_code=501)
 
     # Get the latest retrohunt job information from both Elasticsearch and HauntedHouse
-    doc = STORAGE.retrohunt.get(code, as_obj=False)
+    doc = STORAGE.retrohunt.get(code)
 
     # Make sure the user has the right classification to access this retrohunt job
     if doc is None:
         return make_api_response({}, err="Not Found.", status_code=404)
-
-    if not user or not CLASSIFICATION.is_accessible(user['classification'], doc['classification']):
+    if not CLASSIFICATION.is_accessible(user['classification'], doc['classification']):
         return make_api_response({}, err="Access denied.", status_code=403)
 
     if request.method == "POST":
         req_data = request.json
     else:
         req_data = request.args
 
-    errors = [{'type': 'error', 'message': item} for item in doc['errors']] + \
-             [{'type': 'warning', 'message': item} for item in doc['warnings']]
-
+    errors = doc['errors']
     offset = int(req_data.get('offset', 0))
     rows = int(req_data.get('rows', 20))
 
     if errors is None:
         return {
             'offset': offset,
             'rows': rows,
             'total': None,
             'items': []
         }
 
     sort = req_data.get('sort', None)
     if sort is not None:
-        field = None
-        if 'type' in sort:
-            field = 'type'
-        elif 'message' in sort:
-            field = 'message'
-
-        if field is not None:
-            if 'asc' in sort.lower():
-                errors = sorted(errors, key=lambda e: e[field])
-            elif 'desc' in sort.lower():
-                errors = sorted(errors, key=lambda e: e[field], reverse=True)
+        if 'asc' in sort.lower():
+            errors.sort()
+        elif 'desc' in sort.lower():
+            errors.sort(reverse=True)
 
     return make_api_response({
         'offset': offset,
         'rows': rows,
         'total': len(errors),
         'items': errors[offset:offset + rows]
     })
@@ -536,18 +529,18 @@
     # Make sure retrohunt is configured
     if haunted_house_client is None:
         return make_api_response({}, err="retrohunt not configured for this system", status_code=501)
 
     doc = STORAGE.retrohunt.get(id, as_obj=False)
     if doc is None:
         return make_api_response({}, err="Not Found.", status_code=404)
-
+    
     if not user or not CLASSIFICATION.is_accessible(user['classification'], doc['classification']):
         return make_api_response({}, err="Access denied.", status_code=403)
-
+    
     try:
         params = {
             'query': f"search:{id}",
             'offset': 0,
             'rows': 10000,
             'fl': 'sha256',
             'as_obj': False,
```

## assemblyline_ui/api/v4/service.py

```diff
@@ -253,15 +253,15 @@
 
             if not tmp_data['docker_config'].get('registry_type'):
                 tmp_data['docker_config']['registry_type'] = config.services.preferred_registry_type
 
             # Create a Service object
             tmp_service = Service(tmp_data)
 
-            _, tag_name, _ = get_latest_tag_for_service(tmp_service, config, LOGGER)
+            _, tag_name, _, os = get_latest_tag_for_service(tmp_service, config, LOGGER)
             enable_allowed = bool(tag_name)
             tag_name = tag_name.encode() if tag_name else b'latest'
 
             # Ensure any updates to Service's docker_config details get propagated
             tmp_data['docker_config'].update(tmp_service.docker_config.as_primitives())
             tmp_data.update(non_service_fields)
             data = json.dumps(tmp_data).encode()
@@ -285,20 +285,28 @@
                     "", err=f"Default and value mismatch for submission param: {sp['name']}", status_code=400)
 
         # Apply default global configurations (if absent in service configuration)
         if not service.get('update_channel'):
             service['update_channel'] = config.services.preferred_update_channel
         if not service.get('docker_config', {}).get('registry_type'):
             service['docker_config']['registry_type'] = config.services.preferred_registry_type
+        if not service.get('docker_config', {}).get('operating_system'):
+            service['docker_config']['operating_system'] = os
 
         # Privilege can be set explicitly but also granted to services that don't require the file for analysis
         service['privileged'] = service.get('privileged', config.services.prefer_service_privileged)
 
-        for dep in service.get('dependencies', {}).values():
+        for name, dep in service.get('dependencies', {}).items():
             dep['container']['registry_type'] = dep.get('registry_type', config.services.preferred_registry_type)
+            if not dep['container'].get('operating_system'):
+                # Mock a service config to get the operating system details
+                _, _, _, os = get_latest_tag_for_service(Service({'name': {f"{service['name']}_dep_{name}"},
+                                                                  'version': "0",
+                                                                  'docker_config': dep['container']}), config, LOGGER)
+                dep['container']['operating_system'] = os
         service['enabled'] = service['enabled'] and enable_allowed
 
         # Load service info
         service = Service(service)
 
         # Ensure service classification is at a minimum the default_result_classification
         service.classification = Classification.max_classification(
```

## assemblyline_ui/api/v4/submission.py

```diff
@@ -4,17 +4,16 @@
 from werkzeug.exceptions import BadRequest
 
 from assemblyline.datastore.exceptions import MultiKeyError, SearchException
 from assemblyline.datastore.collection import Index
 from assemblyline.odm.models.user import ROLES
 from assemblyline_core.dispatching.client import DispatchClient
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint
-from assemblyline_ui.config import AI_AGENT, STORAGE, LOGGER, FILESTORE, config, \
-    CLASSIFICATION as Classification, AI_CACHE
-from assemblyline_ui.helper.ai.base import APIException, EmptyAIResponse
+from assemblyline_ui.config import STORAGE, LOGGER, FILESTORE, config, CLASSIFICATION as Classification, AI_CACHE
+from assemblyline_ui.helper.ai import EmptyAIResponse, APIException, detailed_al_submission, summarized_al_submission
 from assemblyline_ui.helper.result import cleanup_heuristic_sections, format_result
 from assemblyline_ui.helper.submission import get_or_create_summary
 
 
 SUB_API = 'submission'
 submission_api = make_subapi_blueprint(SUB_API, api_version=4)
 submission_api._doc = "Perform operations on system submissions"
@@ -494,15 +493,14 @@
     Variables:
     sid         => Submission ID to summarize
 
     Arguments:
     archive_only   => Only use the archive data to generate the summary
     detailed       => Do you want the detailed output (Default: False)
     no_cache       => Caching for the output of this API will be disabled
-    with_trace     => Should the AI call return the full trace of the conversation?
 
     Data Block:
     None
 
     Result example:
     {
       "content": < THE AI SUMMARY IN MARKDOWN FORMAT >,
@@ -513,48 +511,45 @@
     """
     if not config.ui.ai.enabled:
         return make_api_response({}, "AI Support is disabled on this system.", 400)
 
     archive_only = request.args.get('archive_only', 'false').lower() in ['true', '']
     detailed = request.args.get('detailed', 'false').lower() in ['true', '']
     no_cache = request.args.get('no_cache', 'false').lower() in ['true', '']
-    lang = request.args.get('lang', 'english')
-    with_trace = request.args.get('with_trace', 'false').lower() in ['true', '']
 
     index_type = None
     if archive_only:
         if not config.datastore.archive.enabled:
             return make_api_response({}, "Archive Support is disabled on this system.", 400)
         index_type = Index.ARCHIVE
 
     user = kwargs['user']
 
     if archive_only and ROLES.archive_view not in user['roles']:
         return make_api_response({}, "User is not allowed to view the archive", 403)
 
     # Create the cache key
-    cache_key = AI_CACHE.create_key(sid, user['classification'], index_type,
-                                    archive_only, detailed, lang, with_trace, "submission")
+    cache_key = AI_CACHE.create_key(sid, user['classification'], index_type, archive_only, detailed, "submission")
     ai_summary = None
     if (not no_cache):
         # Get the summary from cache
         ai_summary = AI_CACHE.get(cache_key)
 
     if not ai_summary:
         data = STORAGE.get_ai_formatted_submission_data(
             sid, user_classification=user['classification'],
             cl_engine=Classification, index_type=index_type)
         if data is None:
             return make_api_response("", "Submission ID %s does not exists." % sid, 404)
 
         try:
             if detailed:
-                ai_summary = AI_AGENT.detailed_al_submission(data, lang=lang, with_trace=with_trace)
+                ai_summary = detailed_al_submission(data)
             else:
-                ai_summary = AI_AGENT.summarized_al_submission(data, lang=lang, with_trace=with_trace)
+                ai_summary = summarized_al_submission(data)
 
             # Save to cache
             AI_CACHE.set(cache_key, ai_summary)
         except (APIException, EmptyAIResponse) as e:
             return make_api_response("", str(e), 400)
 
     return make_api_response(ai_summary)
```

## assemblyline_ui/api/v4/submit.py

```diff
@@ -13,15 +13,15 @@
 from assemblyline.common.str_utils import safe_str
 from assemblyline.common.uid import get_random_id
 from assemblyline.odm.messages.submission import Submission
 from assemblyline.odm.models.user import ROLES
 from assemblyline_core.submission_client import SubmissionClient, SubmissionException
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint
 from assemblyline_ui.config import ARCHIVESTORE, STORAGE, TEMP_SUBMIT_DIR, FILESTORE, config, \
-    CLASSIFICATION as Classification, IDENTIFY, metadata_validator
+    CLASSIFICATION as Classification, IDENTIFY
 from assemblyline_ui.helper.service import ui_to_submission_params
 from assemblyline_ui.helper.submission import download_from_url, FileTooBigException, submission_received, refang_url
 from assemblyline_ui.helper.user import check_submission_quota, decrement_submission_quota, load_user_settings
 
 SUB_API = 'submit'
 submit_api = make_subapi_blueprint(SUB_API, api_version=4)
 submit_api._doc = "Submit files to the system"
@@ -429,19 +429,14 @@
         if not s_params['description']:
             s_params['description'] = default_description
 
         try:
             metadata = flatten(data.get('metadata', {}))
             metadata.update(extra_meta)
 
-            # Validate the metadata
-            metadata_error = metadata_validator.check_metadata(metadata)
-            if metadata_error:
-                return make_api_response({}, err=metadata_error[1], status_code=400)
-
             submission_obj = Submission({
                 "files": [],
                 "metadata": metadata,
                 "params": s_params
             })
         except (ValueError, KeyError) as e:
             return make_api_response("", err=str(e), status_code=400)
```

## assemblyline_ui/api/v4/user.py

```diff
@@ -160,20 +160,14 @@
     user_data['configuration'] = {
         "auth": {
             "allow_2fa": config.auth.allow_2fa,
             "allow_apikeys": config.auth.allow_apikeys,
             "allow_extended_apikeys": config.auth.allow_extended_apikeys,
             "allow_security_tokens": config.auth.allow_security_tokens,
         },
-        "core": {
-            "archiver": {
-                "metadata": {k: v.as_primitives() for k, v in config.core.archiver.metadata.items()},
-                "use_metadata": config.core.archiver.use_metadata
-            }
-        },
         "datastore": {
             "archive": {
                 "enabled": config.datastore.archive.enabled
             }
         },
         "retrohunt": {
             "enabled": config.retrohunt.enabled,
@@ -196,18 +190,15 @@
         "system": {
             "organisation": config.system.organisation,
             "type": config.system.type,
             "version": VERSION
         },
         "ui": {
             "ai": {
-                "enabled": config.ui.ai.enabled,
-                "assistant": {
-                    "system_message": config.ui.ai.assistant.system_message
-                }
+                "enabled": config.ui.ai.enabled
             },
             "alerting_meta": {
                 "important": config.ui.alerting_meta.important,
                 "subject": config.ui.alerting_meta.subject,
                 "url": config.ui.alerting_meta.url
             },
             "allow_malicious_hinting": config.ui.allow_malicious_hinting,
```

## assemblyline_ui/helper/__init__.py

```diff
@@ -0,0 +1 @@
+00000000: 0a                                       .
```

## assemblyline_ui/helper/oauth.py

```diff
@@ -143,26 +143,14 @@
                     group_match = re.match(auto_prop.pattern, value)
                     if group_match:
                         for group_value in auto_prop.value:
                             for index, gm_value in enumerate(group_match.groups()):
                                 group_value = group_value.replace(f"${index+1}", gm_value)
                             groups.append(group_value)
 
-                # Append multiple groups from a single matching pattern
-                elif auto_prop.type == "multi_group":
-                    all_matches = re.findall(auto_prop.pattern, value)
-                    for group_match in all_matches:
-                        for group_value in auto_prop.value:
-                            if not isinstance(group_match, list):
-                                group_match = [group_match]
-                            for index, gm_value in enumerate(group_match):
-                                group_value = group_value.replace(f"${index+1}", gm_value)
-                            if group_value not in groups:
-                                groups.append(group_value)
-
     # if not user type was assigned
     if not user_type:
         # if also no roles were assigned
         if not roles:
             # Set the default user type
             user_type = ['user']
         else:
```

## assemblyline_ui/helper/search.py

```diff
@@ -46,15 +46,15 @@
     'file': "seen.last desc",
     'heuristic': "heur_id asc",
     'result': "created desc",
     'signature': "type asc",
     'submission': "times.submitted desc",
     'safelist': "added desc",
     'workflow': "last_seen desc",
-    'retrohunt': "created_time desc",
+    'retrohunt': "created desc",
 }
 
 
 def list_all_fields(user=None):
     fields_map = {k: INDEX_MAP[k].fields() for k in INDEX_MAP.keys()}
 
     if user and user['is_admin']:
```

## assemblyline_ui/helper/service.py

```diff
@@ -85,14 +85,13 @@
         params['services'] = {'selected': simplify_services(params["services"])}
 
     params['ttl'] = int(params.get('ttl', config.submission.dtl))
 
     # Remove UI specific params
     params.pop('default_zip_password', None)
     params.pop('download_encoding', None)
-    params.pop('executive_summary', None)
     params.pop('expand_min_score', None)
     params.pop('submission_view', None)
     params.pop('ui4', None)
     params.pop('ui4_ask', None)
 
     return params
```

## assemblyline_ui/sio/retrohunt.py

```diff
@@ -1,11 +1,11 @@
 from flask_socketio import join_room
-from assemblyline.common.forge import get_hauntedhouse_client
 
 from assemblyline_ui.sio.base import LOGGER, datastore, classification, config, SecureNamespace, authenticated_only
+from assemblyline_ui.helper.retrohunt import get_hauntedhouse_client
 
 
 haunted_house_client = get_hauntedhouse_client(config)
 
 
 class RetrohuntNamespace(SecureNamespace):
     def __init__(self, namespace=None):
```

## Comparing `assemblyline_ui-4.5.1.dev76.dist-info/LICENCE.md` & `assemblyline_ui-4.5.1.dev8.dist-info/LICENCE.md`

 * *Files identical despite different names*

## Comparing `assemblyline_ui-4.5.1.dev76.dist-info/METADATA` & `assemblyline_ui-4.5.1.dev8.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: assemblyline-ui
-Version: 4.5.1.dev76
+Version: 4.5.1.dev8
 Summary: Assemblyline 4 - API and Socket IO server
 Home-page: https://github.com/CybercentreCanada/assemblyline-ui/
 Author: CCCS Assemblyline development team
 Author-email: assemblyline@cyber.gc.ca
 License: MIT
 Keywords: assemblyline automated malware analysis gc canada cse-cst cse cst cyber cccs
 Classifier: Development Status :: 5 - Production/Stable
@@ -26,14 +26,15 @@
 Requires-Dist: markdown
 Requires-Dist: python-ldap
 Requires-Dist: authlib <1.0.0
 Requires-Dist: fido2 <1.0.0
 Requires-Dist: PyJWT
 Requires-Dist: gunicorn
 Requires-Dist: gevent
+Requires-Dist: hauntedhouse ==0.1.4
 Provides-Extra: socketio
 Requires-Dist: python-socketio ; extra == 'socketio'
 Requires-Dist: flask-socketio ; extra == 'socketio'
 Requires-Dist: gevent-websocket ; extra == 'socketio'
 Provides-Extra: test
 Requires-Dist: pytest ; extra == 'test'
 Requires-Dist: pytest-mock ; extra == 'test'
```

## Comparing `assemblyline_ui-4.5.1.dev76.dist-info/RECORD` & `assemblyline_ui-4.5.1.dev8.dist-info/RECORD`

 * *Files 19% similar despite different names*

```diff
@@ -1,77 +1,74 @@
-assemblyline_ui/VERSION,sha256=iqWsiCUB4qG6Ft4zqwxt5BpBP0Cew2wVsHSog45Go9Y,12
+assemblyline_ui/VERSION,sha256=vOZcm5VwouAZxLcIFar44guiJDMF80lns5xK0hj2a3Q,11
 assemblyline_ui/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-assemblyline_ui/app.py,sha256=9JB-hkhReF2jLUUMe3F01dvN9i2HnRFGydvQCXBkE1U,6736
-assemblyline_ui/config.py,sha256=o5V97C6WbfzXbwtrhR8k04G20q_NdnFn70MdYxvgsYA,5957
+assemblyline_ui/app.py,sha256=PVbgHTis_1qk6y37Jy5piYUArhBdllXopzVwNHWO-Pk,6606
+assemblyline_ui/config.py,sha256=xxySKtsanrcYkzzNn1SI3UWNJbI1L2mWGlBHQvFmNe4,5709
 assemblyline_ui/error.py,sha256=vqP9pT375oQSoWy2mMR2pNxz2YzBthpO0icxW2oO_YU,3690
 assemblyline_ui/gunicorn_config.py,sha256=qm2Ehn9nY_yH6Klp2acYFZ9jC7St9hSmXIW42WRXbc4,740
 assemblyline_ui/gunicorn_config_socketio.py,sha256=WWAWzrZOw1OXEiV_nNMKf-wH6A0Ckio2juCYWu-QfAE,115
 assemblyline_ui/healthz.py,sha256=IFr2ofSddFX8pvoixMmZHSlk364oKD_vURl_GRT6J2s,777
 assemblyline_ui/http_exceptions.py,sha256=5DvpspLyuE6fQfR6mpPmQiFDXahr2vr3uuTp7S9Guy8,199
 assemblyline_ui/logger.py,sha256=dgaAzJc39ajD1e3hipc291zqcHyCXMgdDSLzz6V-Jus,2322
 assemblyline_ui/patched.py,sha256=EkYqCoW64CuZvrZjE7xNwZ9bTaiVfwuYBbVUR64g42A,85
 assemblyline_ui/socketsrv.py,sha256=4u8oVCt9iONC15wy1jlf6VJ6LR0zoPstcLHl9g_YaQA,2596
 assemblyline_ui/api/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_ui/api/base.py,sha256=tDEgJ61_CzCdY8P7CWqN2aK-qqEuoHNktFHmhY_Bopg,14502
 assemblyline_ui/api/v4/__init__.py,sha256=5sJInJQ7GM-6LTIOvTPFBHE1u-kf562MjjbzX0ZBuDg,3915
-assemblyline_ui/api/v4/alert.py,sha256=XsOATBo5TZb5lhS1h34Pna-RLAZIUpk2WK_0sJ-wesI,37510
-assemblyline_ui/api/v4/archive.py,sha256=mQn0tLEAXUt9SaWN5W9QyWjm8BCln9dPozDQf7tr-Yk,24904
-assemblyline_ui/api/v4/assistant.py,sha256=2GjmY09JRbAZ-ISF73Y2XyEFwKt5a1N3GeFWDFw8oEE,1866
+assemblyline_ui/api/v4/alert.py,sha256=m-uCtYwfQ7mfl9aGzerSkN4mUcxKfi5msumSiJzhJ-w,34480
+assemblyline_ui/api/v4/archive.py,sha256=TgAcq5UyH_MsFGkLEK-KYUPEWqwdIymNnkb4VNqTEIs,24438
 assemblyline_ui/api/v4/authentication.py,sha256=bcTZOCC2LdJcoA9pOgT9YNWaHhSxZzBVO_IZNVUEvSw,33569
 assemblyline_ui/api/v4/badlist.py,sha256=VTo9r7yVQDb52I9l4-iukP47sRB0ac9P38NAtkAGnXs,32455
 assemblyline_ui/api/v4/bundle.py,sha256=XCxILxICh8eZfkbOC0fYW_v2pdl7n-US24qYEW5_RrA,5141
 assemblyline_ui/api/v4/error.py,sha256=rITm-0yrZYidetWqlJUmwyHEyF6kML5Ta3c0gT-L7M4,2560
 assemblyline_ui/api/v4/federated_lookup.py,sha256=lvINN57_oDn7bMep8PvwL4PqBnRMg16DOWTis81U5Y8,12508
-assemblyline_ui/api/v4/file.py,sha256=cCnl1_jic-a7qlgpkAcUud7b_uDlfZDmw8MsW9yv4lI,55854
-assemblyline_ui/api/v4/hash_search.py,sha256=T-otDhWdfR7m7c505S0MwFMe6CmKYyTfTnMnpgccJx4,11900
+assemblyline_ui/api/v4/file.py,sha256=WWlPYcIky4l7c51z5_3OVY7yRvPaqT4eFnCogpB7Xhs,55345
+assemblyline_ui/api/v4/hash_search.py,sha256=mG-llLVrfuOsYnKrppD_y7hX2wlNBxnz2ZURw1jPpWQ,11452
 assemblyline_ui/api/v4/help.py,sha256=4_C82EW4Cu9XPor9pMIPB7v_0uIFZ1TG2PX1nMNm2ck,6367
 assemblyline_ui/api/v4/heuristics.py,sha256=YfTUmDYrilwdNO1Dlr0qfDRTU4fOhPpSCWARLjt1auo,2910
-assemblyline_ui/api/v4/ingest.py,sha256=SnmTgqypf4Jvnro32stGajbEyl9rUGEhdUC1G1B8o_I,20441
+assemblyline_ui/api/v4/ingest.py,sha256=NX1vgo6UISdJXYJXaZ34ZubfgQBnZqU9tXmrrI-VYOM,19980
 assemblyline_ui/api/v4/live.py,sha256=4gz8-zbkTnLWBg2OH-AmRIolBZokDjweOZgaw1I3j3U,5477
 assemblyline_ui/api/v4/ontology.py,sha256=M9fSWDZshgsI8SkNEJmwfK0cR3O7OwHryhpi14kqz7k,13223
 assemblyline_ui/api/v4/replay.py,sha256=LF1kUSzTZQGwgNhKy_GpJVxi66dBrKRFfiHiDAJCbY4,7985
 assemblyline_ui/api/v4/result.py,sha256=XJPUZPdVD1SK7kwppKzFvqGngmdRr0ei6qV0Ppl-c14,6203
-assemblyline_ui/api/v4/retrohunt.py,sha256=ScKnj2x5kwJJPOye7bhNxeoBLijgnVdeohCJribWArI,23121
+assemblyline_ui/api/v4/retrohunt.py,sha256=Rpi4ebE9uW3l_dPf-2qbuL_ajXHcLK9gYEPQEUm0KJ8,23028
 assemblyline_ui/api/v4/safelist.py,sha256=gB-kU-sirRKE29DJL10kQIzX_MtZbz8BoxFVPenel4M,23196
 assemblyline_ui/api/v4/search.py,sha256=_PfLQJxVRHOW1j68h9Y6uey3dGKlI_zsXY03IOX22fk,20528
-assemblyline_ui/api/v4/service.py,sha256=QRQ77nVRsaveYAa7MH-LxS88wXoePeh0B3SFv8LvxD8,39389
+assemblyline_ui/api/v4/service.py,sha256=nOw0K7aaTTkWq6Yw_JqOUkQ8BNaVnac6XwIBcXrmKRM,40038
 assemblyline_ui/api/v4/signature.py,sha256=nMqnNYpmQm_-GZI79jmUd05-Zy3dGBJ3Y1hv8hX8stQ,26966
-assemblyline_ui/api/v4/submission.py,sha256=1BRWCXqhIO6xaRWhOi7vILISo_HHVMOv9922bTjb0-g,46126
-assemblyline_ui/api/v4/submit.py,sha256=TEg3E0rMaMF3VxR4PRc297aBBdh6H6Q3OKc_o4Wuqgs,20443
+assemblyline_ui/api/v4/submission.py,sha256=VgMhICCAtIaoB6kdSEL0ZvpJudQVEBvcwW-35n8Tzd0,45803
+assemblyline_ui/api/v4/submit.py,sha256=tjrszQpduq5_4EXk-ee29xCon2wvapKTE1HcEed7aJ8,20197
 assemblyline_ui/api/v4/system.py,sha256=Hl1BElnJELpp6paTVrNptTEENxlk2RA5bEKBDStuPpE,20730
 assemblyline_ui/api/v4/ui.py,sha256=nMvm8N51rO2oj_ZB8qQu19jF4S-46-3HVMypzcF49mI,11728
-assemblyline_ui/api/v4/user.py,sha256=8hO08OT9dTZA5JKzRKy3h_O_ZY-dCngtARlLF1opn3Y,40316
+assemblyline_ui/api/v4/user.py,sha256=dEN_bw70kuLe8UtJqAD3KmWy1oQ9gVjU3FsdV0tfKI0,39953
 assemblyline_ui/api/v4/webauthn.py,sha256=FxuvXScYiMdgA-ZvojGf7CfQq4C2W8e3dWLxo7W0bx4,4734
 assemblyline_ui/api/v4/workflow.py,sha256=52r5NLh2NL0J1PKD8qfN0lHvoxBhwzCbRhqx_gJDFnM,10308
-assemblyline_ui/helper/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+assemblyline_ui/helper/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+assemblyline_ui/helper/ai.py,sha256=lMqbBWslMOmEQgbrwS7WPyVYwTDH5ZSeEjLI2OJc8w4,2224
 assemblyline_ui/helper/discover.py,sha256=oJBML1dQl0H2Ic-lm5jI4YWIpm9RRW-mGT5sP-2tb9c,1686
-assemblyline_ui/helper/oauth.py,sha256=D_1f6jd0rhwwMXi4qAieFcqAIpWXOb82oeZr0Zds3lI,8154
+assemblyline_ui/helper/oauth.py,sha256=kSLkbBOCFaW04VU7m8YvTzX5HaPn-uAHyqqUSJZ3Xvw,7435
 assemblyline_ui/helper/result.py,sha256=u79F3IKN1EcVOkfk1CvQNEwbIWyiq9Wj8OHp3zuwmBc,4926
-assemblyline_ui/helper/search.py,sha256=QdzHgQCzpLCcq2N2auGAK9GDWC3B3V51Vey-BjGRZ6M,1686
-assemblyline_ui/helper/service.py,sha256=75kdOvWBprCi9h42FtoxDUsuKhnD-rh4f3W-y3q8RU0,3260
+assemblyline_ui/helper/retrohunt.py,sha256=1vH19zkNiGscBRJPDal4iCDkZThyKWnYFYoWP-uUuKg,500
+assemblyline_ui/helper/search.py,sha256=qk0x9rsIHrD4th71t2xKFcYXQ0UOqRSm0gyGx-nyZsQ,1681
+assemblyline_ui/helper/service.py,sha256=UBytaOh0IFZVH9sYFdvOqAC2W2XOsQcUruhJbpc2vlM,3218
 assemblyline_ui/helper/signature.py,sha256=PUiQk56QoY5Ye2Pg3jRNgOT2i2ZqTWkk_0dv-Bfy9vI,899
 assemblyline_ui/helper/submission.py,sha256=P4Ff9ps_nUzHxBE7486_xbyUNuXTvOYU3aWdK8VyBOY,6835
 assemblyline_ui/helper/user.py,sha256=40ze4dNudQR-TLgf5CB1_x_Iu-5bsRiu4gVTDvsktxw,7628
-assemblyline_ui/helper/ai/__init__.py,sha256=p86bsguyeRSC1YJXiMjS-dbMhpjQx8gJvvF5cRrN_As,443
-assemblyline_ui/helper/ai/base.py,sha256=krqblQE_CmV4ExOSu9lfR8EPKIIFPlpZ5wNLtgGxBIY,895
-assemblyline_ui/helper/ai/cohere.py,sha256=2PHpJKNOXQTg8TCjdyNNKg4tKcKTYe_KougCSVx5sS0,5569
-assemblyline_ui/helper/ai/openai.py,sha256=hjxA8hz89AVGwB0shGmY6J2GXPV0fGAVayjy-s5M30s,5267
 assemblyline_ui/security/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_ui/security/apikey_auth.py,sha256=TDESuSgEEkxWZEm2X0vW1t96uWXMKCvAeJBaXnzZKQc,1410
 assemblyline_ui/security/authenticator.py,sha256=Pjuo6VL2QrI4YL1NDAAxURv_8CYo7bwbNbDhOkLiphk,10116
 assemblyline_ui/security/ldap_auth.py,sha256=2HQh3krpPSRRCLVfow_JP_TERNeV6YLtpXOXGNzFm9Q,13749
 assemblyline_ui/security/oauth_auth.py,sha256=hfyOxNacDSh0OuovDzclsi4eCzk08-h1Y10V4QF-O_0,3074
 assemblyline_ui/security/second_factor_auth.py,sha256=GiJNoL_CjDPAHml0VdcK46GfYzkqYuAkOdW9PIorXYs,2951
 assemblyline_ui/security/userpass_auth.py,sha256=vfG9K_jpdigpZolUmkc_cEtfZ5DgPdLW7V5g68CAsVA,750
 assemblyline_ui/sio/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_ui/sio/alert.py,sha256=aTtrkZW21igbP6UcFgo1_fXdF8RpCBlMiKsNdpwItZw,2170
 assemblyline_ui/sio/base.py,sha256=TLSoCLqxvSEFuggmCscnzAY1E60rweIIZLr0ai8jm5M,3529
 assemblyline_ui/sio/file.py,sha256=UMtE7mE7EcbG6KN8HBMQSvv5N7PILCq8nVnrngOnBso,2041
 assemblyline_ui/sio/live_submission.py,sha256=mS0oGO5rEA8PLa8kjBcodOG-Q0CG4SpYAoi8bz9_PCw,4158
-assemblyline_ui/sio/retrohunt.py,sha256=vlH_x6Rb4pm3GM1sNLH1C42-NVR3VoAsEfkAu3L30fY,2146
+assemblyline_ui/sio/retrohunt.py,sha256=OYJl_alv4u7507Ac4EWOrGJytV9f_J2FS3KQyTEX22A,2153
 assemblyline_ui/sio/status.py,sha256=_Bxf1KLPOJEUIk4J9_j9fzvQWUXqSIT9xnJKhT1hhuc,1980
 assemblyline_ui/sio/submission.py,sha256=IYJuGz73HK9HtYfqc-gWW8tc1lt5VZ62Qn64AaGGtm8,2222
-assemblyline_ui-4.5.1.dev76.dist-info/LICENCE.md,sha256=NSkYo9EH8h5oOkzg4VhjAHF4339MqPP2cQ8msTPgl-c,1396
-assemblyline_ui-4.5.1.dev76.dist-info/METADATA,sha256=C1S8wW-yKL9DqQPjKCluGEkn0uCt8E3B_Nm6Pj_sDws,2898
-assemblyline_ui-4.5.1.dev76.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-assemblyline_ui-4.5.1.dev76.dist-info/top_level.txt,sha256=WLa7-PKLJTbMUbKKU3q3kg5_uAV67hss5kC71PAbIeg,16
-assemblyline_ui-4.5.1.dev76.dist-info/RECORD,,
+assemblyline_ui-4.5.1.dev8.dist-info/LICENCE.md,sha256=NSkYo9EH8h5oOkzg4VhjAHF4339MqPP2cQ8msTPgl-c,1396
+assemblyline_ui-4.5.1.dev8.dist-info/METADATA,sha256=x9HoE3whbCY1WaC_0nh4V-m6uQLs-RUwtqDM2xRSqC4,2933
+assemblyline_ui-4.5.1.dev8.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+assemblyline_ui-4.5.1.dev8.dist-info/top_level.txt,sha256=WLa7-PKLJTbMUbKKU3q3kg5_uAV67hss5kC71PAbIeg,16
+assemblyline_ui-4.5.1.dev8.dist-info/RECORD,,
```

