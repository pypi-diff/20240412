# Comparing `tmp/atorch-0.1.7-py3-none-any.whl.zip` & `tmp/atorch-0.1.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,34 +1,34 @@
-Zip file size: 524275 bytes, number of entries: 250
+Zip file size: 578430 bytes, number of entries: 289
 -rw-r--r--  2.0 unx      958 b- defN 24-Jan-18 02:35 atorch/__init__.py
 -rw-r--r--  2.0 unx      255 b- defN 23-Dec-20 06:58 atorch/amp/__init__.py
 -rw-r--r--  2.0 unx     3412 b- defN 23-Dec-20 06:58 atorch/amp/amp.py
 -rw-r--r--  2.0 unx      868 b- defN 23-Dec-20 06:58 atorch/amp/hook.py
 -rw-r--r--  2.0 unx    12488 b- defN 23-Dec-20 06:58 atorch/amp/pipe_amp.py
 -rw-r--r--  2.0 unx       83 b- defN 24-Jan-17 06:24 atorch/auto/__init__.py
--rw-r--r--  2.0 unx    28475 b- defN 24-Jan-18 02:35 atorch/auto/accelerate.py
+-rw-r--r--  2.0 unx    28847 b- defN 24-Apr-10 08:59 atorch/auto/accelerate.py
 -rw-r--r--  2.0 unx     1095 b- defN 24-Jan-17 06:24 atorch/auto/auto_accelerate_context.py
 -rw-r--r--  2.0 unx    13550 b- defN 24-Jan-17 06:24 atorch/auto/clip_grad_norm.py
 -rw-r--r--  2.0 unx     6456 b- defN 24-Jan-17 06:24 atorch/auto/device_context.py
 -rw-r--r--  2.0 unx     2480 b- defN 24-Jan-17 06:24 atorch/auto/engine_client.py
--rw-r--r--  2.0 unx    37719 b- defN 24-Jan-18 02:35 atorch/auto/model_context.py
--rw-r--r--  2.0 unx     4214 b- defN 24-Jan-17 06:24 atorch/auto/strategy.py
+-rw-r--r--  2.0 unx    37647 b- defN 24-Apr-10 08:59 atorch/auto/model_context.py
+-rw-r--r--  2.0 unx     4803 b- defN 24-Apr-10 08:59 atorch/auto/strategy.py
 -rw-r--r--  2.0 unx      468 b- defN 24-Jan-17 06:24 atorch/auto/task.py
 -rw-r--r--  2.0 unx       31 b- defN 24-Jan-17 06:24 atorch/auto/analyser/__init__.py
 -rw-r--r--  2.0 unx    12008 b- defN 24-Jan-17 06:24 atorch/auto/analyser/analyser.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/dry_runner/__init__.py
 -rw-r--r--  2.0 unx     6435 b- defN 24-Jan-17 06:24 atorch/auto/dry_runner/dry_runner.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/__init__.py
 -rw-r--r--  2.0 unx     3241 b- defN 24-Jan-17 06:24 atorch/auto/engine/acceleration_engine.py
 -rw-r--r--  2.0 unx      948 b- defN 24-Jan-17 06:24 atorch/auto/engine/analyser_result.py
 -rw-r--r--  2.0 unx     3064 b- defN 24-Jan-17 06:24 atorch/auto/engine/client.py
 -rw-r--r--  2.0 unx    11304 b- defN 24-Jan-17 06:24 atorch/auto/engine/executor.py
 -rw-r--r--  2.0 unx     6810 b- defN 24-Jan-17 06:24 atorch/auto/engine/optimization_method.py
 -rw-r--r--  2.0 unx     4587 b- defN 24-Jan-17 06:24 atorch/auto/engine/planner.py
--rw-r--r--  2.0 unx     3019 b- defN 24-Jan-17 06:24 atorch/auto/engine/servicer.py
+-rw-r--r--  2.0 unx     3035 b- defN 24-Apr-10 08:59 atorch/auto/engine/servicer.py
 -rw-r--r--  2.0 unx     6306 b- defN 24-Jan-17 06:24 atorch/auto/engine/strategy.py
 -rw-r--r--  2.0 unx     1693 b- defN 24-Jan-17 06:24 atorch/auto/engine/task.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/__init__.py
 -rw-r--r--  2.0 unx     5713 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/bayes_opt_sg.py
 -rw-r--r--  2.0 unx     2271 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/combination_sg.py
 -rw-r--r--  2.0 unx      896 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/sg_algo_lib.py
 -rw-r--r--  2.0 unx      886 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/sg_algorithm.py
@@ -37,44 +37,44 @@
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/acq_optimizers/__init__.py
 -rw-r--r--  2.0 unx     5851 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/acq_optimizers/evolution_optimizer.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/acquisitions/__init__.py
 -rw-r--r--  2.0 unx     3395 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/acquisitions/acq.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/design_space/__init__.py
 -rw-r--r--  2.0 unx     1434 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/design_space/categorical_param.py
 -rw-r--r--  2.0 unx     3119 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/design_space/design_space.py
--rw-r--r--  2.0 unx     1055 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/design_space/param.py
+-rw-r--r--  2.0 unx     1063 b- defN 24-Apr-10 08:59 atorch/auto/engine/sg_algo/hebo/design_space/param.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/__init__.py
 -rw-r--r--  2.0 unx     2105 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/base_model.py
 -rw-r--r--  2.0 unx      666 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/layers.py
 -rw-r--r--  2.0 unx      598 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/model_factory.py
 -rw-r--r--  2.0 unx      541 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/util.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/gauss_process/__init__.py
 -rw-r--r--  2.0 unx     4516 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/gauss_process/gpy_wgp.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/random_forest/__init__.py
 -rw-r--r--  2.0 unx     1815 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/models/random_forest/rf.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/optimizers/__init__.py
 -rw-r--r--  2.0 unx     1174 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/optimizers/abstract_optimizer.py
--rw-r--r--  2.0 unx     8224 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/optimizers/hebo.py
+-rw-r--r--  2.0 unx     8272 b- defN 24-Apr-10 08:59 atorch/auto/engine/sg_algo/hebo/optimizers/hebo.py
 -rw-r--r--  2.0 unx     1608 b- defN 24-Jan-17 06:24 atorch/auto/engine/sg_algo/hebo/optimizers/util.py
 -rw-r--r--  2.0 unx       54 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/__init__.py
--rw-r--r--  2.0 unx    16267 b- defN 24-Jan-18 02:35 atorch/auto/opt_lib/amp_optimization.py
--rw-r--r--  2.0 unx     9604 b- defN 24-Jan-18 02:35 atorch/auto/opt_lib/checkpoint_optimization.py
+-rw-r--r--  2.0 unx    16692 b- defN 24-Apr-10 08:59 atorch/auto/opt_lib/amp_optimization.py
+-rw-r--r--  2.0 unx    10362 b- defN 24-Apr-12 05:44 atorch/auto/opt_lib/checkpoint_optimization.py
 -rw-r--r--  2.0 unx     7195 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/ds_3d_parallel_optimization.py
 -rw-r--r--  2.0 unx      356 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/dynamo_backends.py
 -rw-r--r--  2.0 unx     2639 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/dynamo_optimization.py
 -rw-r--r--  2.0 unx     1856 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/half_optimization.py
 -rw-r--r--  2.0 unx    13786 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/mixed_parallel_optimization.py
 -rw-r--r--  2.0 unx     7217 b- defN 24-Jan-18 02:35 atorch/auto/opt_lib/module_replace_optimization.py
--rw-r--r--  2.0 unx    10708 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/optimization.py
+-rw-r--r--  2.0 unx    10892 b- defN 24-Apr-10 08:59 atorch/auto/opt_lib/optimization.py
 -rw-r--r--  2.0 unx     2787 b- defN 24-Jan-18 02:35 atorch/auto/opt_lib/optimization_library.py
 -rw-r--r--  2.0 unx     2112 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/parallel_mode_optimization.py
 -rw-r--r--  2.0 unx    11721 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/pipeline_parallel_optimization.py
--rw-r--r--  2.0 unx     9840 b- defN 24-Jan-18 02:35 atorch/auto/opt_lib/selective_offloading_checkpoint.py
+-rw-r--r--  2.0 unx    10728 b- defN 24-Apr-10 08:59 atorch/auto/opt_lib/selective_offloading_checkpoint.py
 -rw-r--r--  2.0 unx     7992 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/tensor_parallel_optimization.py
--rw-r--r--  2.0 unx     6182 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/utils.py
+-rw-r--r--  2.0 unx     6182 b- defN 24-Apr-10 08:59 atorch/auto/opt_lib/utils.py
 -rw-r--r--  2.0 unx    22731 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/zero_optimization.py
 -rw-r--r--  2.0 unx      241 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/shard_planners/__init__.py
 -rw-r--r--  2.0 unx     5145 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/shard_planners/base_stage_planner.py
 -rw-r--r--  2.0 unx     9408 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/shard_planners/base_tp_planner.py
 -rw-r--r--  2.0 unx     8974 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/shard_planners/dim_planner.py
 -rw-r--r--  2.0 unx    22977 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/shard_planners/mip_tp_planner.py
 -rw-r--r--  2.0 unx     3471 b- defN 24-Jan-17 06:24 atorch/auto/opt_lib/shard_planners/topology.py
@@ -86,84 +86,91 @@
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/common/file/__init__.py
 -rw-r--r--  2.0 unx      845 b- defN 23-Dec-21 03:00 atorch/common/file/file_io.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/common/file/file_system/__init__.py
 -rw-r--r--  2.0 unx     4991 b- defN 23-Dec-20 06:58 atorch/common/file/file_system/file_system.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/common/file/file_system/pangu/__init__.py
 -rw-r--r--  2.0 unx    13710 b- defN 23-Dec-20 06:58 atorch/common/file/file_system/pangu/fsspec_instance.py
 -rw-r--r--  2.0 unx    17043 b- defN 23-Dec-20 06:58 atorch/common/file/file_system/pangu/pangu_file_system.py
--rw-r--r--  2.0 unx      633 b- defN 24-Jan-18 09:42 atorch/data/__init__.py
+-rw-r--r--  2.0 unx      633 b- defN 24-Jan-22 05:55 atorch/data/__init__.py
 -rw-r--r--  2.0 unx    17310 b- defN 23-Dec-20 06:58 atorch/data/coworker_dataset.py
--rw-r--r--  2.0 unx     1343 b- defN 23-Dec-20 06:58 atorch/data/data_utils.py
+-rw-r--r--  2.0 unx     1347 b- defN 24-Apr-10 08:59 atorch/data/data_utils.py
 -rw-r--r--  2.0 unx    13694 b- defN 23-Dec-21 03:00 atorch/data/elastic_dataloader.py
 -rw-r--r--  2.0 unx     4771 b- defN 23-Dec-20 06:58 atorch/data/elastic_dataset.py
 -rw-r--r--  2.0 unx     6113 b- defN 23-Dec-20 06:58 atorch/data/preloader.py
 -rw-r--r--  2.0 unx    27904 b- defN 23-Dec-20 06:58 atorch/data/shm_context.py
--rw-r--r--  2.0 unx    10185 b- defN 23-Dec-20 06:58 atorch/data/shm_dataloader.py
+-rw-r--r--  2.0 unx    10185 b- defN 24-Apr-10 08:59 atorch/data/shm_dataloader.py
 -rw-r--r--  2.0 unx     3396 b- defN 23-Dec-20 06:58 atorch/data/unordered_dataloader.py
 -rw-r--r--  2.0 unx     1425 b- defN 23-Dec-20 06:58 atorch/data/unshuffled_batch_dataloader.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/data_parallel/__init__.py
 -rw-r--r--  2.0 unx    25559 b- defN 23-Dec-20 06:58 atorch/data_parallel/adp.py
 -rw-r--r--  2.0 unx    13332 b- defN 23-Dec-20 06:58 atorch/data_parallel/auto_wrap.py
 -rw-r--r--  2.0 unx     3562 b- defN 23-Dec-20 06:58 atorch/data_parallel/wrapper.py
 -rw-r--r--  2.0 unx    25890 b- defN 23-Dec-20 06:58 atorch/data_parallel/zero_ddp_mix_112.py
 -rw-r--r--  2.0 unx      261 b- defN 23-Dec-20 06:58 atorch/distributed/__init__.py
--rw-r--r--  2.0 unx    27953 b- defN 23-Dec-21 03:00 atorch/distributed/distributed.py
+-rw-r--r--  2.0 unx    28079 b- defN 24-Apr-10 08:59 atorch/distributed/distributed.py
 -rw-r--r--  2.0 unx      465 b- defN 23-Dec-20 06:58 atorch/distributed/elastic_controller.py
 -rw-r--r--  2.0 unx     3405 b- defN 23-Dec-20 06:58 atorch/distributed/elastic_trainer.py
 -rw-r--r--  2.0 unx     1253 b- defN 23-Dec-21 03:00 atorch/distributed/hooks.py
 -rw-r--r--  2.0 unx    19071 b- defN 23-Dec-21 03:00 atorch/distributed/launch.py
--rw-r--r--  2.0 unx    12408 b- defN 23-Dec-20 06:58 atorch/distributed/run.py
+-rw-r--r--  2.0 unx    12424 b- defN 24-Apr-10 08:59 atorch/distributed/run.py
 -rw-r--r--  2.0 unx       68 b- defN 23-Dec-20 06:58 atorch/fault_tolerance/__init__.py
 -rw-r--r--  2.0 unx     4825 b- defN 23-Dec-20 06:58 atorch/fault_tolerance/api.py
 -rw-r--r--  2.0 unx     8293 b- defN 23-Dec-20 06:58 atorch/fault_tolerance/custom_agent.py
 -rw-r--r--  2.0 unx     5659 b- defN 23-Dec-20 06:58 atorch/fault_tolerance/hanging_detector.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:32 atorch/modules/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/__init__.py
--rw-r--r--  2.0 unx    14747 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/activation_checkpointing.py
+-rw-r--r--  2.0 unx    14763 b- defN 24-Apr-10 08:59 atorch/modules/distributed_modules/activation_checkpointing.py
 -rw-r--r--  2.0 unx     5688 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/cross_entropy.py
 -rw-r--r--  2.0 unx    29411 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/layers.py
--rw-r--r--  2.0 unx    16774 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/mappings.py
+-rw-r--r--  2.0 unx    16790 b- defN 24-Apr-10 08:59 atorch/modules/distributed_modules/mappings.py
 -rw-r--r--  2.0 unx     7633 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/mappings_registry.py
 -rw-r--r--  2.0 unx     1269 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/materialize_modules.py
 -rw-r--r--  2.0 unx    54608 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/modules_registry.py
 -rw-r--r--  2.0 unx     5436 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/randomizer.py
 -rw-r--r--  2.0 unx    75800 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/transformer.py
 -rw-r--r--  2.0 unx     7551 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/utils.py
 -rw-r--r--  2.0 unx      147 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/__init__.py
 -rw-r--r--  2.0 unx    36537 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/pipe_compiler/PipelineStage.py
--rw-r--r--  2.0 unx     3924 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/pipe_compiler/StageInterleaver.py
+-rw-r--r--  2.0 unx     3976 b- defN 24-Apr-10 08:59 atorch/modules/distributed_modules/compilers/pipe_compiler/StageInterleaver.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/pipe_compiler/__init__.py
--rw-r--r--  2.0 unx    20919 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/pipe_compiler/distributed_pippy_compiler.py
+-rw-r--r--  2.0 unx    20974 b- defN 24-Apr-10 08:59 atorch/modules/distributed_modules/compilers/pipe_compiler/distributed_pippy_compiler.py
 -rw-r--r--  2.0 unx    25818 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/pipe_compiler/utils.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/tp_compiler/__init__.py
 -rw-r--r--  2.0 unx      222 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/tp_compiler/dtensor_compiler.py
 -rw-r--r--  2.0 unx     7707 b- defN 24-Jan-17 06:32 atorch/modules/distributed_modules/compilers/tp_compiler/tp_compiler.py
 -rw-r--r--  2.0 unx       80 b- defN 24-Jan-17 06:32 atorch/modules/distributed_transformer/__init__.py
 -rw-r--r--  2.0 unx     3173 b- defN 24-Jan-17 06:32 atorch/modules/distributed_transformer/commu_utils.py
 -rw-r--r--  2.0 unx    14623 b- defN 24-Jan-17 06:32 atorch/modules/distributed_transformer/distributed_attention.py
 -rw-r--r--  2.0 unx      295 b- defN 24-Jan-17 06:32 atorch/modules/moe/__init__.py
--rw-r--r--  2.0 unx    15968 b- defN 24-Jan-17 06:32 atorch/modules/moe/ddp.py
+-rw-r--r--  2.0 unx    16005 b- defN 24-Apr-10 08:59 atorch/modules/moe/ddp.py
 -rw-r--r--  2.0 unx     4291 b- defN 24-Jan-17 06:32 atorch/modules/moe/inject.py
 -rw-r--r--  2.0 unx    25005 b- defN 24-Jan-17 06:32 atorch/modules/moe/moe_layer.py
 -rw-r--r--  2.0 unx     6683 b- defN 24-Jan-17 06:32 atorch/modules/moe/switch_gating.py
 -rw-r--r--  2.0 unx     5799 b- defN 24-Jan-17 06:32 atorch/modules/moe/topk_gating.py
 -rw-r--r--  2.0 unx       37 b- defN 24-Jan-17 06:32 atorch/modules/transformer/__init__.py
 -rw-r--r--  2.0 unx     5210 b- defN 24-Jan-17 06:32 atorch/modules/transformer/_fa_api_compat_patch
 -rw-r--r--  2.0 unx    13580 b- defN 24-Jan-17 06:32 atorch/modules/transformer/cross_entropy.py
 -rw-r--r--  2.0 unx     8248 b- defN 24-Jan-18 02:35 atorch/modules/transformer/inject.py
--rw-r--r--  2.0 unx    72042 b- defN 24-Jan-18 02:35 atorch/modules/transformer/layers.py
+-rw-r--r--  2.0 unx    67467 b- defN 24-Apr-10 08:59 atorch/modules/transformer/layers.py
 -rw-r--r--  2.0 unx     2682 b- defN 24-Jan-17 06:32 atorch/modules/transformer/linear.py
--rw-r--r--  2.0 unx      486 b- defN 24-Jan-17 06:32 atorch/modules/transformer/losses.py
+-rw-r--r--  2.0 unx      374 b- defN 24-Apr-10 08:59 atorch/modules/transformer/losses.py
+-rw-r--r--  2.0 unx      244 b- defN 24-Apr-10 08:59 atorch/mup/__init__.py
+-rw-r--r--  2.0 unx     4232 b- defN 24-Apr-10 08:59 atorch/mup/infshape.py
+-rw-r--r--  2.0 unx     8553 b- defN 24-Apr-10 08:59 atorch/mup/init.py
+-rw-r--r--  2.0 unx    11021 b- defN 24-Apr-10 08:59 atorch/mup/module.py
+-rw-r--r--  2.0 unx     5867 b- defN 24-Apr-10 08:59 atorch/mup/optim.py
+-rw-r--r--  2.0 unx     7971 b- defN 24-Apr-10 08:59 atorch/mup/shape.py
 -rw-r--r--  2.0 unx      455 b- defN 23-Dec-20 06:58 atorch/normalization/__init__.py
--rw-r--r--  2.0 unx     9011 b- defN 23-Dec-20 08:43 atorch/normalization/layernorm.py
--rw-r--r--  2.0 unx     2493 b- defN 24-Jan-18 02:35 atorch/npu/__init__.py
--rw-r--r--  2.0 unx     7625 b- defN 24-Jan-18 02:35 atorch/npu/optim.py
+-rw-r--r--  2.0 unx     9000 b- defN 24-Apr-10 08:59 atorch/normalization/layernorm.py
+-rw-r--r--  2.0 unx     2681 b- defN 24-Apr-10 08:59 atorch/npu/__init__.py
+-rw-r--r--  2.0 unx     6090 b- defN 24-Apr-10 08:59 atorch/npu/layers.py
+-rw-r--r--  2.0 unx     7676 b- defN 24-Apr-10 08:59 atorch/npu/optim.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/ops/__init__.py
 -rw-r--r--  2.0 unx      950 b- defN 23-Dec-20 06:58 atorch/ops/git_version_info.py
--rw-r--r--  2.0 unx      349 b- defN 24-Jan-18 09:43 atorch/ops/git_version_info_installed.py
+-rw-r--r--  2.0 unx      347 b- defN 24-Apr-12 06:05 atorch/ops/git_version_info_installed.py
 -rw-r--r--  2.0 unx      271 b- defN 23-Dec-20 06:58 atorch/ops/accelerator/__init__.py
 -rw-r--r--  2.0 unx     4732 b- defN 23-Dec-20 06:58 atorch/ops/accelerator/abstract_accelerator.py
 -rw-r--r--  2.0 unx     8910 b- defN 23-Dec-20 06:58 atorch/ops/accelerator/cuda_accelerator.py
 -rw-r--r--  2.0 unx     2478 b- defN 23-Dec-20 06:58 atorch/ops/accelerator/real_accelerator.py
 -rw-r--r--  2.0 unx    12017 b- defN 23-Dec-20 06:58 atorch/ops/csrc/includes/conversion_utils.h
 -rw-r--r--  2.0 unx     7001 b- defN 23-Dec-20 06:58 atorch/ops/csrc/includes/dequantization_utils.h
 -rw-r--r--  2.0 unx     1202 b- defN 23-Dec-20 06:58 atorch/ops/csrc/includes/kernel_utils.h
@@ -184,69 +191,101 @@
 -rw-r--r--  2.0 unx     1271 b- defN 23-Dec-20 06:58 atorch/ops/op_builder/all_ops.py
 -rw-r--r--  2.0 unx    25650 b- defN 23-Dec-20 06:58 atorch/ops/op_builder/builder.py
 -rw-r--r--  2.0 unx      846 b- defN 23-Dec-21 03:00 atorch/ops/op_builder/quantization_optimizer.py
 -rw-r--r--  2.0 unx      920 b- defN 23-Dec-20 06:58 atorch/ops/op_builder/quantizer.py
 -rw-r--r--  2.0 unx     2401 b- defN 23-Dec-20 06:58 atorch/ops/quantizer/__init__.py
 -rw-r--r--  2.0 unx       93 b- defN 23-Dec-20 06:58 atorch/optimizers/__init__.py
 -rw-r--r--  2.0 unx    13353 b- defN 23-Dec-21 03:00 atorch/optimizers/adam_offload.py
--rw-r--r--  2.0 unx     6780 b- defN 23-Dec-20 06:58 atorch/optimizers/agd.py
+-rw-r--r--  2.0 unx     6808 b- defN 24-Apr-10 08:59 atorch/optimizers/agd.py
 -rw-r--r--  2.0 unx    11915 b- defN 23-Dec-20 06:58 atorch/optimizers/bf16_optimizer.py
 -rw-r--r--  2.0 unx      625 b- defN 23-Dec-20 06:58 atorch/optimizers/utils.py
 -rw-r--r--  2.0 unx     5375 b- defN 23-Dec-21 03:00 atorch/optimizers/wsam.py
 -rw-r--r--  2.0 unx       55 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/__init__.py
 -rw-r--r--  2.0 unx      626 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/config.py
 -rw-r--r--  2.0 unx    19476 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/functional.py
 -rw-r--r--  2.0 unx      118 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/optim/__init__.py
 -rw-r--r--  2.0 unx    10365 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/optim/q_adafactor.py
 -rw-r--r--  2.0 unx     7123 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/optim/q_adamw.py
 -rw-r--r--  2.0 unx     9927 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/optim/q_agd.py
 -rw-r--r--  2.0 unx    10023 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/optim/q_came.py
 -rw-r--r--  2.0 unx     7034 b- defN 23-Dec-21 03:00 atorch/optimizers/low_bit/optim/q_optimizer.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/protos/__init__.py
--rw-r--r--  2.0 unx    19348 b- defN 24-Jan-18 09:43 atorch/protos/acceleration_pb2.py
--rw-r--r--  2.0 unx     4574 b- defN 24-Jan-18 09:43 atorch/protos/acceleration_pb2_grpc.py
--rw-r--r--  2.0 unx     5993 b- defN 24-Jan-18 09:43 atorch/protos/coworker_pb2.py
--rw-r--r--  2.0 unx     6714 b- defN 24-Jan-18 09:43 atorch/protos/coworker_pb2_grpc.py
+-rw-r--r--  2.0 unx    19348 b- defN 24-Apr-12 06:05 atorch/protos/acceleration_pb2.py
+-rw-r--r--  2.0 unx     4574 b- defN 24-Apr-12 06:05 atorch/protos/acceleration_pb2_grpc.py
+-rw-r--r--  2.0 unx     5993 b- defN 24-Apr-12 06:05 atorch/protos/coworker_pb2.py
+-rw-r--r--  2.0 unx     6714 b- defN 24-Apr-12 06:05 atorch/protos/coworker_pb2_grpc.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-10 08:59 atorch/rl/__init__.py
+-rw-r--r--  2.0 unx     7661 b- defN 24-Apr-10 08:59 atorch/rl/config.py
+-rw-r--r--  2.0 unx      849 b- defN 24-Apr-10 08:59 atorch/rl/main.py
+-rw-r--r--  2.0 unx       39 b- defN 24-Apr-10 08:59 atorch/rl/data/__init__.py
+-rw-r--r--  2.0 unx     6390 b- defN 24-Apr-10 08:59 atorch/rl/data/data_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/__init__.py
+-rw-r--r--  2.0 unx    15390 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/ds_hook.py
+-rw-r--r--  2.0 unx    16621 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/hybrid_engine.py
+-rw-r--r--  2.0 unx     7738 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/initialize.py
+-rw-r--r--  2.0 unx      235 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/replace_policy.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/module_inject/__init__.py
+-rw-r--r--  2.0 unx      632 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/module_inject/utils.py
+-rw-r--r--  2.0 unx       55 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/module_inject/containers/__init__.py
+-rw-r--r--  2.0 unx     6707 b- defN 24-Apr-10 08:59 atorch/rl/ds_hybrid_engine/module_inject/containers/llama.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-10 08:59 atorch/rl/inference_backend/__init__.py
+-rw-r--r--  2.0 unx     1682 b- defN 24-Apr-10 08:59 atorch/rl/inference_backend/vllm_backend.py
+-rw-r--r--  2.0 unx       56 b- defN 24-Apr-10 08:59 atorch/rl/model_engine/__init__.py
+-rw-r--r--  2.0 unx    21156 b- defN 24-Apr-10 08:59 atorch/rl/model_engine/model_engine.py
+-rw-r--r--  2.0 unx     1138 b- defN 24-Apr-10 08:59 atorch/rl/model_engine/strategy.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-10 08:59 atorch/rl/model_utils/__init__.py
+-rw-r--r--  2.0 unx     6372 b- defN 24-Apr-10 08:59 atorch/rl/model_utils/llama2_utils.py
+-rw-r--r--  2.0 unx     6291 b- defN 24-Apr-10 08:59 atorch/rl/model_utils/load_init_model.py
+-rw-r--r--  2.0 unx    12237 b- defN 24-Apr-10 08:59 atorch/rl/model_utils/model_util.py
+-rw-r--r--  2.0 unx     2144 b- defN 24-Apr-10 08:59 atorch/rl/model_utils/redis_util.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-10 08:59 atorch/rl/ppo_utils/__init__.py
+-rw-r--r--  2.0 unx     6842 b- defN 24-Apr-10 08:59 atorch/rl/ppo_utils/ppo_util.py
+-rw-r--r--  2.0 unx       40 b- defN 24-Apr-10 08:59 atorch/rl/replay_buffer/__init__.py
+-rw-r--r--  2.0 unx     1795 b- defN 24-Apr-10 08:59 atorch/rl/replay_buffer/replay_buffer.py
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-10 08:59 atorch/rl/trainer/__init__.py
+-rw-r--r--  2.0 unx      274 b- defN 24-Apr-10 08:59 atorch/rl/trainer/ppo_trainer.py
+-rw-r--r--  2.0 unx     3190 b- defN 24-Apr-10 08:59 atorch/rl/trainer/rl_trainer.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-20 06:58 atorch/service/__init__.py
 -rw-r--r--  2.0 unx     2208 b- defN 23-Dec-20 06:58 atorch/service/coworker_data_service.py
 -rw-r--r--  2.0 unx     1924 b- defN 23-Dec-20 06:58 atorch/service/data_info_service.py
 -rw-r--r--  2.0 unx     3238 b- defN 23-Dec-20 09:08 atorch/service/rpc_clients.py
 -rw-r--r--  2.0 unx      103 b- defN 24-Jan-17 06:33 atorch/trainer/__init__.py
--rw-r--r--  2.0 unx     9795 b- defN 24-Jan-18 02:35 atorch/trainer/atorch_args.py
--rw-r--r--  2.0 unx    95605 b- defN 24-Jan-18 02:35 atorch/trainer/atorch_trainer.py
+-rw-r--r--  2.0 unx    10651 b- defN 24-Apr-10 08:59 atorch/trainer/atorch_args.py
+-rw-r--r--  2.0 unx    98297 b- defN 24-Apr-10 08:59 atorch/trainer/atorch_trainer.py
 -rw-r--r--  2.0 unx       63 b- defN 24-Jan-17 06:27 atorch/utils/__init__.py
 -rw-r--r--  2.0 unx     8524 b- defN 24-Jan-17 06:27 atorch/utils/ds_pipe_utils.py
--rw-r--r--  2.0 unx    14073 b- defN 24-Jan-18 02:35 atorch/utils/fsdp_init_util.py
--rw-r--r--  2.0 unx    40293 b- defN 24-Jan-18 02:35 atorch/utils/fsdp_save_util.py
--rw-r--r--  2.0 unx     2690 b- defN 24-Jan-17 06:27 atorch/utils/grad_scaler.py
+-rw-r--r--  2.0 unx     7784 b- defN 24-Apr-10 08:59 atorch/utils/fsdp_async_ckpt_util.py
+-rw-r--r--  2.0 unx    14062 b- defN 24-Apr-10 08:59 atorch/utils/fsdp_init_util.py
+-rw-r--r--  2.0 unx    41878 b- defN 24-Apr-10 08:59 atorch/utils/fsdp_save_util.py
+-rw-r--r--  2.0 unx     2706 b- defN 24-Apr-10 08:59 atorch/utils/grad_scaler.py
 -rw-r--r--  2.0 unx     5644 b- defN 24-Jan-17 06:27 atorch/utils/graph_transform_utils.py
--rw-r--r--  2.0 unx      980 b- defN 24-Jan-17 06:27 atorch/utils/hooks.py
+-rw-r--r--  2.0 unx     1021 b- defN 24-Apr-10 08:59 atorch/utils/hooks.py
 -rw-r--r--  2.0 unx     6940 b- defN 24-Jan-17 06:27 atorch/utils/ib_monitor.py
--rw-r--r--  2.0 unx     1256 b- defN 24-Jan-17 06:27 atorch/utils/import_util.py
+-rw-r--r--  2.0 unx     1428 b- defN 24-Apr-10 08:59 atorch/utils/import_util.py
 -rw-r--r--  2.0 unx    10381 b- defN 24-Jan-18 02:35 atorch/utils/manual_tp_utils.py
 -rw-r--r--  2.0 unx    34986 b- defN 24-Jan-18 02:35 atorch/utils/meta_model_utils.py
 -rw-r--r--  2.0 unx    11593 b- defN 24-Jan-17 06:27 atorch/utils/meta_overrides.py
 -rw-r--r--  2.0 unx     2267 b- defN 24-Jan-17 06:27 atorch/utils/metric_util.py
--rw-r--r--  2.0 unx     5781 b- defN 24-Jan-17 06:27 atorch/utils/numberic_checker.py
+-rw-r--r--  2.0 unx     5781 b- defN 24-Apr-10 08:59 atorch/utils/numberic_checker.py
 -rw-r--r--  2.0 unx     9514 b- defN 24-Jan-17 06:27 atorch/utils/parse_fsdp_mapping.py
--rw-r--r--  2.0 unx    10463 b- defN 24-Jan-17 06:27 atorch/utils/parse_trace_json.py
+-rw-r--r--  2.0 unx    10451 b- defN 24-Apr-10 08:59 atorch/utils/parse_trace_json.py
 -rw-r--r--  2.0 unx     3487 b- defN 24-Jan-17 06:27 atorch/utils/patch_fairscale.py
--rw-r--r--  2.0 unx     4751 b- defN 24-Jan-18 02:35 atorch/utils/patch_te.py
+-rw-r--r--  2.0 unx     4875 b- defN 24-Apr-10 08:59 atorch/utils/patch_te.py
 -rw-r--r--  2.0 unx     4188 b- defN 24-Jan-17 06:27 atorch/utils/pipe_file_utils.py
--rw-r--r--  2.0 unx    43694 b- defN 24-Jan-17 06:27 atorch/utils/prof.py
+-rw-r--r--  2.0 unx    46954 b- defN 24-Apr-10 08:59 atorch/utils/prof.py
 -rw-r--r--  2.0 unx     2839 b- defN 24-Jan-17 06:27 atorch/utils/shape_prop.py
 -rw-r--r--  2.0 unx     4281 b- defN 24-Jan-17 06:27 atorch/utils/sharding_spec.py
 -rw-r--r--  2.0 unx     2547 b- defN 24-Jan-17 06:27 atorch/utils/sparse.py
 -rw-r--r--  2.0 unx     6342 b- defN 24-Jan-17 06:27 atorch/utils/spec_prop.py
 -rw-r--r--  2.0 unx     2797 b- defN 24-Jan-17 06:27 atorch/utils/timer.py
 -rw-r--r--  2.0 unx    24365 b- defN 24-Jan-17 06:27 atorch/utils/tracer.py
 -rw-r--r--  2.0 unx     2244 b- defN 24-Jan-18 02:35 atorch/utils/trainer_utils.py
 -rw-r--r--  2.0 unx     1441 b- defN 24-Jan-17 06:27 atorch/utils/version.py
--rw-r--r--  2.0 unx     1046 b- defN 23-Dec-20 06:58 atorch-0.1.7.data/data/acceleration.proto
--rw-r--r--  2.0 unx      224 b- defN 23-Oct-10 02:40 atorch-0.1.7.data/data/build_proto.sh
--rw-r--r--  2.0 unx      455 b- defN 23-Dec-20 06:58 atorch-0.1.7.data/data/coworker.proto
--rw-r--r--  2.0 unx      267 b- defN 24-Jan-18 02:35 atorch-0.1.7.data/data/requirements.txt
--rw-r--r--  2.0 unx     1171 b- defN 24-Jan-18 09:43 atorch-0.1.7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Jan-18 09:43 atorch-0.1.7.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 24-Jan-18 09:43 atorch-0.1.7.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    23814 b- defN 24-Jan-18 09:43 atorch-0.1.7.dist-info/RECORD
-250 files, 1993653 bytes uncompressed, 485887 bytes compressed:  75.6%
+-rw-r--r--  2.0 unx     1046 b- defN 23-Dec-20 06:58 atorch-0.1.8.data/data/acceleration.proto
+-rw-r--r--  2.0 unx      224 b- defN 24-Apr-10 08:59 atorch-0.1.8.data/data/build_proto.sh
+-rw-r--r--  2.0 unx      455 b- defN 23-Dec-20 06:58 atorch-0.1.8.data/data/coworker.proto
+-rw-r--r--  2.0 unx      273 b- defN 24-Apr-10 08:59 atorch-0.1.8.data/data/requirements.txt
+-rw-r--r--  2.0 unx     1155 b- defN 24-Apr-12 06:05 atorch-0.1.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-12 06:05 atorch-0.1.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 24-Apr-12 06:05 atorch-0.1.8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    27323 b- defN 24-Apr-12 06:06 atorch-0.1.8.dist-info/RECORD
+289 files, 2182310 bytes uncompressed, 534458 bytes compressed:  75.5%
```

## zipnote {}

```diff
@@ -456,23 +456,44 @@
 
 Filename: atorch/modules/transformer/linear.py
 Comment: 
 
 Filename: atorch/modules/transformer/losses.py
 Comment: 
 
+Filename: atorch/mup/__init__.py
+Comment: 
+
+Filename: atorch/mup/infshape.py
+Comment: 
+
+Filename: atorch/mup/init.py
+Comment: 
+
+Filename: atorch/mup/module.py
+Comment: 
+
+Filename: atorch/mup/optim.py
+Comment: 
+
+Filename: atorch/mup/shape.py
+Comment: 
+
 Filename: atorch/normalization/__init__.py
 Comment: 
 
 Filename: atorch/normalization/layernorm.py
 Comment: 
 
 Filename: atorch/npu/__init__.py
 Comment: 
 
+Filename: atorch/npu/layers.py
+Comment: 
+
 Filename: atorch/npu/optim.py
 Comment: 
 
 Filename: atorch/ops/__init__.py
 Comment: 
 
 Filename: atorch/ops/git_version_info.py
@@ -615,14 +636,107 @@
 
 Filename: atorch/protos/coworker_pb2.py
 Comment: 
 
 Filename: atorch/protos/coworker_pb2_grpc.py
 Comment: 
 
+Filename: atorch/rl/__init__.py
+Comment: 
+
+Filename: atorch/rl/config.py
+Comment: 
+
+Filename: atorch/rl/main.py
+Comment: 
+
+Filename: atorch/rl/data/__init__.py
+Comment: 
+
+Filename: atorch/rl/data/data_utils.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/__init__.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/ds_hook.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/hybrid_engine.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/initialize.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/replace_policy.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/module_inject/__init__.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/module_inject/utils.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/module_inject/containers/__init__.py
+Comment: 
+
+Filename: atorch/rl/ds_hybrid_engine/module_inject/containers/llama.py
+Comment: 
+
+Filename: atorch/rl/inference_backend/__init__.py
+Comment: 
+
+Filename: atorch/rl/inference_backend/vllm_backend.py
+Comment: 
+
+Filename: atorch/rl/model_engine/__init__.py
+Comment: 
+
+Filename: atorch/rl/model_engine/model_engine.py
+Comment: 
+
+Filename: atorch/rl/model_engine/strategy.py
+Comment: 
+
+Filename: atorch/rl/model_utils/__init__.py
+Comment: 
+
+Filename: atorch/rl/model_utils/llama2_utils.py
+Comment: 
+
+Filename: atorch/rl/model_utils/load_init_model.py
+Comment: 
+
+Filename: atorch/rl/model_utils/model_util.py
+Comment: 
+
+Filename: atorch/rl/model_utils/redis_util.py
+Comment: 
+
+Filename: atorch/rl/ppo_utils/__init__.py
+Comment: 
+
+Filename: atorch/rl/ppo_utils/ppo_util.py
+Comment: 
+
+Filename: atorch/rl/replay_buffer/__init__.py
+Comment: 
+
+Filename: atorch/rl/replay_buffer/replay_buffer.py
+Comment: 
+
+Filename: atorch/rl/trainer/__init__.py
+Comment: 
+
+Filename: atorch/rl/trainer/ppo_trainer.py
+Comment: 
+
+Filename: atorch/rl/trainer/rl_trainer.py
+Comment: 
+
 Filename: atorch/service/__init__.py
 Comment: 
 
 Filename: atorch/service/coworker_data_service.py
 Comment: 
 
 Filename: atorch/service/data_info_service.py
@@ -642,14 +756,17 @@
 
 Filename: atorch/utils/__init__.py
 Comment: 
 
 Filename: atorch/utils/ds_pipe_utils.py
 Comment: 
 
+Filename: atorch/utils/fsdp_async_ckpt_util.py
+Comment: 
+
 Filename: atorch/utils/fsdp_init_util.py
 Comment: 
 
 Filename: atorch/utils/fsdp_save_util.py
 Comment: 
 
 Filename: atorch/utils/grad_scaler.py
@@ -720,32 +837,32 @@
 
 Filename: atorch/utils/trainer_utils.py
 Comment: 
 
 Filename: atorch/utils/version.py
 Comment: 
 
-Filename: atorch-0.1.7.data/data/acceleration.proto
+Filename: atorch-0.1.8.data/data/acceleration.proto
 Comment: 
 
-Filename: atorch-0.1.7.data/data/build_proto.sh
+Filename: atorch-0.1.8.data/data/build_proto.sh
 Comment: 
 
-Filename: atorch-0.1.7.data/data/coworker.proto
+Filename: atorch-0.1.8.data/data/coworker.proto
 Comment: 
 
-Filename: atorch-0.1.7.data/data/requirements.txt
+Filename: atorch-0.1.8.data/data/requirements.txt
 Comment: 
 
-Filename: atorch-0.1.7.dist-info/METADATA
+Filename: atorch-0.1.8.dist-info/METADATA
 Comment: 
 
-Filename: atorch-0.1.7.dist-info/WHEEL
+Filename: atorch-0.1.8.dist-info/WHEEL
 Comment: 
 
-Filename: atorch-0.1.7.dist-info/top_level.txt
+Filename: atorch-0.1.8.dist-info/top_level.txt
 Comment: 
 
-Filename: atorch-0.1.7.dist-info/RECORD
+Filename: atorch-0.1.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## atorch/auto/accelerate.py

```diff
@@ -340,14 +340,21 @@
         # set parallel mode's config to data parallel only.
         strategy.adjust_data_parallel(cur_total_process)
     if not is_distributed():
         removed_names = strategy.remove_distributed_method(opt_lib)
         if removed_names is not None:
             logger.info("These distributed optimization methods are ignored in non-distributed case: %s", removed_names)
 
+    device_capability = (
+        torch.cuda.get_device_capability(torch.cuda.current_device()) if torch.cuda.is_available() else None
+    )
+    removed_names = strategy.remove_device_unsupported_method(opt_lib, device_capability)
+    if removed_names is not None:
+        logger.info("Ignored optimization methods as not supported by current device: %s", removed_names)
+
     # reset config for tunable method if finetune_strategy
     if finetune_strategy:
         strategy.reset_config()
     # set tunable value if it is None.
     strategy.set_tunable_value(opt_lib)
     return True, strategy
```

## atorch/auto/model_context.py

```diff
@@ -463,18 +463,16 @@
             return
         wrappers = self.pre_wrappers if is_pre_wrapper else self.post_wrappers
         # Since mp wrapper will add tp and pipe wrappers into wrappers,
         # we have to take it out and execute it separately
         (wrapper_func, wrapper_config) = wrappers.pop("mp", (None, None))
         if wrapper_func is not None:
             wrapper_func(self, "mp", wrapper_config)
-
-        # Since MP wrapper will add some more wrappers, we will call adjust wrappers again.
-        self.adjust_wrappers()
-        wrappers = self.pre_wrappers if is_pre_wrapper else self.post_wrappers
+            # Since MP wrapper will add some more wrappers, we will call adjust wrappers again.
+            self.adjust_wrappers()
 
         for name in wrappers.keys():
             (wrapper_func, wrapper_config) = wrappers[name]
             wrapper_func(self, name, wrapper_config)
         if is_pre_wrapper:
             self.pre_wrapper_applied = True
         else:
```

## atorch/auto/strategy.py

```diff
@@ -84,14 +84,28 @@
             removed_names = [item[0] for item in opt_to_remove]
             for item in opt_to_remove:
                 self.opt_list.remove(item)
             return removed_names
         else:
             return None
 
+    def remove_device_unsupported_method(self, opt_lib, device_capability):
+        # return list of removed opt methods or None if nothing removed.
+        opt_to_remove = []
+        for item in self.opt_list:
+            if not opt_lib[item[0]].device_supported(item[1], device_capability):
+                opt_to_remove.append(item)
+        if len(opt_to_remove) > 0:
+            removed_names = [item[0] for item in opt_to_remove]
+            for item in opt_to_remove:
+                self.opt_list.remove(item)
+            return removed_names
+        else:
+            return None
+
     def convert_strategy_to_easydl_format(self):
         edl_strategy = []
         for item in self.opt_list:
             edl_strategy.append((item[0], pickle.dumps(item[1]), item[2]))
         return edl_strategy
 
     def __str__(self):
```

## atorch/auto/engine/servicer.py

```diff
@@ -1,13 +1,13 @@
 import os
 import pickle
 from concurrent import futures
 
 import grpc
-from google.protobuf import empty_pb2
+from google.protobuf import empty_pb2  # type: ignore
 
 from atorch.auto.engine.task import TaskType
 from atorch.common.log_utils import default_logger as logger
 from atorch.protos import acceleration_pb2, acceleration_pb2_grpc
 
 
 def create_acceleration_service(port, executor, pool_size=None):
```

## atorch/auto/engine/sg_algo/hebo/design_space/param.py

```diff
@@ -11,19 +11,19 @@
         pass
 
     @abstractmethod
     def sample(self, num=1) -> pd.DataFrame:
         pass
 
     @abstractmethod
-    def transform(self, x: np.array) -> np.array:
+    def transform(self, x: np.ndarray) -> np.ndarray:
         pass
 
     @abstractmethod
-    def inverse_transform(self, x: np.array) -> np.array:
+    def inverse_transform(self, x: np.ndarray) -> np.ndarray:
         pass
 
     @property
     @abstractmethod
     def is_numeric(self) -> bool:
         pass
```

## atorch/auto/engine/sg_algo/hebo/optimizers/hebo.py

```diff
@@ -91,27 +91,27 @@
             paras = self.space.paras
             enum_names = self.space.enum_names
             cfg["num_uniqs"] = [paras[name].num_uniqs for name in enum_names]
         return cfg
 
     def get_best_id(self, fix_input: dict = None) -> int:
         if fix_input is None:
-            return np.argmin(self.y.reshape(-1))
+            return np.argmin(self.y.reshape(-1))  # type: ignore
         X = self.X.copy()
         y = self.y.copy()
         for k, v in fix_input.items():
             if X[k].dtype != "float":
                 crit = (X[k] != v).values
             else:
                 crit = ((X[k] - v).abs() > np.finfo(float).eps).values
             y[crit] = np.inf
         if np.isfinite(y).any():
-            return np.argmin(y.reshape(-1))
+            return np.argmin(y.reshape(-1))  # type: ignore
         else:
-            return np.argmin(self.y.reshape(-1))
+            return np.argmin(self.y.reshape(-1))  # type: ignore
 
     def suggest(self, n_suggestions=1, fix_input=None):
         if self.acq_cls != MACE and n_suggestions != 1:
             raise RuntimeError("Only MACE can batch infer")
         if self.X.shape[0] < self.rand_sample:
             sample = self.quasi_sample(n_suggestions, fix_input)
             return sample
```

## atorch/auto/opt_lib/amp_optimization.py

```diff
@@ -7,17 +7,18 @@
 from fairscale.nn.data_parallel import ShardedDataParallel as ShardedDDP
 from torch.cuda.amp import GradScaler, autocast
 from torch.distributed.fsdp import FullyShardedDataParallel as FSDP
 
 import atorch
 from atorch.distributed.distributed import parallel_group
 from atorch.utils.grad_scaler import BF16GradScaler, BF16ShardedGradScaler
+from atorch.utils.import_util import is_torch_npu_available
 from atorch.utils.version import torch_version
 
-if torch_version() >= (1, 12, 0):
+if torch_version() >= (1, 12, 0):  # type: ignore
     from torch.distributed.fsdp.sharded_grad_scaler import ShardedGradScaler
 
 else:
     from fairscale.optim.grad_scaler import ShardedGradScaler
 
 from atorch.auto.auto_accelerate_context import AutoAccelerateContext
 from atorch.auto.opt_lib.optimization import Optimization
@@ -59,14 +60,17 @@
     @staticmethod
     def apply_wrapper(model_context, wrapper_name, wrapper_config=None):
         if wrapper_name == "amp_native":
             model = model_context.model
             skip_if_nonfinite = (
                 wrapper_config.pop("skip_if_nonfinite") if "skip_if_nonfinite" in wrapper_config else False
             )
+            if is_torch_npu_available() and skip_if_nonfinite:
+                skip_if_nonfinite = False
+                logger.info("NPU does not support 'skip_if_nonfinite'")
             model.forward = autocast(**wrapper_config)(model.forward)
             if hasattr(model, "generate") and callable(getattr(model, "generate")):
                 model.generate = autocast(**wrapper_config)(model.generate)
             loss_func = model_context.loss_func
 
             if wrapper_config["dtype"] == torch.bfloat16 and not skip_if_nonfinite:
                 # bfloat16 does not need loss or gradient scaling
@@ -181,17 +185,17 @@
         _CUDA_RNG_STATE_TRACKER = CudaRNGStatesTracker()
     return _CUDA_RNG_STATE_TRACKER
 
 
 def is_fp8_available():
     if not torch.cuda.is_available():
         return False
-    # GPU sm version >= 8.9 (Ada, Hopper, etc)
+
     device_capability = torch.cuda.get_device_capability()
-    return isinstance(device_capability, tuple) and device_capability >= (8, 9)
+    return Fp8Optimization.device_supported(device_capability=device_capability)
 
 
 class Fp8Optimization(Optimization):
     def __init__(self):
         super().__init__("fp8", "amp", False)
 
     def tune(self, model_context, config=None, strategy=None, apply_transform=True, time_limit=None):
@@ -362,7 +366,12 @@
         # step 3: record fp8_enabled for checkpoint optimization
         if hasattr(AutoAccelerateContext, "fp8_enabled"):
             AutoAccelerateContext.fp8_enabled.update({AutoAccelerateContext.counter: True})
         else:
             AutoAccelerateContext.add_ac_attr("fp8_enabled", {AutoAccelerateContext.counter: True})
 
         return model_context
+
+    @staticmethod
+    def device_supported(config=None, device_capability=None):
+        # GPU sm version >= 8.9 (Ada, Hopper, etc)
+        return isinstance(device_capability, tuple) and device_capability >= (8, 9)
```

## atorch/auto/opt_lib/checkpoint_optimization.py

```diff
@@ -1,8 +1,7 @@
-import inspect
 from collections.abc import MutableMapping
 from functools import partial
 from typing import Callable
 
 import torch
 
 from atorch.auto.opt_lib.optimization import Optimization
@@ -118,45 +117,56 @@
                 )
 
                 if fp8_enabled:
                     # use te checkpoint
                     from transformer_engine.pytorch.distributed import CudaRNGStatesTracker
                     from transformer_engine.pytorch.distributed import checkpoint as te_checkpoint
 
-                    # patch te checkpoint to support non-tensor inputs/outputs
-                    from atorch.utils.patch_te import patch_te
+                    # patch te checkpoint to support non-tensor inputs/outputs if needed
+                    from atorch.utils.patch_te import patch_te_if_needed
 
-                    patch_te()
+                    patch_te_if_needed()
 
                     _CUDA_RNG_STATE_TRACKER = CudaRNGStatesTracker()
 
                     def get_cuda_rng_tracker():
                         return _CUDA_RNG_STATE_TRACKER
 
                     def te_checkpoint_func(m, *args, **kargs):
                         return te_checkpoint(m, False, get_cuda_rng_tracker, None, *args, **kargs)
 
                     checkpoint_wrapper_fn = partial(checkpoint_wrapper, checkpoint_fn=te_checkpoint_func)
                     apply_activation_checkpointing = partial(
                         apply_activation_checkpointing, checkpoint_wrapper_fn=checkpoint_wrapper_fn
                     )
                 else:
-                    # check by signature of func
-                    params = inspect.signature(checkpoint_wrapper).parameters
-                    need_patch = params["checkpoint_impl"].default != CheckpointImpl.NO_REENTRANT
-
                     assert other_config is not None  # for mypy
-                    # default to `need_patch`
-                    no_reentrant = other_config.pop("no_reentrant", need_patch)
+                    # pytorch uses default None for use_reentrant parameter in checkpoint,
+                    # which is equivalent to reentrant. This parameter will become mandatory in torch 2.4.
+                    no_reentrant = other_config.pop("no_reentrant", None)
                     selective_offload = other_config.pop("selective_offload", None)
+                    if no_reentrant is None:
+                        # Used no_reentrant for checkpoint selective offload
+                        no_reentrant = selective_offload is not None
+                        logger.warning(
+                            "checkpoint config does not contains no_reentrant value, "
+                            "set no_reentrant=True as selective_offload is used"
+                            if selective_offload is not None
+                            else "set no_reentrant=False as default"
+                        )
+                    else:
+                        logger.info(f"checkpoint config contains no_reentrant={no_reentrant}")
                     checkpoint_impl = CheckpointImpl.NO_REENTRANT if no_reentrant else CheckpointImpl.REENTRANT
                     checkpoint_wrapper_fn_kwargs = {"checkpoint_impl": checkpoint_impl}
                     if selective_offload is not None:
                         if checkpoint_impl == CheckpointImpl.REENTRANT:
-                            raise ValueError("selective offloading don't support `CheckpointImpl.REENTRANT`")
+                            raise ValueError(
+                                "selective offloading don't support `CheckpointImpl.REENTRANT`, "
+                                "requires no_reentrant=False in checkpoint config"
+                            )
                         if "offload_args" not in selective_offload or "num_layers" not in selective_offload:
                             raise ValueError("`offload_args` or `num_layers` is not passed")
 
                         from .selective_offloading_checkpoint import (
                             OffloadOpManagerArgs,
                             get_selective_offloading_checkpoint_modes,
                         )
```

## atorch/auto/opt_lib/optimization.py

```diff
@@ -68,14 +68,19 @@
         return model_context
 
     @staticmethod
     def reset(config):
         """Reset environment changed by current optimization."""
         pass
 
+    @staticmethod
+    def device_supported(config=None, device_capability=None):
+        "If the method with config is supported by device with device_capability"
+        return True
+
 
 class DistributedGraphMixin:
     def __init__(
         self,
         num_nodes=None,
         num_devices_per_node=None,
         tracer_backend="meta_fx",
```

## atorch/auto/opt_lib/selective_offloading_checkpoint.py

```diff
@@ -1,15 +1,15 @@
 """This file is for selecting activation recomputing.
 We offload activation to cpu, in recomputing stage, reload to gpu.
 refers to https://github.com/pytorch/pytorch/issues/70135#issuecomment-1542439983
 docs: https://yuque.antfin-inc.com/ai-infra/atorch-design/os05u91bdresusku
 """
 from collections import defaultdict, deque
-from dataclasses import dataclass
-from typing import DefaultDict, Deque, List, Sequence, Set
+from dataclasses import dataclass, field
+from typing import DefaultDict, Deque, List, Optional, Set
 
 import torch
 from torch.utils._python_dispatch import TorchDispatchMode
 from torch.utils._pytree import tree_map
 
 import atorch
 
@@ -72,15 +72,17 @@
         offload all activation to cpu, so this param is for which op instance needs to be offload.
         eg. We have 10 matmul, we want to offload first, third matmul op, it should pass [1,3].
         In a 8 gpus node, 2 gpus are sharing upstream bandwidth, so we should let those gpus offload different
         activations to avoid pcie race.
     """
 
     name: str
-    index_to_offload: Sequence[int]
+    index_to_offload: List[int]
+    index_to_hold: Optional[List[int]] = field(default_factory=list)  # type: ignore
+    index_to_hold_layer: Optional[int] = -1
 
 
 class OffloadOpManager:
     def __init__(self, config: OffloadOpManagerArgs):
         """
         name: See `OffloadOpManagerArgs`
         offload_index: recording which op instance is processing.
@@ -97,32 +99,39 @@
             At this point, `cpu_storage` cache offload via `index_to_offload`, it don't know which op should be
             recomputed in backward, this will lead useless allocation and wrong offload.
         """
         self.name: str = config.name
         self.offload_index: int = 0
         self.reload_index: int = 0
         self.index_to_offload: Set[int] = set(config.index_to_offload)
+        assert config.index_to_hold is not None  # for mypy
+        self.index_to_hold: Set[int] = set(config.index_to_hold)
+        self.index_to_hold_layer = config.index_to_hold_layer
         self.cpu_storage: Deque[torch.Tensor] = deque()
         self.gpu_storage: Deque[torch.Tensor] = deque()
         self.shaped_cpu_cache: DefaultDict[torch.Size, Deque[torch.Tensor]] = defaultdict(deque)
 
+    def need_hold_on_gpu_by_layer(self, layer_index, index):
+        return layer_index < self.index_to_hold_layer and index in self.index_to_hold
+
     def reset(self):
         """Reseting all index to 0, this should called in each iteration."""
         self.offload_index = self.reload_index = 0
 
-    def offload(self, x, offload_event_queue, current_stream, copy_stream, is_last_layer=False):
+    def offload(self, x, offload_event_queue, current_stream, copy_stream, layer_index, need_hold_on_gpu=False):
         """Offload gpu to cpu. We use `offload_index` and `index_to_offload` to select which to offload.
-        If `is_last_layer` is True, we use `gpu_storage` to cache tensor and pop in backward.
+        If `need_hold_on_gpu` is True, we use `gpu_storage` to cache tensor and pop in backward.
         """
         self.offload_index += 1
-        if self.offload_index not in self.index_to_offload:
-            return x
-        if is_last_layer:
+        if self.offload_index not in self.index_to_offload and self.offload_index not in self.index_to_hold:
+            return
+
+        if need_hold_on_gpu or self.need_hold_on_gpu_by_layer(layer_index, self.offload_index):
             self.gpu_storage.append(x)
-            return x
+            return
 
         def _detach_to_cpu(x):
             if isinstance(x, torch.Tensor) and x.is_cuda:
                 offload_event_queue.deque_event_and_synchronize()
                 tensor = x.detach()
                 copy_stream.wait_stream(current_stream)
                 s = tensor.shape
@@ -135,20 +144,21 @@
                 tensor.record_stream(copy_stream)
                 offload_event_queue.enque_event()
                 return packed
 
         out_detached_cpu = tree_map(_detach_to_cpu, x)
         self.cpu_storage.append(out_detached_cpu)
 
-    def reload(self, x_gen, reload_event_queue, current_stream, copy_stream, is_last_layer=False):
+    def reload(self, x_gen, reload_event_queue, current_stream, copy_stream, layer_index, need_hold_on_gpu=False):
         """Same as `offload`."""
         self.reload_index += 1
-        if self.reload_index not in self.index_to_offload:
+        if self.reload_index not in self.index_to_offload and self.reload_index not in self.index_to_hold:
             return x_gen()
-        if is_last_layer:
+
+        if need_hold_on_gpu or self.need_hold_on_gpu_by_layer(layer_index, self.reload_index):
             return self.gpu_storage.popleft()
 
         def _to_cuda(x):
             if isinstance(x, torch.Tensor) and x.device.type == "cpu":
                 s = x.shape
                 reload_event_queue.deque_event_and_synchronize()
                 self.shaped_cpu_cache[s].append(x)
@@ -175,46 +185,50 @@
     current_offload_index = 0
 
     class CachingMode(TorchDispatchMode):
         """Doing dispatch in forward pass, inspect kernel and use `OffloadOpManager` to offload tensor."""
 
         def __init__(self, offloaders, num_of_layers, index, _dispatch_key=None):
             self.offloaders = offloaders
-            self.is_last = index == num_of_layers
+            self.need_hold_on_gpu = index == num_of_layers
+            self.index = index
             super().__init__(_dispatch_key)
 
         def __torch_dispatch__(self, func, types, args=(), kwargs=None):
             kwargs = {} if kwargs is None else kwargs
             out = func(*args, **kwargs)
             func_name = func.__name__
             if func_name not in self.offloaders:
                 return out
             offloader = self.offloaders[func_name]
-            offloader.offload(out, pack_event_queue, current_stream, copy_stream, self.is_last)
+            offloader.offload(out, pack_event_queue, current_stream, copy_stream, self.index, self.need_hold_on_gpu)
             return out
 
     class CachedMode(TorchDispatchMode):
         """Doing dispatch in backward pass, inspect kernel and use `OffloadOpManager` to reload tensor."""
 
         def __init__(self, offloaders, num_of_layers, index, _dispatch_key=None):
             self.offloaders = offloaders
-            self.is_last = index == num_of_layers
+            self.need_hold_on_gpu = index == num_of_layers
+            self.index = index
             super().__init__(_dispatch_key)
 
         def __torch_dispatch__(self, func, types, args=(), kwargs=None):
             kwargs = {} if kwargs is None else kwargs
             func_name = func.__name__
             if func_name not in self.offloaders:
                 return func(*args, **kwargs)
             offloader = self.offloaders[func_name]
 
             def x_gen():
                 return func(*args, **kwargs)
 
-            out = offloader.reload(x_gen, unpack_event_queue, current_stream, copy_stream, self.is_last)
+            out = offloader.reload(
+                x_gen, unpack_event_queue, current_stream, copy_stream, self.index, self.need_hold_on_gpu
+            )
             return out
 
     def gen(offload_args: List[OffloadOpManagerArgs], num_of_layers: int):
         """Generating instance of `CachingMode` and ``CachedMode`."""
         nonlocal current_offload_index
         current_offload_index += 1
         offloaders = {arg.name: OffloadOpManager(arg) for arg in offload_args}
```

## atorch/auto/opt_lib/utils.py

```diff
@@ -73,27 +73,27 @@
 
 
 # Convert module name in module_list into module type.
 # Also ignore any module names that not exist in model.
 def to_module_class_by_name(model, module_list):
     module_classes = {}
     for m in module_list:
-        if type(m) == str:
+        if type(m) is str:
             module_classes[m] = None
     unassigned_num = len(module_classes)
     if unassigned_num > 0:
         for m in model.modules():
             if type(m).__name__ in module_classes.keys() and module_classes[type(m).__name__] is None:
                 module_classes[type(m).__name__] = type(m)
                 unassigned_num -= 1
                 if unassigned_num == 0:
                     break
     result = []
     for m in module_list:
-        if type(m) == str:
+        if type(m) is str:
             if module_classes[m] is not None:
                 result.append(module_classes[m])
         else:
             result.append(m)
     return type(module_list)(result)
```

## atorch/data/data_utils.py

```diff
@@ -14,15 +14,15 @@
 
 def get_sample_batch(dataset, dataloader_args, num=1):
     new_args = {"num_workers": 0}
     for key in dataloader_args:
         if key in ["num_workers", "prefetch_factor"]:
             # multi-process is not needed.
             continue
-        if key == "sampler" and type(dataloader_args["sampler"]) == DistributedSampler:
+        if key == "sampler" and isinstance(dataloader_args["sampler"], DistributedSampler):
             # no need for sampler if it is default
             continue
         new_args[key] = dataloader_args[key]
     dataloader = DataLoader(dataset, **new_args)
     batches = []
     for idx, data in enumerate(dataloader):
         batches.append(data)
```

## atorch/data/shm_dataloader.py

```diff
@@ -233,22 +233,22 @@
         create multiple shm_dataloaders with corresponding size.
         dataset, dataloader_args should be a list of same length with shm_data_size.
         shm_name_prefix must be a list of strings with different prefix names.
         coworker_data_process_func takes inputs as list of shm_context instead of shm_context.
         return a list of ShmDataloader
     """
     num_shms = 1
-    if type(shm_data_size) == list:
+    if type(shm_data_size) is list:
         num_shms = len(shm_data_size)
-        assert type(dataset) == list and len(dataset) == num_shms, f"dataset should be a list with length {num_shms}"
+        assert type(dataset) is list and len(dataset) == num_shms, f"dataset should be a list with length {num_shms}"
         assert (
-            type(dataloader_args) == list and len(dataloader_args) == num_shms
+            type(dataloader_args) is list and len(dataloader_args) == num_shms
         ), f"dataloader_args should be a list with length {num_shms}"
         assert (
-            type(shm_name_prefix) == list and len(shm_name_prefix) == num_shms
+            type(shm_name_prefix) is list and len(shm_name_prefix) == num_shms
         ), f"shm_name_prefix should be a list with length {num_shms}"
     else:
         dataset = [dataset]
         dataloader_args = [dataloader_args]
         shm_data_size = [shm_data_size]
         shm_name_prefix = [shm_name_prefix]
     if atorch.distributed.is_coworker():
```

## atorch/distributed/distributed.py

```diff
@@ -7,14 +7,15 @@
 import torch.distributed as dist
 import torch.distributed.rpc as torch_rpc
 from torch.distributed.constants import default_pg_timeout
 from torch.distributed.distributed_c10d import _get_default_group
 
 from atorch.common.log_utils import default_logger as logger
 from atorch.common.util_func import find_free_port, get_ip_address, wait_for_server_started
+from atorch.utils.import_util import is_torch_npu_available
 
 
 class _DistributedContext:
     LOCAL_RANK = None
     RANK = None
     WORLD_SIZE = None
     BACKEND = None
@@ -635,14 +636,16 @@
         if not torch.cuda.is_available():
             logger.error(
                 f"torch.cuda.is_available() returns False. Cannot find any GPUs. If using {backend}"
                 " as the communication backend, a GPU must exists. Using gloo to communicate in cpu"
                 " context."
             )
             return False
+        if is_torch_npu_available():
+            backend = "hccl"
         if backend == "nccl":
             try:
                 torch.cuda.nccl.version()
             except Exception as e:
                 logger.error(f"Failed to get nccl version. {str(e)}")
                 return False
         elif backend == "accl":
```

## atorch/distributed/run.py

```diff
@@ -9,16 +9,16 @@
 from atorch.distributed.hooks import hook_set_master_addr_port
 from atorch.distributed.launch import main as normal_run
 from atorch.distributed.launch import parse_args as parse_static_args
 from atorch.fault_tolerance.api import run as fault_tolerant_run
 
 try:
     from dlrover.trainer.torch.elastic_run import run as dlrover_run
-except ImportError:
-    logger.warning("DLRrover is not installed and torchrun is used.")
+except ImportError as e:
+    logger.warning(f"DLRover is not installed and torchrun is used. Error: {e}")
     dlrover_run = torchrun
 
 
 def parse_fault_tolerant_or_elastic_args(args=None, mode="elastic"):
     """Helper function parsing the command line options when using elastic training."""
     parser = ArgumentParser(description="ATorch Distributed Elastic Training Launcher")
```

## atorch/modules/distributed_modules/activation_checkpointing.py

```diff
@@ -23,15 +23,15 @@
 from torch.utils.checkpoint import detach_variable
 
 from atorch.distributed.distributed import parallel_group_size
 from atorch.utils.graph_transform_utils import _pack_kwargs, _unpack_kwargs, combine_map_aggregate, map_aggregate
 from atorch.utils.version import torch_version
 
 try:
-    if torch_version() <= (2, 0, 0):
+    if torch_version() <= (2, 0, 0):  # type: ignore
         from torch.distributed.algorithms._checkpoint.checkpoint_wrapper import CheckpointWrapper as TorchWrapper
     else:
         from torch.distributed.algorithms._checkpoint.checkpoint_wrapper import ActivationWrapper as TorchWrapper
 except ImportError:
     from atorch.common.log_utils import default_logger as logger
 
     logger.info("Checkpoint not supported, ignore")
```

## atorch/modules/distributed_modules/mappings.py

```diff
@@ -10,15 +10,15 @@
     generate_output_tensor_list,
     rank_list_is_sorted,
     rearrange_tensor_list,
     split_tensor_along_shard_dim,
 )
 from atorch.utils.version import torch_version
 
-if torch_version() <= (1, 12, 1):
+if torch_version() <= (1, 12, 1):  # type: ignore
     from torch.distributed import _all_gather_base as torch_all_gather_base
 else:
     from torch.distributed import all_gather_into_tensor as torch_all_gather_base
 
 
 def _reduce(input_, group=None):
     """ "All reduce the input_ tensor across group.
```

## atorch/modules/distributed_modules/compilers/pipe_compiler/StageInterleaver.py

```diff
@@ -1,20 +1,21 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates
 import threading
 from typing import Any, Dict, List, Tuple
 
-try:
-    from torch.optim.lr_scheduler import _LRScheduler
-except ImportError:
-    _LRScheduler = object
-
 import torch
 
 from .PipelineStage import PipelineStage
 
+_LRScheduler = None
+try:
+    from torch.optim.lr_scheduler import _LRScheduler  # type: ignore
+except ImportError:
+    _LRScheduler = object
+
 
 class StageInterleaver(torch.nn.Module):
     def __init__(
         self,
         stages: List[PipelineStage],
     ):
         super().__init__()
@@ -110,14 +111,14 @@
             optim.zero_grad(*args, **kwargs)
 
     def step(self, *args, **kwargs):
         for optim in self.optimizers:
             optim.step(*args, **kwargs)
 
 
-class InterleaverLRScheduler(_LRScheduler):
+class InterleaverLRScheduler(_LRScheduler):  # type: ignore
     def __init__(self, lr_schedulers):
         self.lr_schedulers = lr_schedulers
 
     def step(self, *args, **kwargs):
         for lr_scheduler in self.lr_schedulers:
             lr_scheduler.step()
```

## atorch/modules/distributed_modules/compilers/pipe_compiler/distributed_pippy_compiler.py

```diff
@@ -4,33 +4,14 @@
 # FIXME Do more testing util integrate this with torch._dynamo.optimize
 import math
 from collections import OrderedDict
 
 import torch
 import torch.distributed.rpc as torch_rpc
 from torch.cuda.amp import autocast
-
-try:
-    from pippy import Pipe, PipelineDriver1F1B, PipelineDriverFillDrain
-    from pippy.microbatch import Replicate, TensorChunkSpec, split_args_kwargs_into_chunks, sum_reducer
-    from pippy.PipelineDriver import PipelineDriverInterleaved1F1B
-except ImportError:
-    Pipe, PipelineDriver1F1B, PipelineDriverFillDrain, PipelineDriverInterleaved1F1B = (
-        None,
-        None,
-        None,
-        None,
-    )
-    sum_reducer, TensorChunkSpec, Replicate, split_args_kwargs_into_chunks = None, None, None, None
-
-try:
-    from torch.optim.lr_scheduler import LRScheduler
-except ImportError:
-    LRScheduler = object
-
 from torch.nn.parallel import DistributedDataParallel
 
 from atorch.amp.pipe_amp import get_pipe_amp_optimizer
 from atorch.common.log_utils import default_logger as logger
 from atorch.distributed.distributed import (
     _DistributedContext,
     _prefix_pg_name,
@@ -39,14 +20,27 @@
     parallel_group_size,
     parallel_rank,
     rank,
 )
 from atorch.modules.distributed_modules.materialize_modules import materialize_modules_to_device
 from atorch.utils.graph_transform_utils import map_aggregate
 
+from .utils import (
+    check_split_points,
+    check_staged_model,
+    compile_to_pipe,
+    construct_output_chunk_spec,
+    dp_pg_cb,
+    get_number_of_params,
+    hack_interpreter,
+    hack_pippy_driver,
+    prepare_args_kwargs,
+    propagate_fake_split_gm,
+)
+
 try:
     from atorch.modules.distributed_modules.compilers.pipe_compiler.PipelineStage import (
         PipelineStage,
         PipelineStage1F1B,
     )
     from atorch.modules.distributed_modules.compilers.pipe_compiler.StageInterleaver import (
         InterleaverLRScheduler,
@@ -54,26 +48,33 @@
         StageInterleaver,
     )
 
     pipeline_stage_imported = True
 except ImportError:
     pipeline_stage_imported = False
 
-from .utils import (
-    check_split_points,
-    check_staged_model,
-    compile_to_pipe,
-    construct_output_chunk_spec,
-    dp_pg_cb,
-    get_number_of_params,
-    hack_interpreter,
-    hack_pippy_driver,
-    prepare_args_kwargs,
-    propagate_fake_split_gm,
-)
+try:
+    from pippy import Pipe, PipelineDriver1F1B, PipelineDriverFillDrain
+    from pippy.microbatch import Replicate, TensorChunkSpec, split_args_kwargs_into_chunks, sum_reducer
+    from pippy.PipelineDriver import PipelineDriverInterleaved1F1B
+except ImportError:
+    Pipe, PipelineDriver1F1B, PipelineDriverFillDrain, PipelineDriverInterleaved1F1B = (
+        None,
+        None,
+        None,
+        None,
+    )
+    sum_reducer, TensorChunkSpec, Replicate, split_args_kwargs_into_chunks = None, None, None, None
+
+_LRScheduler = None
+try:
+    from torch.optim.lr_scheduler import _LRScheduler  # type: ignore
+except ImportError:
+    _LRScheduler = object
+
 
 driver_schedules = {
     "FillDrain": PipelineDriverFillDrain,
     "1F1B": PipelineDriver1F1B,
     "Interleaved1F1B": PipelineDriverInterleaved1F1B,
 }
 
@@ -94,15 +95,15 @@
     def zero_grad(self, *args, **kwargs):
         pass
 
     def step(self, *args, **kwargs):
         pass
 
 
-class DummyLRScheduler(LRScheduler):
+class DummyLRScheduler(_LRScheduler):  # type: ignore
     def __init__(self):
         pass
 
     def step(self):
         pass
```

## atorch/modules/moe/ddp.py

```diff
@@ -7,15 +7,20 @@
 import logging
 from contextlib import contextmanager
 
 import torch
 import torch.distributed as dist
 from torch.distributed.algorithms.join import Join
 from torch.nn.parallel import DistributedDataParallel
-from torch.nn.parallel.distributed import _DDPSink, _find_tensors, _tree_flatten_with_rref, _tree_unflatten_with_rref
+from torch.nn.parallel.distributed import (  # type: ignore
+    _DDPSink,
+    _find_tensors,
+    _tree_flatten_with_rref,
+    _tree_unflatten_with_rref,
+)
 
 from atorch.common.log_utils import default_logger as logger
 from atorch.modules.moe.moe_layer import get_experts_ddp_process_group
 
 # torch 2.0
 try:
     from torch.distributed.utils import _sync_module_states
```

## atorch/modules/transformer/layers.py

```diff
@@ -1,30 +1,31 @@
 # coding=utf-8
 from __future__ import absolute_import, unicode_literals
 
 import copy
+import functools
 import inspect
-import re
 import shutil
 from importlib.metadata import version
 from pathlib import Path
 
 import torch
 import torch.nn.functional as F
 from deepspeed import DeepSpeedTransformerLayer
 from deepspeed.ops.op_builder import StochasticTransformerBuilder, TransformerBuilder
 from deepspeed.ops.transformer import transformer  # using module var
 from pkg_resources import packaging  # type: ignore
 from torch import nn
+from torch.cuda.amp.autocast_mode import _cast, autocast
 from torch.nn import MultiheadAttention
 
 from atorch.common.log_utils import default_logger as logger
 from atorch.common.util_func import divide, split_tensor_along_last_dim
+from atorch.utils.import_util import is_torch_npu_available
 from atorch.utils.meta_model_utils import is_meta, recursive_empty_param, reload_meta_module
-from atorch.utils.version import torch_version
 
 
 class ImportFailDummyClass:
     pass
 
 
 try:
@@ -44,15 +45,38 @@
 
 try:
     import flash_attn
 except ModuleNotFoundError:
     logger.info("flash_attn not installed")
     flash_attn = None
 
+
+# patch fn to handle autocast
+def _cast_fa_fn(fa_fn):
+    @functools.wraps(fa_fn)
+    def new_fa_fn(*args, **kwargs):
+        if torch.is_autocast_enabled():
+            cur_dtype = torch.get_autocast_gpu_dtype()
+            with autocast(enabled=False):
+                return fa_fn(*_cast(args, cur_dtype), **_cast(kwargs, cur_dtype))
+        else:
+            return fa_fn(*args, **kwargs)
+
+    return new_fa_fn
+
+
 if flash_attn is not None:
+    # patching flash_attn.flash_attn_interface.flash_attn[xxxx]_func to handle autocast
+    import flash_attn.flash_attn_interface
+
+    fn_names = [i for i in dir(flash_attn.flash_attn_interface) if i.startswith("flash_attn_") and i.endswith("_func")]
+    for fn_name in fn_names:
+        new_fa_fn = _cast_fa_fn(getattr(flash_attn.flash_attn_interface, fn_name))
+        setattr(flash_attn.flash_attn_interface, fn_name, new_fa_fn)
+
     _flash_attn_version = packaging.version.Version(version("flash-attn"))
     try:
         from flash_attn.flash_attention import FlashMHA  # cuda version
     except (ImportError, ModuleNotFoundError) as e:
         logger.error(f"Import FlashMHA failed. {e}")
         assert _flash_attn_version >= packaging.version.Version(
             "2"
@@ -76,180 +100,60 @@
         dropout_add_layer_norm = None
 else:
     FlashMHA = ImportFailDummyClass
     _flash_attn_version = None
     dropout_add_layer_norm = None
 
 try:
-    import flash_attn_1
+    # patching flash_attn_1.flash_attn_interface.flash_attn[xxxx]_func to handle autocast
+    import flash_attn_1.flash_attn_interface
+
+    fn_names = [
+        i for i in dir(flash_attn_1.flash_attn_interface) if i.startswith("flash_attn_") and i.endswith("_func")
+    ]
+    for fn_name in fn_names:
+        new_fa_fn = _cast_fa_fn(getattr(flash_attn_1.flash_attn_interface, fn_name))
+        setattr(flash_attn_1.flash_attn_interface, fn_name, new_fa_fn)
+
     from flash_attn_1.flash_attn_interface import flash_attn_unpadded_func as flash_attn_1_unpadded_func
     from flash_attn_1.ops.layer_norm import dropout_add_layer_norm
 
     has_legacy_fa1 = True
+    if _flash_attn_version is None:
+        _flash_attn_version = packaging.version.Version(version("flash-attn-1"))
 except (ImportError, ModuleNotFoundError):
     flash_attn_1 = None
     has_legacy_fa1 = False
 
-if torch_version() >= (2, 0, 0):  # torch ops seems to differ from 1.x, support pt2.0+ only
-    try:
-        import flash_attn_2_cuda
-
-        _flash_attn_2_cuda_lib = torch.library.Library("flash_attn_2_cuda", "DEF")
-        _flash_attn_2_cuda_lib.define(
-            re.sub(
-                r"\s+",
-                " ",
-                f"""
-            fa2_fwd(Tensor q, Tensor k, Tensor v, Tensor? out_,
-            float p_dropout, float softmax_scale, bool is_causal,
-            {"int window_size_left, int window_size_right, "
-            if _flash_attn_version > packaging.version.Version("2.3.0")
-            else ""}
-            bool return_softmax, Generator? gen_, Tensor? glm_mask)
-             -> (Tensor out, Tensor q_padded, Tensor k_padded,
-            Tensor v_padded, Tensor out_padded, Tensor softmax_lse,
-            Tensor p, Tensor rng_state)""".replace(
-                    "\n", ""
-                ),
-            )
-        )
-        _flash_attn_2_cuda_lib.define(
-            re.sub(
-                r"\s+",
-                " ",
-                f"""
-            fa2_varlen_fwd(Tensor q, Tensor k, Tensor v, Tensor? out_,
-            Tensor cu_seqlens_q, Tensor cu_seqlens_k,
-            {"Tensor? seqused_k, "
-            if _flash_attn_version >= packaging.version.Version("2.3.6")
-            else ""}
-            int max_seqlen_q, int max_seqlen_k, float p_dropout,
-            float softmax_scale, bool zero_tensors, bool is_causal,
-            {"int window_size_left, int window_size_right, "
-            if _flash_attn_version >= packaging.version.Version("2.3.0")
-            else ""}
-            bool return_softmax, Generator? gen_, Tensor? glm_mask)
-             -> (Tensor out, Tensor q_padded, Tensor k_padded,
-            Tensor v_padded, Tensor out_padded, Tensor softmax_lse,
-            Tensor p, Tensor rng_state)""".replace(
-                    "\n", ""
-                ),
-            )
-        )
-        _flash_attn_2_cuda_lib.define(
-            re.sub(
-                r"\s+",
-                " ",
-                f"""
-            fa2_bwd(Tensor dout, Tensor q, Tensor k, Tensor v, Tensor out,
-            Tensor softmax_lse, Tensor? dq_, Tensor? dk_, Tensor? dv_,
-            float p_dropout, float softmax_scale, bool is_causal,
-            {"int window_size_left, int window_size_right, "
-            if _flash_attn_version >= packaging.version.Version("2.3.0")
-            else ""}
-            Generator? gen_, Tensor? glm_mask, Tensor? rng_state)
-             -> (Tensor dq, Tensor dk, Tensor dv, Tensor softmax_d)
-            """.replace(
-                    "\n", ""
-                ),
-            )
-        )
-        _flash_attn_2_cuda_lib.define(
-            re.sub(
-                r"\s+",
-                " ",
-                f"""
-            fa2_varlen_bwd(Tensor dout, Tensor q, Tensor k, Tensor v, Tensor out,
-            Tensor softmax_lse, Tensor? dq_, Tensor? dk_, Tensor? dv_,
-            Tensor cu_seqlens_q, Tensor cu_seqlens_k, int max_seqlen_q, int max_seqlen_k,
-            float p_dropout, float softmax_scale, bool zero_tensors, bool is_causal,
-            {"int window_size_left, int window_size_right, "
-            if _flash_attn_version >= packaging.version.Version("2.3.0")
-            else ""}
-            Generator? gen_, Tensor? glm_mask, Tensor? rng_state)
-             -> (Tensor dq, Tensor dk, Tensor dv, Tensor softmax_d)
-            """.replace(
-                    "\n", ""
-                ),
-            )
-        )
-        _flash_attn_2_cuda_lib.impl("fa2_fwd", flash_attn_2_cuda.fwd, "CUDA")
-        _flash_attn_2_cuda_lib.impl("fa2_varlen_fwd", flash_attn_2_cuda.varlen_fwd, "CUDA")
-        _flash_attn_2_cuda_lib.impl("fa2_bwd", flash_attn_2_cuda.bwd, "CUDA")
-        _flash_attn_2_cuda_lib.impl("fa2_varlen_bwd", flash_attn_2_cuda.varlen_bwd, "CUDA")
-        if _flash_attn_version._version.release <= (2, 3, 6):
-            flash_attn_2_cuda.fwd = torch.ops.flash_attn_2_cuda.fa2_fwd
-            flash_attn_2_cuda.varlen_fwd = torch.ops.flash_attn_2_cuda.fa2_varlen_fwd
-            flash_attn_2_cuda.bwd = torch.ops.flash_attn_2_cuda.fa2_bwd
-            flash_attn_2_cuda.varlen_bwd = torch.ops.flash_attn_2_cuda.fa2_varlen_bwd
-        else:
-            logger.info(f"flash_attn version {_flash_attn_version} not verified for dispatcher.")
-    except (ImportError, ModuleNotFoundError):
-        logger.info("flash_attn_2_cuda lib not founded, not registering to torch dispatcher.")
-
-    try:
-        try:
-            import flash_attn_1_cuda
-        except ModuleNotFoundError:
-            import flash_attn_cuda as flash_attn_1_cuda
-        _flash_attn_1_cuda_lib = torch.library.Library("flash_attn_1_cuda", "DEF")
-        _flash_attn_1_cuda_lib.define(
-            "fa1_fwd(Tensor q, Tensor k, Tensor v, Tensor out, "
-            "Tensor cu_seqlens_q, Tensor cu_seqlens_k, "
-            "int max_seqlen_q_, int max_seqlen_k_, float p_dropout, "
-            "float softmax_scale, bool zero_tensors, bool is_causal, "
-            "bool return_softmax, int num_splits, Generator? gen_, Tensor? attn_mask, Tensor? attn_bias)"
-            " -> (Tensor softmax_lse, Tensor? s)"
-        )
-        _flash_attn_1_cuda_lib.define(
-            "fa1_bwd(Tensor dout, Tensor q, Tensor k, Tensor v, Tensor out, "
-            "Tensor softmax_lse_, Tensor dq, Tensor dk, Tensor dv, "
-            "Tensor cu_seqlens_q, Tensor cu_seqlens_k, int max_seqlen_q_, int max_seqlen_k_, "
-            "float p_dropout, float softmax_scale, bool zero_tensors, bool is_causal, "
-            "int num_splits, Generator? gen_, Tensor? attn_mask, Tensor? attn_bias)"
-            " -> (Tensor softmax_d, Tensor? dbias)"
-        )
-        _flash_attn_1_cuda_lib.impl("fa1_fwd", flash_attn_1_cuda.fwd, "CUDA")
-        _flash_attn_1_cuda_lib.impl("fa1_bwd", flash_attn_1_cuda.bwd, "CUDA")
-
-        def keep_one_tensor_list(func):
-            def _func(*args, **kwargs):
-                output = func(*args, **kwargs)
-                if isinstance(output, torch.Tensor):
-                    return [output]
-                else:
-                    return output
-
-            return _func
-
-        flash_attn_1_cuda.fwd = keep_one_tensor_list(torch.ops.flash_attn_1_cuda.fa1_fwd)
-        flash_attn_1_cuda.bwd = keep_one_tensor_list(torch.ops.flash_attn_1_cuda.fa1_bwd)
-    except (ImportError, ModuleNotFoundError):
-        logger.info("flash_attn_1_cuda lib not founded, not registering to torch dispatcher.")
-
-
 try:
     from apex.amp import _amp_state
 except (ImportError, ModuleNotFoundError):
     _amp_state = None
 
+if is_torch_npu_available():
+    from atorch.npu.layers import npu_fa_with_glm_mask
+
 
 def is_apex_amp_activate():
     if _amp_state is None:
         return False
     return hasattr(_amp_state, "opt_properties") and _amp_state.opt_properties.enabled
 
 
 def is_additive_mask_bias_supported_fa1():
     if not _flash_attn_version or _flash_attn_version >= packaging.version.Version("2"):
         return False
+    if has_legacy_fa1:
+        flash_attn_unpadded_func = flash_attn_1_unpadded_func
     return "attn_mask" in inspect.signature(flash_attn_unpadded_func).parameters
 
 
 def is_glm_mask_supported_fa2():
+    if is_torch_npu_available():
+        return True
     if not _flash_attn_version or _flash_attn_version < packaging.version.Version("2"):
         return False
     return "glm_mask" in inspect.signature(flash_attn_func).parameters
 
 
 def is_pack_glm_mask_supported_fa2():
     if not _flash_attn_version or _flash_attn_version < packaging.version.Version("2"):
@@ -1259,35 +1163,37 @@
                 )
 
         self._register_load_state_dict_pre_hook(hook)
 
 
 def flash_attn_with_mask_bias(q, k, v, mask=None, bias=None, dropout_p=0.0, softmax_scale=None, causal=False):
     """
-    FlashAttention that support mask and bias. dropout_p should be set to 0.0 during evaluation.
-    q, k, v, mask and bias should be half precision(torch.float16 or torch.bfloat16).
+    FlashAttention that support mask. dropout_p should be set to 0.0 during evaluation.
+    q, k, v, mask should be half precision(torch.float16 or torch.bfloat16).
 
     We use the following notation:
-        batch_size: n
-        sequence_length: s_q, s_k
+        b: batch_size
+        s_q, s_k: sequence length of Q and K
         nh: number of attention heads
         hs: head dimension
 
     Args:
         q: [b, s_q, nh, hs]
         k/v: [b, s_k, nh, hs]
         mask: [b, nh or 1, s_q or 1, s_k]
-        bias: [1, nh, s_q, s_k]  # not verified yet
+        bias: [1, nh, s_q, s_k]  # not supported yet
         softmax_scale: float. The scaling of QK^T before applying softmax.
-            Default to 1 / sqrt(headdim).
+            Default to 1 / sqrt(hs).
         causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
 
     Returns:
         out:[b, s_q, nh, hs]
     """
+    if bias is not None:
+        raise NotImplementedError("FlashAttention1 does not support bias.")
     if has_legacy_fa1:
         _flash_attn_unpadded_func = flash_attn_1_unpadded_func
     else:
         _flash_attn_unpadded_func = flash_attn_unpadded_func
 
     b, s_q, nh, hs = q.shape
     _, s_k, _, _ = k.shape
@@ -1411,14 +1317,17 @@
 
         # FA2 glm_mask
         if glm_mask is not None:
             assert self.causal, "causal must be True for glm_mask"
             assert is_glm_mask_supported_fa2(), "please install glm mask supported version FA2"
             kwargs.update({"glm_mask": glm_mask})
 
+            if is_torch_npu_available():
+                return npu_fa_with_glm_mask(q, k, v, **kwargs)
+
         # FA1 additive mask
         if additive_mask is not None or additive_bias is not None:
             assert (
                 is_additive_mask_bias_supported_fa1() or has_legacy_fa1
             ), "Must be attn mask/bias supported version FlashAttn v1"
             assert not self.causal and key_padding_mask is None, "Should not causal/padding mask when additive mask"
             kwargs.update({"mask": additive_mask, "bias": additive_bias})
```

## atorch/modules/transformer/losses.py

```diff
@@ -1,15 +1,9 @@
-try:
-    import triton.language as tl  # noqa F401
-    from triton import jit  # noqa F401
-
-    HAS_TRITON = True
-except (ImportError, ModuleNotFoundError):
-    HAS_TRITON = False
+from atorch.utils.import_util import is_triton_available
 
 try:
     from flash_attn.losses.cross_entropy import CrossEntropyLoss  # noqa F401
 except (ImportError, ModuleNotFoundError):
-    if HAS_TRITON:
+    if is_triton_available():
         from .cross_entropy import AtorchCrossEntropyLoss as CrossEntropyLoss  # noqa F401
     else:
         from torch.nn import CrossEntropyLoss  # noqa F401
```

## atorch/normalization/layernorm.py

```diff
@@ -1,18 +1,16 @@
 import torch
 
-try:
+from atorch.utils.import_util import is_triton_available
+
+if is_triton_available():
     import triton
     import triton.language as tl
     from triton import jit
-
-    HAS_TRITON = True
-except (ImportError, ModuleNotFoundError):
-    HAS_TRITON = False
-    triton = None
+else:
 
     class Library(object):
         constexpr = int
 
     tl = Library
     from functools import wraps as jit
 
@@ -199,15 +197,15 @@
             GROUP_SIZE_M = 256
         # allocate output
         # dy = dy.to(torch.float32)
         locks = torch.zeros(2 * GROUP_SIZE_M, dtype=torch.int32, device="cuda")
         # TODO: dtype=x.dtype will loss precision; but dtype=torch.float32 will be slow
         _dw = torch.empty((GROUP_SIZE_M, w.shape[0]), dtype=x.dtype, device=w.device)
 
-        # need store fp32 to keep acc
+        ## need store fp32 to keep acc
         dw = torch.empty((w.shape[0],), dtype=w.dtype, device=w.device)
         # db = torch.zeros((w.shape[0],), dtype=x.dtype, device=w.device)
         dx = torch.empty_like(dy)
         # enqueue kernel using forward pass heuristics
         # also compute partial sums for DW and DB
         x_arg = x.reshape(-1, x.shape[-1])
         M, N = x_arg.shape
@@ -241,13 +239,13 @@
         else:
             db = None
         return dx, None, dw, db, None
 
 
 class AtorchLayerNorm(torch.nn.LayerNorm):
     def __init__(self, *args, **kwargs):
-        if not HAS_TRITON:
-            raise RuntimeError("Triton is not installed. Atorch LayerNorm need it")
+        if not is_triton_available():
+            raise RuntimeError("Triton is not installed. AtorchLayerNorm need it")
         return super().__init__(*args, **kwargs)
 
     def forward(self, input):
         return AtorchLayerNormFunc.apply(input, self.normalized_shape, self.weight, self.bias, self.eps)
```

## atorch/npu/__init__.py

```diff
@@ -1,19 +1,25 @@
 import traceback
 from typing import Optional, Union
 
+import torch
+
 from atorch.common.log_utils import default_logger as logger
+from atorch.utils.import_util import is_torch_npu_available
 
 try:
-    import deepspeed_npu
+    if hasattr(torch.device, "__enter__"):
+        # NPU bug. Activate DeviceContext before importing torch_npu
+        with torch.device("meta"):
+            _ = torch.tensor((1.0))
     import torch_npu
     from torch_npu.contrib import transfer_to_npu
 except (ModuleNotFoundError, ImportError):
     logger.error(f"{traceback.format_exc()}")
-import torch
+
 
 _device_t = Union[torch.device, str, int, None]
 old_device_capability = torch.cuda.get_device_capability
 
 
 def new_device_capability(device: Optional[_device_t] = None):
     """
@@ -36,39 +42,38 @@
     else:
         return old_device_capability(device)
 
 
 new_device_capability.__doc__ = old_device_capability.__doc__
 
 
-def npu_profile_context(*args, **kwargs):
-    if "experimental_config" not in kwargs:
-        kwargs["experimental_config"] = torch_npu.profiler._ExperimentalConfig(
-            aic_metrics=torch_npu.profiler.AiCMetrics.PipeUtilization,
-            profiler_level=torch_npu.profiler.ProfilerLevel.Level1,
-            l2_cache=False,
-            record_op_args=True,
-            data_simplification=False,
-        )
-    return torch_npu.profiler.profile(*args, **kwargs)
-
-
 def make_atorch_npu_patch():
     # todo: can't create same device on multiprocessing?
     device = torch.device("npu")
     # # if there is no npu device, there will not make patch
     if torch.npu.get_device_capability(device) is None:
         torch.npu.get_device_capability = new_device_capability
         torch.cuda.get_device_capability = new_device_capability
 
-    torch.profiler.profile = npu_profile_context
-    reset_attrs = ["ProfilerActivity", "tensorboard_trace_handler", "schedule"]
-    for attr in reset_attrs:
-        if hasattr(torch.profiler, attr):
-            delattr(torch.profiler, attr)
-        setattr(torch.profiler, attr, getattr(torch_npu.profiler, attr))
+    try:
+        import transformers
+        from packaging import version
+
+        old_is_torch_bf16_gpu_available = transformers.utils.is_torch_bf16_gpu_available
+
+        def npu_is_torch_bf16_gpu_available():
+            if is_torch_npu_available():
+                return torch.npu.get_device_name() == "Ascend910B2"
+            else:
+                return old_is_torch_bf16_gpu_available()
+
+        # transformers does not recognize that 910B support bf16 until 4.35.0
+        if version.parse(transformers.__version__) < version.parse("4.35.0"):
+            setattr(transformers.utils, "is_torch_bf16_gpu_available", npu_is_torch_bf16_gpu_available)
+    except (ModuleNotFoundError, ImportError):
+        logger.error(f"{traceback.format_exc()}")
 
 
 try:
     make_atorch_npu_patch()
 except Exception:
     logger.error(f"{traceback.format_exc()}")
```

## atorch/npu/optim.py

```diff
@@ -1,12 +1,17 @@
 from typing import List, Optional, Tuple, Union
 
 import torch
 from torch import Tensor
-from torch.optim.optimizer import _default_to_fused_or_foreach, _get_value, _use_grad_for_differentiable, params_t
+from torch.optim.optimizer import (  # type: ignore[attr-defined]
+    _default_to_fused_or_foreach,
+    _get_value,
+    _use_grad_for_differentiable,
+    params_t,
+)
 
 from atorch.utils.import_util import is_torch_npu_available
 
 if is_torch_npu_available():
     import torch_npu
```

## atorch/ops/git_version_info_installed.py

```diff
@@ -1,6 +1,6 @@
-version = '0.1.7+b9ec680b'
-git_hash = 'b9ec680b'
-git_branch = '_add_fp8'
+version = '0.1.8+1ce9b881'
+git_hash = '1ce9b881'
+git_branch = 'master'
 installed_ops = {'quantization_optimizer': False, 'quantizer': False}
 compatible_ops = {'quantization_optimizer': True, 'quantizer': True, 'atorch_not_implemented': False}
-torch_info = {'version': '1.12', 'bf16_support': False, 'cuda_version': '11.3', 'nccl_version': '2.10'}
+torch_info = {'version': '1.13', 'bf16_support': False, 'cuda_version': '11.6', 'nccl_version': '2.14'}
```

## atorch/optimizers/agd.py

```diff
@@ -1,10 +1,9 @@
 from typing import Any, Callable, Dict, Iterable, Optional, Tuple, Union
 
-import numpy as np
 import torch
 from torch import Tensor
 
 Params = Union[Iterable[Tensor], Iterable[Dict[str, Any]]]
 
 LossClosure = Callable[[], float]
 OptLossClosure = Optional[LossClosure]
@@ -96,15 +95,15 @@
                     else:
                         if group["weight_decay"] != 0:
                             grad.add_(p.data, alpha=group["weight_decay"])
 
                 state = self.state[p]
                 # Lazy state initialization
                 if len(state) == 0:
-                    state["step"] = 0
+                    state["step"] = torch.tensor(0.0, device=p.device)
                     # Exponential moving average of gradient values
                     state["exp_avg"] = torch.zeros_like(p, memory_format=torch.preserve_format)
                     # Exponential moving average of squared gradient values
                     state["exp_avg_sq"] = torch.zeros_like(p, memory_format=torch.preserve_format)
                     if group["amsgrad"]:
                         # Maintains max of all exp. moving avg. of sq. grad. values
                         state["max_exp_avg_sq"] = torch.zeros_like(p, memory_format=torch.preserve_format)
@@ -134,18 +133,18 @@
                 if group["amsgrad"]:
                     max_exp_avg_sq = state["max_exp_avg_sq"]
                     torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)
                     update = max_exp_avg_sq.sqrt()
                 else:
                     update = exp_avg_sq.sqrt()
 
-                delta_adjust = group["delta"] * np.sqrt(bias_correction2)
-                update.clamp_(min=delta_adjust)
+                delta_adjust = group["delta"] * bias_correction2.sqrt()
+                update.clamp_(min=delta_adjust.to(update.device))
 
-                lr_adjust = group["lr"] * np.sqrt(bias_correction2) / bias_correction1
+                lr_adjust = group["lr"] * bias_correction2.sqrt() / bias_correction1
                 update = exp_avg / update
                 if group["clip"] is not None:
                     update.clamp_(min=-group["clip"], max=group["clip"])
                 if not group["win"]:
                     p.data.add_(update, alpha=-lr_adjust)
                 else:
                     z = state["z"]
```

## atorch/trainer/atorch_args.py

```diff
@@ -46,16 +46,17 @@
         metadata={
             "help": (
                 "Whether to use `auto_accelerate()` to wrap dataloader."
                 "If you want to use Trainer's get_train_dataloader(), set --use_atorch_dataloader False."
             )
         },
     )
-    loss_func: Optional[Callable] = field(
-        default=None,
+    shuffle: bool = field(default=True, metadata={"help": "If `True` (default), dataloader will shuffle the data."})
+    optim_func: Optional[Callable] = field(
+        default=torch.optim.AdamW,
         metadata={
             "help": (
                 "optim_func can be a pytorch built-in optimizer function or a user-defined function, with params and"
                 "optim_args as arguments. such as:"
                 "def optim_func(parameters, **optim_args):"
                 "    return optim.SGD(parameters, **optim_args)"
                 "The optimizer will be created by optim_func(model.parameters(), **optim_args)."
@@ -66,14 +67,26 @@
         default=None,
         metadata={"help": 'A dict of arguments used for optim, such as: optim_args = {"lr": 0.01, "momentum": 0.9}'},
     )
     optim_param_func: Optional[Callable] = field(
         default=None,
         metadata={"help": "Function returns an optimizer's parameters if users want to specify per-parameter options."},
     )
+    loss_func: Optional[Callable] = field(
+        default=None,
+        metadata={
+            "help": (
+                "loss function for loss calculation from model input and output, such as:"
+                "def loss_func(input, output):"
+                "    loss = nn.MSELoss()"
+                '    return loss(input["label"], output)'
+                "This function either returns a loss value, or a list/tuple with the first value as loss."
+            )
+        },
+    )
     prepare_input: Optional[Callable] = field(
         default=None,
         metadata={
             "help": (
                 "This is a function taken data and device as arguments."
                 "Call this function on data generated from dataloader before model input."
             )
@@ -105,15 +118,15 @@
     finetune_strategy: bool = field(
         default=False, metadata={"help": "If True and `load_strategy` is not None, finetune the loaded strategy."}
     )
     save_strategy_to_file: Optional[str] = field(
         default=None, metadata={"help": "If not None, a file name for saving the acceleration strategy."}
     )
 
-    atorch_checkpoint_cls: Optional[Tuple[Callable]] = field(
+    atorch_checkpoint_cls: Optional[Tuple[Union[Callable, str]]] = field(
         default=None,
         metadata={
             "help": (
                 "Tuple of module classes for gradient checkpointing. Applicable when --gradient_checkpointing is set."
             )
         },
     )
@@ -130,21 +143,21 @@
 
     ignore_write_errors: bool = field(
         default=False, metadata={"help": ("Whether to ignore write errors when writting to disk.")}
     )
 
     async_save: bool = field(default=False, metadata={"help": ("Whether to use multiprocess to save model.")})
 
-    atorch_lr_scheduler_type: Union[AtorchSchedulerType, str] = field(
+    atorch_lr_scheduler_type: Optional[Union[AtorchSchedulerType, str]] = field(
         default=None,
         metadata={"help": "The custom scheduler type to use."},
     )
 
     # ATorch FSDP config
-    atorch_wrap_cls: Optional[Tuple[Callable]] = field(
+    atorch_wrap_cls: Optional[Tuple[Union[Callable, str]]] = field(
         default=None, metadata={"help": "Tuple of module classes to wrap with fsdp."}
     )
     cpu_offload: bool = field(default=False, metadata={"help": "Whether to use cpu_offload"})
     use_orig_params: bool = field(default=True, metadata={"help": "Whether to use_orig_params"})
     wrap_trainable_outmost: bool = field(default=False, metadata={"help": "Whether to wrap_trainable_outmost"})
     sync_module_states: bool = field(default=True, metadata={"help": "Whether to sync_module_states"})
     limit_all_gathers: bool = field(default=True, metadata={"help": "Whether to limit_all_gathers"})
@@ -202,27 +215,28 @@
                     d[k] = [x.__name__ if hasattr(x, "__name__") else str(x) for x in v]
             elif isinstance(v, tuple) and len(v) > 0 and isinstance(v[0], Callable):
                 v = [x.__name__ if hasattr(x, "__name__") else str(x) for x in v]
                 d[k] = tuple(v)
         return d
 
     def __post_init__(self):
-        # set logging_dir for AntMonitor
-        if self.logging_dir is None:
-            tensorboard_path = os.getenv("ATORCH_TENSORBOARD_PATH")
-            tensorboard_path = os.path.expandvars(tensorboard_path) if tensorboard_path else None
-            self.logging_dir = tensorboard_path
+        # Check arguments in transformers.training_args.TrainingArguments
+        if self.report_to is not None:
+            if self.report_to == "all" or self.report_to == ["all"]:
+                logger.info("AtorchTrainer only support TensorBoard to report the results and logs.")
+            elif self.report_to != "tensorboard" and self.report_to != ["tensorboard"]:
+                raise ValueError("AtorchTrainer only support TensorBoard to report the results and logs.")
 
         # check lr_scheduler_type
         if self.atorch_lr_scheduler_type is not None and self.atorch_lr_scheduler_type not in ATORCHSCHEDULER_NAMES:
             raise ValueError(
                 f"lr_scheduler_type={self.atorch_lr_scheduler_type} is invalid, please select one of "
                 f"{SCHEDULER_NAMES + ATORCHSCHEDULER_NAMES}."
             )
 
-        super().__post_init__()
-
         if self.atorch_wrap_cls is not None and not isinstance(self.atorch_wrap_cls, tuple):
             raise ValueError(f"atorch_wrap_cls has {type(self.atorch_wrap_cls)} type, required tuple type.")
 
         if self.atorch_checkpoint_cls is not None and not isinstance(self.atorch_checkpoint_cls, tuple):
             raise ValueError(f"atorch_checkpoint_cls has {type(self.atorch_checkpoint_cls)} type, required tuple type.")
+
+        Seq2SeqTrainingArguments.__post_init__(self)
```

## atorch/trainer/atorch_trainer.py

```diff
@@ -13,15 +13,14 @@
 import random
 import re
 import shutil
 import sys
 import time
 import warnings
 from collections.abc import Mapping
-from functools import partial
 from pathlib import Path
 from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union
 
 import datasets
 import numpy as np
 import psutil
 import safetensors
@@ -38,23 +37,27 @@
 from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler
 from transformers import __version__
 from transformers.configuration_utils import PretrainedConfig
 from transformers.data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator
 
 import atorch
 from atorch.auto import auto_accelerate
+from atorch.auto.accelerate import get_strategy
+from atorch.auto.strategy import Strategy
 from atorch.distributed.distributed import is_distributed
 from atorch.trainer.atorch_args import AtorchArguments
 from atorch.utils.fsdp_save_util import ShardOptim, save_fsdp_flat_param, save_fsdp_optim_param
+from atorch.utils.hooks import ATorchHooks
+from atorch.utils.import_util import is_torch_npu_available
 from atorch.utils.trainer_utils import AsyncCheckpointSignal, PipeMessageEntity, get_scheduler
 from atorch.utils.version import torch_version
 
 # Integrations must be imported before ML frameworks:
 # isort: off
-from transformers.integrations import get_reporting_integration_callbacks
+from transformers.integrations import TensorBoardCallback
 
 # isort: on
 from transformers.modeling_utils import PreTrainedModel, load_sharded_checkpoint, unwrap_model
 from transformers.tokenization_utils_base import PreTrainedTokenizerBase
 from transformers.trainer import OPTIMIZER_NAME, SCALER_NAME, SCHEDULER_NAME, TRAINER_STATE_NAME, TRAINING_ARGS_NAME
 from transformers.trainer_callback import (
     CallbackHandler,
@@ -105,14 +108,16 @@
 
 PEFT_PARAM_PREFIX = "base_model.model."
 LORA_KEY = "lora"
 STREAMING_CKPT_DIR = "streaming_ckpt"  # save/load dir for Atorch's FSDP
 
 logger = logging.getLogger(__name__)
 
+additional_tensorboard_hook = ATorchHooks.hooks.get(ATorchHooks.ADDITIONAL_TENSORBOARD_HOOK)
+
 
 def count_model_params(model):
     trainable_params = 0
     all_params = 0
     for param in model.parameters():
         num_params = param.numel()
         all_params += num_params
@@ -131,15 +136,15 @@
         eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]] = None,
         tokenizer: Optional[PreTrainedTokenizerBase] = None,
         model_init: Optional[Callable[[], PreTrainedModel]] = None,
         compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,
         callbacks: Optional[List[TrainerCallback]] = None,
         optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),
         preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,
-        load_strategy: Optional[List[Union[str, Tuple]]] = None,
+        load_strategy: Optional[Union[str, bytes, Strategy, List]] = None,
         **kwargs,
     ):
         if args is None:
             output_dir = "tmp_atorch_trainer"
             logger.info(f"No `AtorchArguments` passed, using `output_dir={output_dir}`.")
             args = AtorchArguments(output_dir=output_dir)  # type: ignore[call-arg]
 
@@ -148,17 +153,21 @@
                 "--sharded_ddp, --fsdp, --deepspeed in `TrainingArguments` is invalid when using `AtorchArguments`."
             )
 
         self.args = args
         self.kwargs = kwargs
         self.model = model
 
-        self.atorch_fsdp = args.atorch_opt == "fsdp"
+        self.atorch_fsdp = args.atorch_opt == "fsdp" and self.args.world_size > 1
+
+        if self.args.save_load_by_streaming and self.args.world_size == 1:
+            logger.warning("FSDP is unnecessary on only one device, so `save_load_by_streaming` will be set to False.")
+            self.args.save_load_by_streaming = False
 
-        if self.atorch_fsdp and torch_version() < (2, 0, 0):
+        if self.atorch_fsdp and torch_version() < (2, 0, 0):  # type: ignore
             raise ValueError("Greater than version 2.0 of PyTorch is necessary for FSDP.")
 
         if args.save_load_by_streaming and not self.atorch_fsdp:
             raise ValueError("--atorch_opt fsdp is needed when using --save_load_by_streaming.")
 
         # create accelerator object
         self.accelerator = Accelerator()
@@ -175,17 +184,27 @@
         self.train_dataset = train_dataset
         self.eval_dataset = eval_dataset
         self.tokenizer = tokenizer
 
         self.model_init = model_init
         self.compute_metrics = compute_metrics
         self.preprocess_logits_for_metrics = preprocess_logits_for_metrics
-        self.optimizer, self.lr_scheduler = optimizers
 
-        default_callbacks = DEFAULT_CALLBACKS + get_reporting_integration_callbacks(self.args.report_to)
+        self.optimizer, self.lr_scheduler = optimizers
+        # Check optimizer and lr_scheduler
+        if self.optimizer is not None and not isinstance(self.optimizer, torch.optim.Optimizer):
+            raise ValueError("`optimizer` must be the torch.optim.Optimizer type.")
+        if self.lr_scheduler is not None and not isinstance(self.lr_scheduler, torch.optim.lr_scheduler.LambdaLR):
+            raise ValueError("`lr_scheduler` must be the torch.optim.lr_scheduler.LambdaLR type.")
+
+        report_callbacks = [TensorBoardCallback]
+        # Add additional tensorboard callback.
+        if additional_tensorboard_hook is not None and len(additional_tensorboard_hook) > 0:
+            report_callbacks.append(additional_tensorboard_hook[0])
+        default_callbacks = DEFAULT_CALLBACKS + report_callbacks
         callbacks = default_callbacks if callbacks is None else default_callbacks + callbacks
         self.callback_handler = CallbackHandler(
             callbacks, self.model, self.tokenizer, self.optimizer, self.lr_scheduler
         )
         self.add_callback(PrinterCallback if self.args.disable_tqdm else DEFAULT_PROGRESS_CALLBACK)
 
         if self.args.should_save:
@@ -236,19 +255,20 @@
         self.control = TrainerControl()
         # Internal variable to count flos in each process, will be accumulated in `self.state.total_flos` then
         # returned to 0 every time flos need to be logged
         self.current_flos = 0
         default_label_names = find_labels(self.model.__class__)
         self.label_names = default_label_names if self.args.label_names is None else self.args.label_names
         self.model_forward_args = list(inspect.signature(self.model.forward).parameters.keys())
-        self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
 
         # Set ATorch Parameters
         self.atorch_wrap_cls = args.atorch_wrap_cls
         self.prepare_input = args.prepare_input
+        self.optim_func = args.optim_func
+        self.optim_args = args.optim_args
         self.optim_param_func = args.optim_param_func
         self.loss_func = args.loss_func
         self.distributed_sampler_cls = args.distributed_sampler_cls
         self.model_input_format = args.model_input_format
         self.load_strategy = load_strategy
 
         self.is_peft_model = isinstance(model, PeftModel)
@@ -267,14 +287,16 @@
         # Activate gradient checkpointing if needed
         if args.gradient_checkpointing and args.atorch_checkpoint_cls is None:
             self.model.gradient_checkpointing_enable()
 
         # Call ATorch's auto_accelerate() to wrap model, optimizer, loss_function, ...
         self._atorch_init()
 
+        self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
+
     def add_callback(self, callback):
         """
         Add a callback to the current list of [`~transformer.TrainerCallback`].
 
         Args:
            callback (`type` or [`~transformer.TrainerCallback`]):
                A [`~transformer.TrainerCallback`] class or an instance of a [`~transformer.TrainerCallback`]. In the
@@ -295,24 +317,21 @@
 
         Returns:
             [`~transformer.TrainerCallback`]: The callback removed, if found.
         """
         return self.callback_handler.pop_callback(callback)
 
     def _atorch_init(self):
-        if self.load_strategy is not None:
-            # TODO: check strategy format
-            pass
-        else:
+        if self.load_strategy is None:
             self.load_strategy = []
             # Set parallel mode
             if self.args.atorch_parallel_mode:
                 self.load_strategy.append(("parallel_mode", ([("data", self.args.world_size)], None)))
             # Set module replace
-            if self.args.atorch_module_replace:
+            if self.args.atorch_module_replace and not is_torch_npu_available():
                 self.load_strategy.append("module_replace")
             # Set FSDP
             if self.atorch_fsdp:
                 atorch_fsdp_config = {
                     "atorch_wrap_cls": self.atorch_wrap_cls,
                     "cpu_offload": self.args.cpu_offload,
                     "sync_module_states": self.args.sync_module_states,
@@ -329,60 +348,79 @@
                     amp_config = {"dtype": torch.bfloat16, "skip_if_nonfinite": self.args.skip_if_nonfinite}
                 else:
                     amp_config = {"dtype": torch.float16}
                 self.load_strategy.append(("amp_native", amp_config))
             if self.args.gradient_checkpointing and self.args.atorch_checkpoint_cls is not None:
                 self.load_strategy.append(("checkpoint", self.args.atorch_checkpoint_cls))
 
+        # Get load_strategy with `Strategy` type by calling get_strategy function,
+        # which can check the format of load_strategy
+        status, self.load_strategy = get_strategy(self.load_strategy)
+        if not status:
+            raise TypeError("Unsupported load_strategy, please check your load_strategy.")
+
+        # The listed methods will not change the model parameters, while other methods will.
+        optim_methods_to_check = ["parallel_mode", "amp_native", "checkpoint"]
+
+        if self.optimizer is not None:
+            for (opt_name, config, tunable) in self.load_strategy:
+                if opt_name not in optim_methods_to_check:
+                    raise ValueError(
+                        f"If you're using optimization methods outside of {optim_methods_to_check}, passing"
+                        " `optimizers=(xxx,xxx)` when creating a trainer is not supported because auto_accelerate()"
+                        " will change the model parameters. Please set `optimizers` via `args.optim_func` instead."
+                    )
+
         # atorch auto_accelerate will restore batch_size by dividing by world size.
         train_dataloader_args = {
-            "shuffle": True,
+            "shuffle": self.args.shuffle,
             "batch_size": self._train_batch_size * self.args.world_size,
             "pin_memory": self.args.dataloader_pin_memory,
             "num_workers": self.args.dataloader_num_workers,
             "persistent_workers": self.args.dataloader_num_workers > 0,
         }
 
         if self.data_collator is not None:
             train_dataloader_args["collate_fn"] = self.data_collator
 
         if not isinstance(self.train_dataset, torch.utils.data.IterableDataset):
             train_dataloader_args["drop_last"] = self.args.dataloader_drop_last
 
-        optim_args = {
-            "lr": self.args.learning_rate,
-            "weight_decay": self.args.weight_decay,
-            "eps": self.args.adam_epsilon,
-            "betas": (self.args.adam_beta1, self.args.adam_beta2),
-        }
+        if self.optim_args is None:
+            self.optim_args = {
+                "lr": self.args.learning_rate,
+                "weight_decay": self.args.weight_decay,
+                "eps": self.args.adam_epsilon,
+                "betas": (self.args.adam_beta1, self.args.adam_beta2),
+            }
 
         status, result, best_strategy = auto_accelerate(
             model=self.model,
-            optim_func=self.optimizer,
+            optim_func=self.optim_func,
             dataset=self.train_dataset if self.args.use_atorch_dataloader else None,
             distributed_sampler_cls=self.distributed_sampler_cls,
             dataloader_args=train_dataloader_args,
             loss_func=self.loss_func,
             prepare_input=self.prepare_input,
             model_input_format=self.model_input_format,
-            optim_args=optim_args,
-            optim_param_func=partial(self.optim_param_func, args=optim_args)
-            if self.optim_param_func is not None
-            else None,
+            optim_args=self.optim_args,
+            optim_param_func=self.optim_param_func if self.optim_param_func is not None else None,
+            excluded=self.args.excluded,
+            included=self.args.included,
             load_strategy=self.load_strategy,
+            finetune_strategy=self.args.finetune_strategy,
+            save_strategy_to_file=self.args.save_strategy_to_file,
             ignore_dryrun_on_load_strategy=self.args.ignore_dryrun_on_load_strategy,
             sampler_seed=self.args.seed,
         )
         assert status, f"auto_accelerate failed. status: {status}, result: {result}, best_strategy: {best_strategy}"
         logger.info(f"Best strategy is: {best_strategy}")
 
-        logger.info("Calling auto_accelerate() will wrap model, optimizer, lr_scheduler, loss_func and prepare_input")
         self.model = result.model
-        self.optimizer = result.optim
-        self.lr_scheduler = result.lr_scheduler
+        self.optimizer = self.optimizer if self.optimizer is not None else result.optim
         self.loss_func = result.loss_func
         self.train_dataloader = result.dataloader
         self.prepare_input = result.prepare_input
 
     def _set_signature_columns_if_needed(self):
         if self._signature_columns is None:
             # Inspect model forward signature to keep only the arguments it accepts.
@@ -767,14 +805,18 @@
         # Asynchronous saving model and optimizer.
         if self.args.async_save:
             self._init_async_save()
 
         total_batched_samples = 0
         for epoch in range(epochs_trained, num_train_epochs):
             epoch_iterator = train_dataloader
+            if hasattr(epoch_iterator, "set_epoch"):
+                epoch_iterator.set_epoch(epoch)
+            elif hasattr(epoch_iterator.sampler, "set_epoch"):
+                epoch_iterator.sampler.set_epoch(epoch)
 
             # Reset the past mems state at the beginning of each epoch if necessary.
             if args.past_index >= 0:
                 self._past = None
 
             steps_in_epoch = (
                 len(epoch_iterator) if len_dataloader is not None else args.max_steps * args.gradient_accumulation_steps
@@ -1187,15 +1229,15 @@
             logger.warning(
                 "Can't load optimizer and scheduler, "
                 "please check whether optimizer and scheduler checkpoint files exist."
             )
             return
 
         map_location = self.args.device if self.args.world_size > 1 else "cpu"
-        if self.atorch_fsdp:
+        if self.atorch_fsdp and isinstance(self.model, FSDP):
             if self.args.save_load_by_streaming:
                 if not os.path.isdir(streaming_ckpt_dir):
                     raise FileNotFoundError(f"Can't find {streaming_ckpt_dir} directory!")
                 logger.info("Begin to load optimizer by streaming")
                 sm = ShardOptim(streaming_ckpt_dir)
                 reshard_optim_state = sm.reshard_optim_state_dict(self.model)
                 self.optimizer.load_state_dict(reshard_optim_state)
@@ -1287,17 +1329,15 @@
 
         # Save model
         if not self.save_model(output_dir, _internal_call=True):
             return False
 
         # Save optimizer and scheduler
         full_osd = None
-        if self.atorch_fsdp:
-            if not isinstance(self.model, FSDP):
-                raise ValueError("Self.model is not 'FullyShardedDataParallel' type when using --atorch_opt 'fsdp'.")
+        if self.atorch_fsdp and isinstance(self.model, FSDP):
             if self.args.save_load_by_streaming:
                 streaming_ckpt_dir = os.path.join(output_dir, STREAMING_CKPT_DIR)
                 if not self._write_safely(os.makedirs, streaming_ckpt_dir, exist_ok=True):
                     return False
                 logger.info(f"Saving optimizer in {streaming_ckpt_dir}")
                 if self._write_safely(
                     save_fsdp_optim_param,
@@ -1347,18 +1387,15 @@
         Will only save from the main process.
         """
         if output_dir is None:
             output_dir = self.args.output_dir
         if not self._write_safely(os.makedirs, output_dir, exist_ok=True):
             return False
 
-        if self.atorch_fsdp:
-            # Check if model is FSDP type
-            if not isinstance(self.model, FSDP):
-                raise ValueError("Self.model is not 'FullyShardedDataParallel' type when using --atorch_opt 'fsdp'.")
+        if self.atorch_fsdp and isinstance(self.model, FSDP):
             if self.args.save_load_by_streaming:
                 if isinstance(unwrap_model(self.model), PeftModel):
                     raise ValueError(
                         "Non-PeftModel is required when using Atorch's streaming save function `save_fsdp_flat_param`."
                     )
                 streaming_ckpt_dir = os.path.join(output_dir, STREAMING_CKPT_DIR)
                 if not self._write_safely(os.makedirs, streaming_ckpt_dir, exist_ok=True):
@@ -1424,15 +1461,15 @@
             model = unwrap_model(self.model)
             if isinstance(model, supported_classes):
                 if not self._write_safely(
                     model.save_pretrained,
                     output_dir,
                     state_dict=state_dict,
                     safe_serialization=self.args.save_safetensors,
-                    global_step=self.state.global_step,
+                    max_shard_size=self.args.max_shard_size,
                 ):
                     return False
                 if isinstance(model, PeftModel) and self.args.save_base_model:
                     base_model = model.get_base_model()
                     # Filter the peft params ...
                     param_keys = list(state_dict.keys())
                     base_model_state_dict = {}
@@ -1447,14 +1484,15 @@
                             base_model_state_dict[key] = value
                     logger.info(f"Saving base model checkpoint to {output_dir}")
                     if not self._write_safely(
                         base_model.save_pretrained,
                         output_dir,
                         state_dict=base_model_state_dict,
                         safe_serialization=self.args.save_safetensors,
+                        max_shard_size=self.args.max_shard_size,
                     ):
                         return False
             else:
                 logger.info("Trainer.model is not a `PreTrainedModel`, only saving its state dict.")
                 if self.args.save_safetensors:
                     if not self._write_safely(
                         safetensors.torch.save_file,
@@ -1467,14 +1505,15 @@
                         return False
         else:
             if not self._write_safely(
                 self.model.save_pretrained,
                 output_dir,
                 state_dict=state_dict,
                 safe_serialization=self.args.save_safetensors,
+                max_shard_size=self.args.max_shard_size,
             ):
                 return False
 
         # Save tokenizer
         if self.tokenizer is not None:
             if not self._write_safely(self.tokenizer.save_pretrained, output_dir):
                 return False
@@ -1959,18 +1998,21 @@
         self.pipe1.send(PipeMessageEntity(AsyncCheckpointSignal.SAVE_OVER, os.getpid()))
         return save_success
 
     def _terminate_process_by_pid(self, pid: int, exec_join: bool = False):
         try:
             p = psutil.Process(pid)
             if exec_join:
-                p.join(timeout=1000)
+                p.wait(timeout=1000)
             p.terminate()
         except psutil.NoSuchProcess:
             logger.info(f"No process found with PID {pid}, maybe was terminated.")
+        except psutil.TimeoutExpired:
+            logger.info(f"Wait for process {pid} to finish timed out.")
+            p.terminate()
         except Exception:
             if self.args.ignore_write_errors:
                 logging.exception(f"Error occured when getting process handle by PID {pid}!")
             else:
                 raise
 
     def _async_save(self, save_func, *args, **kwargs):
@@ -2030,15 +2072,17 @@
             elif recv.signal_type == AsyncCheckpointSignal.TRAIN_OVER:
                 logger.info("Join all saving processes!")
                 # Join for all save processes
                 for pid, ckpt in self.writing_processes.items():
                     self._terminate_process_by_pid(pid, exec_join=True)
                 break
             else:
-                raise ValueError("Receive error signal type! Signal type should be from `AsyncCheckpointSignal`.")
+                raise ValueError(
+                    f"Receive error signal type! Signal type should be one of {AsyncCheckpointSignal._member_names_}."
+                )
 
     def _init_async_save(self):
         if self.args.save_strategy != IntervalStrategy.NO and self.args.should_save:
             self.data_manager = Manager()
 
             # Duplex Pipe for inter-process communication
             self.pipe1, self.pipe2 = Pipe()
```

## atorch/utils/fsdp_init_util.py

```diff
@@ -30,17 +30,17 @@
     ignore_ckpt_version: boot, flat ckpt version, current support 2 versions in [0,1]
 
     It is dangerous to patch core functions in FSDP, so we only support pt2.1.0.
     """
     version = torch.version.git_version
     if version == "7bcf7da3a268b435777fe87c7794c382f444e86d":
         RestoreFlatParamHandle.GLOBAL_CONFIG.build_ckpt_util(ckpt_path, wrap_class, top_model)
-        if not RestoreFlatParamHandle.GLOBAL_CONFIG.compare_wrap_class(
-            check_module=check_module, ignore_ckpt_version=ignore_ckpt_version
-        ):
+        if not check_module:
+            logger.warn("Ignore module checkint, make sure your wrap class in FSDP is same")
+        elif not RestoreFlatParamHandle.GLOBAL_CONFIG.compare_wrap_class(ignore_ckpt_version=ignore_ckpt_version):
             ckpt_wrap_class: List[Tuple[str, str]] = list(
                 RestoreFlatParamHandle.GLOBAL_CONFIG.ckpt_util.ckpt_meta["wrap_class"]
             )
             raise FlatCkptError(
                 f"wrap class mismatch ckpt({ckpt_wrap_class}) vs model({wrap_class}",
                 ErrorCode.CHECKPOINT_WRAP_CLASS_MISMATCH,
             )
@@ -73,24 +73,24 @@
         """This will build util of flat ckpt and get all init order of FSDP."""
         self.ckpt_path = ckpt_path
         self.wrap_class = set(wrap_class) if isinstance(wrap_class, collections.Sequence) else {wrap_class}
         self.top_model = top_model
         self.ckpt_util = ShardTensorUtil(self.ckpt_path, rank(), world_size(), device="cpu")
         self.ckpt_util.get_fsdp_init_order(self.top_model, self.wrap_class, build_fsdp_load_map=False)
 
-    def compare_wrap_class(self, check_module, ignore_ckpt_version=False):
+    def compare_wrap_class(self, ignore_ckpt_version=False):
         assert self.wrap_class is not None  # mypy
         wrap_class_config: List[Tuple[str, str]] = [(i.__module__, i.__name__) for i in self.wrap_class]
         ckpt_wrap_class: List[Tuple[str, str]] = list(self.ckpt_util.ckpt_meta["wrap_class"])
 
         if self.ckpt_util.ckpt_meta["version"] == 0:
             logger.warn("Meet old flat ckpt, make sure your wrap class in FSDP is same")
             return ignore_ckpt_version
-        sorted(wrap_class_config, key=lambda x: ".".join(x) if check_module else lambda x: x[1])
-        sorted(ckpt_wrap_class, key=lambda x: ".".join(x) if check_module else lambda x: x[1])
+        sorted(wrap_class_config, key=lambda x: ".".join(x))
+        sorted(ckpt_wrap_class, key=lambda x: ".".join(x))
         return wrap_class_config == ckpt_wrap_class
 
     def enable(self):
         """Check enable of not"""
         return all(i is not None for i in vars(self).values())
```

## atorch/utils/fsdp_save_util.py

```diff
@@ -230,26 +230,41 @@
             'param_offsets': (0, 26806271),
             'pad': 0,
             'rank': 0,
             'striped_fsdp_name': '',
             'flat_numel': 26806272
         }
     """
+    params, buffers, metas, ckpt_meta = get_flat_model_param(model)
+    _persist_flat_model_param(path, params, buffers, metas, ckpt_meta)
+
+
+def get_flat_model_param(model):
+    """
+    Get flat param and meta info of each fsdp units.
+    This is only working on `use_orig_param` is True.
+
+    Returns:
+        params (dict[str, flat_param]): the parameters of FSDP units.
+        buffers (dict): from model.named_buffers().
+        metas (dict): contains flat_param_meta and param_meta.
+        ckpt_meta: the meta of checkpoint contains the version and the world size.
+    """
     check_is_support(model)
     fsdp_units = [
         m
         for m in model.named_modules()
         if isinstance(m[1], torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel)
     ]
     metas = {"flat_param_meta": {}, "param_meta": {}}
     param_meta = metas["param_meta"]
     flat_param_meta = metas["flat_param_meta"]
     params = {}
-    buffers = {clean_tensor_name(k): v for k, v in model.named_buffers()}
     data_group = parallel_group("data")
+    buffers = {clean_tensor_name(k): v for k, v in model.named_buffers()}
     wrap_class = set()
     for fsdp_name, fsdp_unit in fsdp_units:
         fsdp_flat_handle = get_handle(fsdp_unit)
         meta = fsdp_flat_handle.shard_metadata()
         flat_param = fsdp_flat_handle.flat_param
         pad = flat_param._shard_numel_padded
 
@@ -279,40 +294,54 @@
 
             param_meta[global_name] = each
         params[name] = flat_param
         if fsdp_name:
             origin_module = fsdp_unit._fsdp_wrapped_module
             wrap_class.add((origin_module.__class__.__module__, origin_module.__class__.__name__))
 
+    ckpt_meta = {"version": CKPT_VERSION, "world_size": dist.get_world_size(), "wrap_class": wrap_class}
+    return params, buffers, metas, ckpt_meta
+
+
+def _persist_flat_model_param(path, params, buffers, flat_meta, ckpt_meta):
+    """Persit the flat model parameters into the storage."""
     d = Path(path)
     d.mkdir(parents=True, exist_ok=True)
+    data_group = parallel_group("data")
     suffix = f"{str(dist.get_rank(data_group)).zfill(5)}-{str(dist.get_world_size(data_group)).zfill(5)}"
     safetensors_dump(params, f"{path}/flat_param.{suffix}")
     if dist.get_rank(data_group) == 0:
         safetensors_dump(buffers, f"{path}/buffers")
     with open(f"{path}/flat_meta.{suffix}", "wb") as f:
-        pickle.dump(metas, f)
-
-    if dist.get_rank() != 0:
-        return
+        pickle.dump(flat_meta, f)
 
-    with open(f"{path}/ckpt_meta", "wb") as f:
-        meta = {"version": CKPT_VERSION, "world_size": dist.get_world_size(), "wrap_class": wrap_class}
-        pickle.dump(meta, f)
+    if dist.get_rank() == 0:
+        with open(f"{path}/ckpt_meta", "wb") as f:
+            pickle.dump(ckpt_meta, f)
 
 
 def save_fsdp_optim_param(model, optimizer, path):
     """Save state of optimizer for each FSDP unit. This func is only support FSDP with `use_orig_params`
     Structure of save path describe as below, it includes 2 parts:
         1. optim_meta, which saves param_groups and others hyperparameters, saved by pickle
         2. optim_param.<rank>-<world_size>, which saves optimizer's state or each FSDP unit, saved by safetensors.
+    The structure of checkpoint in the storage is like
     ├── optim_meta
     ├── optim_param.00000-00002
     └── optim_param.00001-00002
+    """
+    optim_state, param_groups = get_fsdp_optim_param(model, optimizer)
+    _persist_optim_param(path, optim_state, param_groups)
+
 
+def get_fsdp_optim_param(model, optimizer):
+    """Get the state of optimizer for each FSDP unit. This func is only support FSDP with `use_orig_params`
+    Structure of save path describe as below, it includes 2 parts:
+        1. optim_meta, which saves param_groups and others hyperparameters, saved by pickle
+        2. optim_param.<rank>-<world_size>, which saves optimizer's state or each FSDP unit, saved by safetensors.
     """
     check_is_support(model)
     param_mappings = {}
     start_index = 0
     param_to_names = {v: clean_tensor_name(k) for k, v in model.named_parameters()}
     optim_state = optimizer.state_dict()
 
@@ -326,23 +355,28 @@
         packed["params_names"] = {param_mappings[id(p)]: param_to_names[p] for p in group["params"]}
         start_index += len(packed["params"])
         return packed
 
     param_groups = [pack_group(g) for g in optimizer.param_groups]
     optim_param_idx_to_name = {}
     _ = [optim_param_idx_to_name.update(i["params_names"]) for i in param_groups]
-    d = Path(path)
-    d.mkdir(parents=True, exist_ok=True)
     flat_state = {optim_param_idx_to_name[k]: v for k, v in optim_state["state"].items()}
-    save_state = {}
+    optim_state = {}
     for name, state in flat_state.items():
-        save_state.update({f"{name}-{k}": v for k, v in state.items()})
+        optim_state.update({f"{name}-{k}": v for k, v in state.items()})
+    return optim_state, param_groups
+
+
+def _persist_optim_param(path, optim_state, param_groups):
+    """Persit the optimizer parameters into the storage."""
+    d = Path(path)
+    d.mkdir(parents=True, exist_ok=True)
     data_group = parallel_group("data")
     suffix = f"{str(dist.get_rank(data_group)).zfill(5)}-{str(dist.get_world_size(data_group)).zfill(5)}"
-    safetensors_dump(save_state, f"{path}/optim_param.{suffix}")
+    safetensors_dump(optim_state, f"{path}/optim_param.{suffix}")
     if dist.get_rank(data_group) == 0:
         with open(f"{path}/optim_meta", "wb") as f:
             pickle.dump(param_groups, f)
 
 
 class ShardOptim:
     class ShardFlatManager:
```

## atorch/utils/grad_scaler.py

```diff
@@ -2,15 +2,15 @@
 
 import torch.distributed as dist
 from torch.cuda.amp import GradScaler
 
 from atorch.common.log_utils import default_logger as logger
 from atorch.utils.version import torch_version
 
-if torch_version() >= (1, 12, 0):
+if torch_version() >= (1, 12, 0):  # type: ignore
     from torch.distributed.fsdp.sharded_grad_scaler import ShardedGradScaler
 else:
     from fairscale.optim.grad_scaler import ShardedGradScaler
 
 
 class BF16GradScaler(GradScaler):
     def __init__(self, init_scale=2.0**16, growth_factor=2.0, backoff_factor=0.5, growth_interval=2000, enabled=True):
```

## atorch/utils/hooks.py

```diff
@@ -1,14 +1,15 @@
 from enum import auto
 from typing import Callable, Dict, List
 
 
 class ATorchHooks(object):
     COMPUTE_GPU_UTIL_HOOK = auto()
     REPORT_METRICS_HOOK = auto()
+    ADDITIONAL_TENSORBOARD_HOOK = auto()
 
     # hooks stored as dict, key for hook_type, value for corresponding hook list.
     hooks: Dict[auto, List[Callable]] = {}
 
     @staticmethod
     def register_hook(hook_type, hook_func):
         if hook_type not in ATorchHooks.hooks:
```

## atorch/utils/import_util.py

```diff
@@ -35,7 +35,13 @@
         try:
             # Will raise a RuntimeError if no NPU is found
             _ = torch.npu.device_count()
             return torch.npu.is_available()
         except RuntimeError:
             return False
     return hasattr(torch, "npu") and torch.npu.is_available()
+
+
+def is_triton_available():
+    if importlib.util.find_spec("triton") is None or importlib.util.find_spec("triton.language") is None:
+        return False
+    return True
```

## atorch/utils/numberic_checker.py

```diff
@@ -16,15 +16,15 @@
         return args_or_kwargs
 
 
 def move_to_same_device(args_or_kwargs1, args_or_kwargs2):
 
     if isinstance(args_or_kwargs1, (list, tuple)):  # they can be list or tuple
         return [move_to_same_device(arg1, arg2) for arg1, arg2 in zip(args_or_kwargs1, args_or_kwargs2)]
-    assert type(args_or_kwargs1) == type(args_or_kwargs2), "type not same: %s,%s" % (
+    assert type(args_or_kwargs1) is type(args_or_kwargs2), "type not same: %s,%s" % (
         type(args_or_kwargs1),
         type(args_or_kwargs2),
     )
     if isinstance(args_or_kwargs1, dict):
         return {
             k: move_to_same_device(v1, v2) for (k, v1), (_, v2) in zip(args_or_kwargs1.items(), args_or_kwargs2.items())
         }
```

## atorch/utils/parse_trace_json.py

```diff
@@ -240,15 +240,15 @@
     parser.add_argument("--verbose", "-v", action="store_true")
     args = parser.parse_args()
     kernel_start_times = []
     for json_file in args.json_files:
         with open(json_file, "r") as fin:
             json_obj = load(fin)  # TODO: iter json_obj,save memory usage
             df = prepare_df(json_obj)
-            kernel_start_times.append(df.query("cat=='kernel'").head(1)["ts"].values[0])
+            kernel_start_times.append(df.query("cat=='kernel'")["ts"].min())
             print("kernel 5 sample:\n", df.query("cat=='kernel'").head(n=5))
 
             ret = analyze_gpu_kernel(df)
             print("compute summary:", ret)
             ret = analyze_communicate_overlap(df, args.verbose)
             nooverlap_comm_df = ret.pop("nooverlap_comm_df")
             print("communicate summary:", ret)
```

## atorch/utils/patch_te.py

```diff
@@ -1,8 +1,9 @@
 # mypy: ignore-errors
+from importlib import metadata
 from typing import Any, Callable, Dict, Tuple, Union
 
 import torch
 from transformer_engine.pytorch.constants import dist_group_type
 from transformer_engine.pytorch.distributed import (
     CheckpointFunction,
     _set_cuda_rng_state,
@@ -122,11 +123,12 @@
         raise RuntimeError("none of output has requires_grad=True," " this checkpoint() is not necessary")
 
     torch.autograd.backward(outputs_with_grad, args_with_grad)
     grads = tuple(inp.grad if isinstance(inp, torch.Tensor) else None for inp in detached_inputs)
     return (None, None, None, None, None) + grads
 
 
-def patch_te():
-    # patch checkpoint
-    CheckpointFunction.forward = te_checkpoint_forward
-    CheckpointFunction.backward = te_checkpoint_backward
+def patch_te_if_needed():
+    # patch checkpoint if te version < 1.3
+    if metadata.version("transformer_engine") < "1.3":
+        CheckpointFunction.forward = te_checkpoint_forward
+        CheckpointFunction.backward = te_checkpoint_backward
```

## atorch/utils/prof.py

```diff
@@ -8,15 +8,14 @@
 import torch.nn.functional as F
 from distutils.util import strtobool
 from torch import Tensor
 from torch.nn import Module
 
 import atorch
 from atorch.common.constants import AnalyserConstants, GPUCapability
-from atorch.common.file import file_io  # noqa: F401
 from atorch.common.log_utils import default_logger as logger
 from atorch.normalization.layernorm import AtorchLayerNormFunc
 from atorch.utils.hooks import ATorchHooks
 
 try:
     import flash_attn.flash_attn_interface as fa
 
@@ -1132,7 +1131,70 @@
         ATorchHooks.call_hooks(ATorchHooks.REPORT_METRICS_HOOK, {AnalyserConstants.MODEL_FLOPS: prof.get_total_flops()})
         # TODO: report GPU type、amp_used by hook
 
 
 def get_gpu_name():
     gpu = torch.cuda.get_device_properties(0)
     return gpu.name
+
+
+def report_device_memory(name=""):
+    """Simple GPU memory report."""
+    if not torch.cuda.is_available():
+        return
+
+    mega_bytes = 1024.0 * 1024.0
+    string = name + " memory (MB)"
+    string += " | allocated: {:.1f}".format(torch.cuda.memory_allocated() / mega_bytes)
+    string += " | max allocated: {:.1f}".format(torch.cuda.max_memory_allocated() / mega_bytes)
+    string += " | reserved: {:.1f}".format(torch.cuda.memory_reserved() / mega_bytes)
+    string += " | max reserved: {:.1f}".format(torch.cuda.max_memory_reserved() / mega_bytes)
+
+    if hasattr(torch.cuda, "memory_snapshot"):
+        snapshot = torch.cuda.memory_snapshot()
+        if snapshot:
+            total_allocated = sum(b["total_size"] for b in snapshot)
+            if total_allocated > 0:
+                memory_fragmentation = sum(b["allocated_size"] for b in snapshot) / total_allocated
+                string += " | memory fragmentation: {:.2f}%".format(memory_fragmentation)
+
+    import importlib.util
+
+    # pynvml is Python bindings to the NVIDIA Management Library
+    if importlib.util.find_spec("pynvml") is not None:
+        try:
+            from pynvml.smi import nvidia_smi
+        except ImportError:
+            nvidia_smi = None
+        if nvidia_smi is not None:
+            try:
+                nvsmi = nvidia_smi.getInstance()
+                nvsmi_gpu_memory = nvsmi.DeviceQuery("memory.free, memory.used, memory.total")["gpu"]
+                """
+                nvsmi.DeviceQuery["gpu"]'s result's format is:
+                [
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}},
+                    {'fb_memory_usage': {'total': 81251.1875, 'used': 58708.0, 'free': 22543.1875, 'unit': 'MiB'}}
+                ]
+                """
+                current_device_nvsmi_gpu_memory = nvsmi_gpu_memory[torch.cuda.current_device()]["fb_memory_usage"]
+                total_memory, used_memory, free_memory = (
+                    current_device_nvsmi_gpu_memory["total"],
+                    current_device_nvsmi_gpu_memory["used"],
+                    current_device_nvsmi_gpu_memory["free"],
+                )
+                string += " | nvidia-smi memory: free {:.1f}, used: {:.1f}, total {:.1f}".format(
+                    free_memory, used_memory, total_memory
+                )
+            except Exception:
+                pass
+
+    if torch.distributed.is_initialized():
+        string = f"[Rank {torch.distributed.get_rank()}] " + string
+        # remove subprocess nvidia-smi call because of too slow
+    print(string, flush=True)
```

## Comparing `atorch-0.1.7.data/data/acceleration.proto` & `atorch-0.1.8.data/data/acceleration.proto`

 * *Files identical despite different names*

## Comparing `atorch-0.1.7.dist-info/METADATA` & `atorch-0.1.8.dist-info/METADATA`

 * *Files 12% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 Metadata-Version: 2.1
 Name: atorch
-Version: 0.1.7
+Version: 0.1.8
 Summary: A pytorch extension for efficient deep learning.
 Home-page: https://github.com/intelligent-machine-learning/dlrover/tree/master/atorch
 Author: Ant Group
 Requires-Python: >=3.8
-Requires-Dist: fairscale (==0.4.1)
+Requires-Dist: fairscale ==0.4.1
 Requires-Dist: apex
 Requires-Dist: flash-attn
-Requires-Dist: deepspeed (==0.10.0)
-Requires-Dist: transformers (==4.31.0)
+Requires-Dist: deepspeed ==0.10.0
+Requires-Dist: transformers ==4.31.0
 Requires-Dist: networkx
 Requires-Dist: pyomo
-Requires-Dist: pynvml (==11.4.1)
-Requires-Dist: grpcio (==1.34.1)
-Requires-Dist: grpcio-tools (==1.34.1)
-Requires-Dist: fsspec (==2023.10.0)
-Requires-Dist: pyarrow (==12.0.0)
-Requires-Dist: pandas (==2.0.1)
-Requires-Dist: tensorboard (==2.11.0)
-Requires-Dist: dlrover[torch]
-Requires-Dist: protobuf (==3.20.3)
+Requires-Dist: pynvml ==11.4.1
+Requires-Dist: grpcio ==1.34.1
+Requires-Dist: grpcio-tools ==1.34.1
+Requires-Dist: fsspec ==2023.10.0
+Requires-Dist: pyarrow ==12.0.0
+Requires-Dist: pandas ==2.0.1
+Requires-Dist: tensorboard ==2.11.0
+Requires-Dist: dlrover[torch] ==0.4.0
+Requires-Dist: protobuf ==3.20.3
 Requires-Dist: safetensors
 Requires-Dist: GPy
-Requires-Dist: pymoo (==0.5.0)
+Requires-Dist: pymoo ==0.5.0
 
 ATorch supports efficient and easy-to-use model training experience. ATorch provides performance optimizations in aspects such as I/O, preprocessing, computation, and communication (including automatic optimization), and has supported large-scale pretraining and finetuning of LLMs with over 100 billion parameters and thousands of advanced GPUs.
```

## Comparing `atorch-0.1.7.dist-info/RECORD` & `atorch-0.1.8.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 atorch/__init__.py,sha256=Vy5IZwDHwIKC9CBE4oqr6Y9QF3yOrpV5xd8aabICPGs,958
 atorch/amp/__init__.py,sha256=faaBAtNc1_5EiBtVuZ5xarKpxOBBtVc8abHJH_RjdMk,255
 atorch/amp/amp.py,sha256=APe-aym_Hky6CipREVSppAExje55gAfhpzvOGo07OkM,3412
 atorch/amp/hook.py,sha256=2r1RXbKHbh5QRVT9U-q25QV2zJMbIoq7YbiZk2Gy60I,868
 atorch/amp/pipe_amp.py,sha256=ky_0Yi4jKLHo97CZw4UpPcwydziG6jq1kUXoOcM2SuY,12488
 atorch/auto/__init__.py,sha256=5GppCkqhC0MXbVndBHGKCk0XhHr6vFvBXwsA1EcBylM,83
-atorch/auto/accelerate.py,sha256=EXYQtppe5opFDg33eoBCYiDf2Gyw681AaRzLBeRDtpo,28475
+atorch/auto/accelerate.py,sha256=n6AWTUs6LbDOZE9HjC1evQ7S6PGbFIKTYF0yUpIyDj4,28847
 atorch/auto/auto_accelerate_context.py,sha256=vGul6an9wE6lAh2WXx9aamVjpSmC-1bcwL-XWE5JkPs,1095
 atorch/auto/clip_grad_norm.py,sha256=sPw4Jv0DTdRIZiI1oWe13usjxmXl5_6aa1wtkiTVjX8,13550
 atorch/auto/device_context.py,sha256=HOiizEAEhHFZIHvJK0JPCasyNmutanmd_nLCL9CJhuw,6456
 atorch/auto/engine_client.py,sha256=2L3rBUDPLFGZJx4nYjm2Sx3t-Dkzu-q4pO8DpYbAeGo,2480
-atorch/auto/model_context.py,sha256=r9l8tHHzORvOQf5Mzm085UXRTrFTOZLY7loTIHZ3jZc,37719
-atorch/auto/strategy.py,sha256=zNJd_y839MNbweoBm08xe7Nco9b_uNIx2gPG4cbPuxA,4214
+atorch/auto/model_context.py,sha256=J7qzhy4zXq_ITxQ7Ejvbhl6eZZofOO7-_lym8f3anso,37647
+atorch/auto/strategy.py,sha256=BTDVlv_hNgZX0rZ0-_ouZkGVpV6VG0AWAAI7qVEvUQo,4803
 atorch/auto/task.py,sha256=tTf8f8FJB4klUgKGbAFM7mEz3FuvZ-Mgg_bjy3TdNbI,468
 atorch/auto/analyser/__init__.py,sha256=4C4jMmmfnkX-s4eyoK_SuOUpTwNwABJ__9wHjaNips8,31
 atorch/auto/analyser/analyser.py,sha256=wtJryeGZqLe17UyUeBeuDf8Cu4OAUhyfVTCSOWNkmw0,12008
 atorch/auto/dry_runner/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/dry_runner/dry_runner.py,sha256=m4Pq0sq9p0YzimoVv_4V8zCCOGsS0N9A4ulCnneQieM,6435
 atorch/auto/engine/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/acceleration_engine.py,sha256=oEXE4YI5E4yOx_JmmjZrLodKQ3e0oQim-deTTpKf0gY,3241
 atorch/auto/engine/analyser_result.py,sha256=DymBB8uPltZax-ymGQJ0pP2-AgrkV3JsGJbrVge8I_8,948
 atorch/auto/engine/client.py,sha256=vR0CKK0hjJoqGi7KYFLIQVaqMW9eW_O1uy549V6rkzc,3064
 atorch/auto/engine/executor.py,sha256=x6EQYK0xKESJIxvGvxH8j-Dkl9nVRFnbCGOf1OEDX-A,11304
 atorch/auto/engine/optimization_method.py,sha256=o78lmoXSdJbAHIaqX1oJKtKjCAnLri5J7_pJcDb6LUE,6810
 atorch/auto/engine/planner.py,sha256=ddNn1bYvtmH09DX7qllk2cclq9rl-4q36mSfSmo_fhM,4587
-atorch/auto/engine/servicer.py,sha256=nfSnDmXSzziaGDVowbiKwLpCXQdPkoeywK3iXsJ4umU,3019
+atorch/auto/engine/servicer.py,sha256=Bfl1EuOF_66tsHmQVWRm3VbtDDbRiZyT8HsD2Or3ISQ,3035
 atorch/auto/engine/strategy.py,sha256=TZmr4CKBNTBm_aQ9TOw9HpjMGm4ZQnMgBK2ZziOpEio,6306
 atorch/auto/engine/task.py,sha256=qxENGSacFgam6b5J-7COpY54gYDdzwE0kjd5bf67bl8,1693
 atorch/auto/engine/sg_algo/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/bayes_opt_sg.py,sha256=u3xtRDEEtqBiYrWKHBmxzeyYGiYDB-idGjDpIlbzdTY,5713
 atorch/auto/engine/sg_algo/combination_sg.py,sha256=DLK_iTlLs6JYwd80O3DKzVFuFCySZ2GrPxVByxSdLtI,2271
 atorch/auto/engine/sg_algo/sg_algo_lib.py,sha256=9EK2ehaQ2mhRbSVaXcNu19sQ9LvqdfDWI1RnJe9JcUE,896
 atorch/auto/engine/sg_algo/sg_algorithm.py,sha256=HPHXpfcPRWKUGFCim-qa9if6-bomX3DRXPyu1Nh-xPY,886
@@ -36,44 +36,44 @@
 atorch/auto/engine/sg_algo/hebo/acq_optimizers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/acq_optimizers/evolution_optimizer.py,sha256=8fkAw7SWmGSw2n_eZ08Vb3_tZSmDy4FY2si9gYlanMM,5851
 atorch/auto/engine/sg_algo/hebo/acquisitions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/acquisitions/acq.py,sha256=7rGD9KywH3OsfbNgqrxrWNM8HIJbqMvHyyiRA4mLZwg,3395
 atorch/auto/engine/sg_algo/hebo/design_space/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/design_space/categorical_param.py,sha256=bg9xBFupbfmu6qiLpbtbt3NIo4xtCs3OfVVZAWi76-k,1434
 atorch/auto/engine/sg_algo/hebo/design_space/design_space.py,sha256=A51xXrpSyyTwF7zIDoOTIgiCFwCZDM5aBPlS7fTmO8g,3119
-atorch/auto/engine/sg_algo/hebo/design_space/param.py,sha256=M_VHhTJ8gsSJsc5zM7_L0F4Ke50LOV5nbuGnM3vImOI,1055
+atorch/auto/engine/sg_algo/hebo/design_space/param.py,sha256=Tmero5myaxZ8C_6LbTuAQkv2h5D8FnRxrDHUhAbXsCg,1063
 atorch/auto/engine/sg_algo/hebo/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/models/base_model.py,sha256=nRSzQh2mG90U0o_uQOnTIhg0P3e9rcQHO1kyZyFFpDM,2105
 atorch/auto/engine/sg_algo/hebo/models/layers.py,sha256=pDEEkXxvIr8y5vt6WgvxNu_I4uO66UszWAifV1jJX4c,666
 atorch/auto/engine/sg_algo/hebo/models/model_factory.py,sha256=dPBjwQ8UDempy5wIeO7d_4RZ_x-6VpFe2yg7xskIDtg,598
 atorch/auto/engine/sg_algo/hebo/models/util.py,sha256=YMO3xfVAQcpceXpv_cU1U_mRHwBM2Hk0zeHCYfnEslI,541
 atorch/auto/engine/sg_algo/hebo/models/gauss_process/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/models/gauss_process/gpy_wgp.py,sha256=sOVf2C3jamODE50q060gvmpOGteWQoxRrMsgDTejbec,4516
 atorch/auto/engine/sg_algo/hebo/models/random_forest/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/models/random_forest/rf.py,sha256=RER1YKjVeV5Eur0KGe4gaRKiVbyowdldvYPqh-5AXAA,1815
 atorch/auto/engine/sg_algo/hebo/optimizers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/auto/engine/sg_algo/hebo/optimizers/abstract_optimizer.py,sha256=lbUTNd8-s4zbjo4bV4AqEUVjix5cmmZVoI0mVVvHThA,1174
-atorch/auto/engine/sg_algo/hebo/optimizers/hebo.py,sha256=oqzW7HZjgCyWBl8dC1CImvxL8OlorUAxmLqRv5hQFOQ,8224
+atorch/auto/engine/sg_algo/hebo/optimizers/hebo.py,sha256=PZBnZ3PF1r67LfB8w_yTPIH3tia9qoBZOMk2inzrMqg,8272
 atorch/auto/engine/sg_algo/hebo/optimizers/util.py,sha256=anWTTbI7MGck8y7fv7b_mhcQ8pILHKp8CqpzL2CmWRY,1608
 atorch/auto/opt_lib/__init__.py,sha256=hm1pfI_MWOYQ8wjbeVwxU37TORGAhC6NHaEvVfBK6oE,54
-atorch/auto/opt_lib/amp_optimization.py,sha256=9OsBP95LF9g9t0TYH4iBp-i0cSkYVbZjgapdZNvdQXo,16267
-atorch/auto/opt_lib/checkpoint_optimization.py,sha256=TdgpXMeKOfhyPHUFPL_9eXX79rc4Bzk6ka92o4xzgwQ,9604
+atorch/auto/opt_lib/amp_optimization.py,sha256=GIDWzeOTmmgIgIALTZKcSqwhIiPungNCgVJo6USAoOY,16692
+atorch/auto/opt_lib/checkpoint_optimization.py,sha256=tVAkRpxh0f7RZxZ-7-_RdRvlerM9jZYrFyfxfSTIULI,10362
 atorch/auto/opt_lib/ds_3d_parallel_optimization.py,sha256=kt6LltZWUGewT00MlwrFuKZN07dO0dKeZf-r6pyCpSE,7195
 atorch/auto/opt_lib/dynamo_backends.py,sha256=nASqKJuDiGzaHH1rsYrHA8TJv7oUA-8ozKb-nSPRJLs,356
 atorch/auto/opt_lib/dynamo_optimization.py,sha256=i4G91wNn-VzTSb27uVqe1vhftkvTTxvgE43AHHf9eyA,2639
 atorch/auto/opt_lib/half_optimization.py,sha256=O18VK70CTD03olzJm568DDaECG7i1shDHHjL_FVxrZ4,1856
 atorch/auto/opt_lib/mixed_parallel_optimization.py,sha256=T7EsDOzMX86ZuPb7GtDDwz6Wc-BGHFPeb0fZq_IrDTM,13786
 atorch/auto/opt_lib/module_replace_optimization.py,sha256=MHGTFm2UsUojaAz6LIHqEMSTDXehvwGjmHWun_PAxlY,7217
-atorch/auto/opt_lib/optimization.py,sha256=fId-3llQeIHpY5TAGEvkCfmgScyJDQfvk5_FBFK28JE,10708
+atorch/auto/opt_lib/optimization.py,sha256=OKO5uf_W8mvj0xzeRLJws4PxeTm07Te06N9z1n7-Qp8,10892
 atorch/auto/opt_lib/optimization_library.py,sha256=6khls3p-kyzb4KcMHASVVri9zf9BB0iffhHZAYoOoZg,2787
 atorch/auto/opt_lib/parallel_mode_optimization.py,sha256=f-UylUODH1tpEXQvZNB55N773nIjRfMN8XnxoyrjJHo,2112
 atorch/auto/opt_lib/pipeline_parallel_optimization.py,sha256=062_oAxSiCv9vXE6UEHfV90wb2KCeo4QWWs19EJhgjs,11721
-atorch/auto/opt_lib/selective_offloading_checkpoint.py,sha256=vIWH_uoKwZsovApof5uV_oTy0wwnFETrY8DGLW6qRXk,9840
+atorch/auto/opt_lib/selective_offloading_checkpoint.py,sha256=6hskQusHkWk1WaehMQUb-QUT2sRlOEc6nvRyrw0qaQs,10728
 atorch/auto/opt_lib/tensor_parallel_optimization.py,sha256=uD4hkk8zzTuBTrJoM0IXVqqExIPrKfUfTQ1OHEDeGI8,7992
-atorch/auto/opt_lib/utils.py,sha256=w1HmaVxLUGGiVRBMC-r6pKV6p_vNa-SK8aaDzEAkLuQ,6182
+atorch/auto/opt_lib/utils.py,sha256=7Ghc12Oduc4jTkl_LSMDIdUsgBCu2av9CYr_t0cN9ZU,6182
 atorch/auto/opt_lib/zero_optimization.py,sha256=jcvxpIRI--SzSeM87-UyIczgRK21PLfk14Q9AQM5k90,22731
 atorch/auto/opt_lib/shard_planners/__init__.py,sha256=TbUvdmFvOAKiwJrh36y9G6tkW9N8TWOVyWt3vHnbxAg,241
 atorch/auto/opt_lib/shard_planners/base_stage_planner.py,sha256=EhgthFiK1PuCu24mJJ9TIp90Q6GjYgSkAFcdpZm676Q,5145
 atorch/auto/opt_lib/shard_planners/base_tp_planner.py,sha256=TX6Z-R3C_nI_OHF5R1KDo5ooeVWNMX7oL3PzyF4pHnE,9408
 atorch/auto/opt_lib/shard_planners/dim_planner.py,sha256=ORKrzIWX0NsRgbpuHS5rEVDfYhFcDGxjcqMayCVW_eU,8974
 atorch/auto/opt_lib/shard_planners/mip_tp_planner.py,sha256=tv53ovNNDQF5dm6yAm5Y9cxeWzGi9r4KnFwSAiDBQ4M,22977
 atorch/auto/opt_lib/shard_planners/topology.py,sha256=cUR8kaHlZu00CjEmQ3UYf1Qkuj_sRU2eFwT3WSW53WM,3471
@@ -87,82 +87,89 @@
 atorch/common/file/file_system/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/common/file/file_system/file_system.py,sha256=DPbmj-JhiwS83YBo1pVIuoymzqf_VPW06134Scdwmxg,4991
 atorch/common/file/file_system/pangu/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/common/file/file_system/pangu/fsspec_instance.py,sha256=VzfKkeMjMZLSRjRdU_dkNqlGXtMXbkcGY3DP7SMHukY,13710
 atorch/common/file/file_system/pangu/pangu_file_system.py,sha256=EgPDOkdpoOBBI71MA4qXWXm3AR2A_DOpUzU98RDKT8U,17043
 atorch/data/__init__.py,sha256=mHv0gvkEvucRaZmC8KmzTabD4Tz-OIScrEgAr57hqG4,633
 atorch/data/coworker_dataset.py,sha256=b4iPlNloD0IAXEmIF7IJ5Y5hCly2HeVokeGcgNMy-R8,17310
-atorch/data/data_utils.py,sha256=ucRCJBaDFWc2GR3b5YHHJn6w5fRNwiw8JSCpml-N-SA,1343
+atorch/data/data_utils.py,sha256=yBhMkvUusMKQ29evN1bM1_EXUj0B2sxcgLmD8pZpUfc,1347
 atorch/data/elastic_dataloader.py,sha256=mrSDrWTLxehdCRnzhqokNGBB794zAKjZUQiQ-Dd9Qzk,13694
 atorch/data/elastic_dataset.py,sha256=xOU70QiUwvtrExfgoKF4dXwcofEtNg4IiolOO9xrTNM,4771
 atorch/data/preloader.py,sha256=hkYVHJ22dE7bPV9TNOO6ihmDWVqPkPtRw3_mi87rUXQ,6113
 atorch/data/shm_context.py,sha256=iUwp3xcoXknGf-CLizR0qkVFy4xcPx3SqdDFHUFx3HE,27904
-atorch/data/shm_dataloader.py,sha256=ljpMfFDoCxYvOGogh5u1dc5711OqI-fBVC7VpaJQT0U,10185
+atorch/data/shm_dataloader.py,sha256=2kNeX83Xcy2_RH-WRz5THQ-Q_VPR-gLA4xo_aJ__6Jw,10185
 atorch/data/unordered_dataloader.py,sha256=fMRrCPK5tzEPEFsVl7glxKjav6k5rKtRp1t4HYFfwy4,3396
 atorch/data/unshuffled_batch_dataloader.py,sha256=-mYLnymYcnoWdWovRNkfSW_96yK6GgTdz8285tenzsc,1425
 atorch/data_parallel/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/data_parallel/adp.py,sha256=-lw6ABlDyPiRePMZ_7s6dG09rNW6ewGImQaIaIk4bGU,25559
 atorch/data_parallel/auto_wrap.py,sha256=720Ewtqw07xI4g1CxRsnof0WmyOydXPfeDqqXpG-_Sg,13332
 atorch/data_parallel/wrapper.py,sha256=oarEzeRLlcMWpWidiZaiOifZINUqWwEIeSQabxNKcx4,3562
 atorch/data_parallel/zero_ddp_mix_112.py,sha256=-THdMHvXANJgGq0EeVBbf1_wQdzVfuScx4VCeQvTboo,25890
 atorch/distributed/__init__.py,sha256=VzPm1UfPpoMP6_XMZHNK-PblQcOg6egxEacU8BgISf8,261
-atorch/distributed/distributed.py,sha256=2CElRlS7NyIxJdKKAyelV-a0vVn4xCBoDQFuzd2luto,27953
+atorch/distributed/distributed.py,sha256=A7N7yJX62YOlkmYhZ6DVzCUSfKdmskXYtJJ0V-G2gvo,28079
 atorch/distributed/elastic_controller.py,sha256=qyy8BHCOIhtHIje-a6d_O-BkRYL31M251WT1DVqB9NQ,465
 atorch/distributed/elastic_trainer.py,sha256=V8KJdKdHuiEe_BRoMEdbVXE38cCpO0j9aMRGr9dqujY,3405
 atorch/distributed/hooks.py,sha256=7KQNyYtDU6XrekztrKQQz31S-JagyPjZ8OA-6BVNWNA,1253
 atorch/distributed/launch.py,sha256=sAWY0P5AMxOz2cQSg8Niuhe1tY3BtVSjw4CCPaISClw,19071
-atorch/distributed/run.py,sha256=sGAWRwPGypMYPrEHDlE2IiEJuE7pjpzINBuJWVMg5V4,12408
+atorch/distributed/run.py,sha256=llXERdpqNg2YBdp6tDMdnHNKmaEF9Z1Nq3ATnb_iWIo,12424
 atorch/fault_tolerance/__init__.py,sha256=4upTsfblcbQZxgCnUYEpvA3ALhjPqUkkGEcqkzNnjpg,68
 atorch/fault_tolerance/api.py,sha256=wLXxCJRm8dkPEAjZbarGh2pldfOxdnpMvqOwr2SlBes,4825
 atorch/fault_tolerance/custom_agent.py,sha256=x_PpQGG4Hvopic2W9y78rtrBmsb8MI86F1mKln27XQI,8293
 atorch/fault_tolerance/hanging_detector.py,sha256=tYFGtHKAgZN-BBRG09QbsUCLEBndDK5UuludpFYpecw,5659
 atorch/modules/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/modules/distributed_modules/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-atorch/modules/distributed_modules/activation_checkpointing.py,sha256=vkFIL5xThymvaw9HQuyjlpGvsxzL9-UbjIZ9lKZg0tk,14747
+atorch/modules/distributed_modules/activation_checkpointing.py,sha256=DtKP5ByzmZ4Qv5Lf0XUo-eeVElVgtodR6Sk-TE0Lt7U,14763
 atorch/modules/distributed_modules/cross_entropy.py,sha256=2vO4JXfsaNly-car7z7oAVQwkjlHBQ7u5maz0ohtS5I,5688
 atorch/modules/distributed_modules/layers.py,sha256=Gmy1QAASienm74iSrKfzK91EFCZjhKwfmdtkuVCfER4,29411
-atorch/modules/distributed_modules/mappings.py,sha256=OQVgTD6tBAMfG0VW3u9uzHzDtVXoMRMFSAEM8amxiN4,16774
+atorch/modules/distributed_modules/mappings.py,sha256=9BQH-Sf5ZaXWQ8_Vg6B3Oe-7O2czC1KCCG42TW1tIE0,16790
 atorch/modules/distributed_modules/mappings_registry.py,sha256=j2a56W0lOQxwchJVM3n6gMPZgDkFym2NGP92UCsP8OA,7633
 atorch/modules/distributed_modules/materialize_modules.py,sha256=icJiWK_5x70_htHUewo8cWob2pi9XGzB4avxrcjWoU0,1269
 atorch/modules/distributed_modules/modules_registry.py,sha256=j6s8PpU4bSVHLuTy1xVlm9FCdhREsV09FGGPV-P6bkk,54608
 atorch/modules/distributed_modules/randomizer.py,sha256=Ja_GT8_Gnn9IqlTLwlKQI8oGyjhfscSTMG1RIkI66uo,5436
 atorch/modules/distributed_modules/transformer.py,sha256=zJugPudfwLj_KOutOBBGgwr8Ty8VHjx46yERp2BE85g,75800
 atorch/modules/distributed_modules/utils.py,sha256=bKulFgK3f90Y6cKIzlpCRHdMDPTO9ShI_S-j4yKTe14,7551
 atorch/modules/distributed_modules/compilers/__init__.py,sha256=9xHmv75S0Ic39I6zDFD1HtouJS3uBoqY_rctM7TO3Ow,147
 atorch/modules/distributed_modules/compilers/pipe_compiler/PipelineStage.py,sha256=uQfaOBQiyVU0g_hw8IyqPrELGioMm48BGrVyzVKYLPI,36537
-atorch/modules/distributed_modules/compilers/pipe_compiler/StageInterleaver.py,sha256=1YP4LEEyttdZ_HoEYHuccc3k6NXGZ7uOgYY-_ZZHEww,3924
+atorch/modules/distributed_modules/compilers/pipe_compiler/StageInterleaver.py,sha256=sQqS81L0w7LDHjWHLSQWxNqxkvepEs7snnoIpNGPA4Y,3976
 atorch/modules/distributed_modules/compilers/pipe_compiler/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-atorch/modules/distributed_modules/compilers/pipe_compiler/distributed_pippy_compiler.py,sha256=7pmedQ7fzm2yl9TaXFTVGTQT-ro5YVG3lCiCuDYTRF8,20919
+atorch/modules/distributed_modules/compilers/pipe_compiler/distributed_pippy_compiler.py,sha256=vmcIvQAcwT25uuHH59ifAWv67hJaY2nZZSIpFKw5nk8,20974
 atorch/modules/distributed_modules/compilers/pipe_compiler/utils.py,sha256=63Ixlx4cXyAddfXEj7ylsHVeEv_qXaLUwxD9cRZ6l58,25818
 atorch/modules/distributed_modules/compilers/tp_compiler/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/modules/distributed_modules/compilers/tp_compiler/dtensor_compiler.py,sha256=wIw4OrXfdHMKDHizVkXOM8nRUycdWIWptehJIniihNI,222
 atorch/modules/distributed_modules/compilers/tp_compiler/tp_compiler.py,sha256=M5uymcUECFf-fkd1-BYjmLyY1bQpOgFQW8QVmP37gsI,7707
 atorch/modules/distributed_transformer/__init__.py,sha256=LVuyK4aCir9zRsde-RvMFRNUSb-zTeGN5fcS36nt460,80
 atorch/modules/distributed_transformer/commu_utils.py,sha256=ljzY1lpNjdEzwfCg3GbO6x4IyCJejlawXAKwWXOh4hI,3173
 atorch/modules/distributed_transformer/distributed_attention.py,sha256=LCMkkcsmvRCdPhnmWJGSAJ6t8rmGQO6JPcmbA3ghl8E,14623
 atorch/modules/moe/__init__.py,sha256=ddTRkRFLvmEws66--QiOx-dKT4mdKd_8-Q3TxBjjwBM,295
-atorch/modules/moe/ddp.py,sha256=xR-cG8fjN7t792CkKaA2bDjfDAGTpVzopBxxtXNOYV8,15968
+atorch/modules/moe/ddp.py,sha256=xhYn6xEzkzkoEY1g8hS8zYNj_U-OkAb9orx5xPzSgvA,16005
 atorch/modules/moe/inject.py,sha256=njrdSMjILOL1WJZwZFJxROaHNoSiuF7R4tlU1yQyHfM,4291
 atorch/modules/moe/moe_layer.py,sha256=PQ4eIZx81JcUO-D-UbLnIpQAmpSJuzpje4FhFUhUJvA,25005
 atorch/modules/moe/switch_gating.py,sha256=1OfKZFJ9YrfvQKJCUUnoqiHAblM1sAavRka8uzzRmkk,6683
 atorch/modules/moe/topk_gating.py,sha256=BTScyg2dkt3WcX5w_ojzTBgvaDbsiT7mSKr7tKw0B4o,5799
 atorch/modules/transformer/__init__.py,sha256=8jGPBsMO4Yc-rsAO2CfZ_dn9kIu_8faBo4b3lTE7rm4,37
 atorch/modules/transformer/_fa_api_compat_patch,sha256=iOfGTPpaTarJ4hVaS6VoQKK7iDpn7N2LUwgAhlASn78,5210
 atorch/modules/transformer/cross_entropy.py,sha256=Xv32RhMM53jCLrhu12MEEShzwY9-9YpzJwElZoqAqZA,13580
 atorch/modules/transformer/inject.py,sha256=0AVocffvENX0ppvXV8EarYhvmRw8yQiUKtAeK2qVSfE,8248
-atorch/modules/transformer/layers.py,sha256=CRPXnIeYGzlDTtZZGITcu0w4LDdnriR5n1xwIl5-vSY,72042
+atorch/modules/transformer/layers.py,sha256=ua6S8q-rT8EALWypxOJITAod4zmO4l07pLl-MgWHJ3o,67467
 atorch/modules/transformer/linear.py,sha256=p2bu3WT-dyvwWxdIYhpFlTxuFeV-cqQrUgs-y7zEk0o,2682
-atorch/modules/transformer/losses.py,sha256=zZizCQhVKRPLCkOdYcU3IzWMJTC-u7ns0cYBzQupzGI,486
+atorch/modules/transformer/losses.py,sha256=sbMsYmzqZFArbHFIGh-1EOhzjXEBZJQTvk7q7Yh2cow,374
+atorch/mup/__init__.py,sha256=T5q60GRUstHUYwNSsoIsGsDOVcs7C5UlDLborv5CpTE,244
+atorch/mup/infshape.py,sha256=QOolFbJkTInt-Mr77RzrRHOIjFx6sCJLE5VBT9tTBUQ,4232
+atorch/mup/init.py,sha256=QZKlSX8YIWNyHc_3KmjyahAfbAA27gSk-nZbM0_w0tk,8553
+atorch/mup/module.py,sha256=5vLI9NGAVO-S3D8-ZI54W2svq70sYwRN_w7Aq5_WAhM,11021
+atorch/mup/optim.py,sha256=X4SdpBKh7588kLWEnEXM7DXVNVl3-14tFY-4CMTNDbw,5867
+atorch/mup/shape.py,sha256=V-L8eCgD96FAS1idKmjwWDnlK3SGk859pNBouGWdTM8,7971
 atorch/normalization/__init__.py,sha256=jS_nSmlS1t03tY1Kvt84e-XU6aURJf2xMqWOAnsWorI,455
-atorch/normalization/layernorm.py,sha256=UEN6CKVXiFFNGTIktUI1gdSA7XtSyQVw4kFv_gS7F_w,9011
-atorch/npu/__init__.py,sha256=OvxNdZaMZ0U-pRQsvyWJvbBPguIefHOiS6obbmShu8M,2493
-atorch/npu/optim.py,sha256=0Gd08olWa2TdARtBEHacICj6GozA0USGr5o6agAiRXo,7625
+atorch/normalization/layernorm.py,sha256=YlQ9TP3yN5289T6CauqgkmxPQqq7YkmJxpVn9JiEF9I,9000
+atorch/npu/__init__.py,sha256=j9kJhxhFccrmIpJYN_5rUUWawVArR0KLtcVWZ7qNOVA,2681
+atorch/npu/layers.py,sha256=H-d9jQlA67nbh0XpzFUMH_Nm0CjNwFc1nv8jknPDyhc,6090
+atorch/npu/optim.py,sha256=1lbnfV1xiEb55091M9Hyhi3SqISs1KbtNr-gGjdMtZg,7676
 atorch/ops/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/ops/git_version_info.py,sha256=0UWHC_5zh71LNENaFWCacCsC4PsbHi3gKOihQBLmzeM,950
-atorch/ops/git_version_info_installed.py,sha256=FvWtEHsg-advbjbpE7p6D8-PIwbe7fI2xWg8viKfjgE,349
+atorch/ops/git_version_info_installed.py,sha256=M5V245OTobrxnMBjsmJsFieeKSSlD_JPq6DVv-jWztM,347
 atorch/ops/accelerator/__init__.py,sha256=gWQg_tMCqUv4mjGYxXV-C314BDS4IEdLEV4rGPwfXUI,271
 atorch/ops/accelerator/abstract_accelerator.py,sha256=Bz7eo_CCRCr_V3eO_8xw7aL1WqVftUU-M5cd5e6qzHQ,4732
 atorch/ops/accelerator/cuda_accelerator.py,sha256=LFvghhqUrL-Z9rRnWZXfouPy4ZNNjB1uyrLbaRBc7b8,8910
 atorch/ops/accelerator/real_accelerator.py,sha256=jWxYWBNNWbDpL6Vhk_4_ySLCV3rHyT-GdcylseRMvZU,2478
 atorch/ops/csrc/includes/conversion_utils.h,sha256=Rj9QBKdYTLrkCovxMI03IKQKb153SrtgE9WYJS_PnLs,12017
 atorch/ops/csrc/includes/dequantization_utils.h,sha256=q9gZ4uSR9Kq1nU9bFu7oFMkWUV9kflzX78ZiyUQdXuo,7001
 atorch/ops/csrc/includes/kernel_utils.h,sha256=iZ1AAiQL8ipcNdSEN4itVH8xPIXiAI4XWrnpz6lGfVg,1202
@@ -183,15 +190,15 @@
 atorch/ops/op_builder/all_ops.py,sha256=rSIW26lYrpM7etZtNZQ80yUaTUT_fWJ06fZOkhsjDzY,1271
 atorch/ops/op_builder/builder.py,sha256=zUxTzqhqS-GFJ9J2JAbrnLw4uxz1Er-prerxz0bS9Ss,25650
 atorch/ops/op_builder/quantization_optimizer.py,sha256=yMsFTJwyIQZXX0qnwSqXVVueU-woBJDCwipb29FM2GY,846
 atorch/ops/op_builder/quantizer.py,sha256=3C1H0M3cW0fCJ3iIkU-gYaTtwYKm5_6eNOQHIhtgGtk,920
 atorch/ops/quantizer/__init__.py,sha256=UOtZpuW_E_41eDw1HBY86KGv5l6AokgGLQxqvjKxIDA,2401
 atorch/optimizers/__init__.py,sha256=QNcw-KPs3WSs7nnQjzIc7cpL5aYuCqIWilUAyaa9NuU,93
 atorch/optimizers/adam_offload.py,sha256=csE2HMqiuRFWMctUeA3B23veafgTd4CUtMeSK49ZMBE,13353
-atorch/optimizers/agd.py,sha256=4hy5lJWvu1OtHPJiveNZ2cEN1DPQpmFRPcLXO0bAatE,6780
+atorch/optimizers/agd.py,sha256=c58H0JnQ-I762xjbWzfcY3ueSrFnpPR3w6pBXkb6zU8,6808
 atorch/optimizers/bf16_optimizer.py,sha256=wHqG3m28gQDBEXlt2cGClkIlAumr7AgMf-4yMnz8Jew,11915
 atorch/optimizers/utils.py,sha256=rdE-kZQEb-Q8xyoiAu4aRHZ-C84mKrPayjz8Txm_MKY,625
 atorch/optimizers/wsam.py,sha256=IErIOvzd6WrwU48jk0sPxh57RwRsxmol9m6lUwPwb6Y,5375
 atorch/optimizers/low_bit/__init__.py,sha256=F6vweKmAWojlNar3qESYgnxFzbDXsBL3IW6w2Z6ZZ5g,55
 atorch/optimizers/low_bit/config.py,sha256=dcTwltNcqPelFiS-NXc15OD_7wRattk436SexpeUcLs,626
 atorch/optimizers/low_bit/functional.py,sha256=6YZzeU62YUmF6BiixqpJRMSnbpxgIqm71OLVNP6FR6o,19476
 atorch/optimizers/low_bit/optim/__init__.py,sha256=EDq0eIKpAk2IYcgg8XiZhBTJ2J-na7XAXZ2QR0ralH8,118
@@ -201,50 +208,82 @@
 atorch/optimizers/low_bit/optim/q_came.py,sha256=SToF6Bws8wTa1qS7-5Fwnqzx5BT68nbJ6kdwqg-5sYs,10023
 atorch/optimizers/low_bit/optim/q_optimizer.py,sha256=tFOQbRfjgN3sb7xJvHp5RgdqU_Dj7J6ZqS9B3rb5g4Y,7034
 atorch/protos/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/protos/acceleration_pb2.py,sha256=njaQFtIRpb-rnHO6FzqBtCuUiinyUQh550Y7F4RQKDs,19348
 atorch/protos/acceleration_pb2_grpc.py,sha256=zuznfu_tehpKMLI35pyfB1XqMHMH6czvPRjPBgEN2dw,4574
 atorch/protos/coworker_pb2.py,sha256=E-RcveDUbrH0N-vJoLFiuLi8e_Tj4RC8o_92bhIvCS8,5993
 atorch/protos/coworker_pb2_grpc.py,sha256=X29YrfA028EACXZnjTTxZBqugKc_CoozIJC3k91HHqU,6714
+atorch/rl/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+atorch/rl/config.py,sha256=ctu2t1_XuFW6--QbpCmxT86_DIoT7WIZoMQdq0Ij9IM,7661
+atorch/rl/main.py,sha256=SWg2e2Y5fa5yvdUv7w_72sulX4R1sO1T0hgKToVV_2c,849
+atorch/rl/data/__init__.py,sha256=BJhzBkR6f8S99fjMr3MhfZZL2QDHkf8Ovj3PDQlS4a8,39
+atorch/rl/data/data_utils.py,sha256=p43-c-pVMzHQxj3pHSgh17CR5A5aF7xpfHBHVFha5qY,6390
+atorch/rl/ds_hybrid_engine/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+atorch/rl/ds_hybrid_engine/ds_hook.py,sha256=UOAvGBYoMNm5VokM-tfjRIyIIx4TtSBJl8doYfODJSw,15390
+atorch/rl/ds_hybrid_engine/hybrid_engine.py,sha256=Sg7JBuefdX6meBzJnSZZ7kHVzXNfjR7I17JDl8l7apQ,16621
+atorch/rl/ds_hybrid_engine/initialize.py,sha256=2rpj12d7rjB8rmRIdvrwjzFlnZXwkv-1op1qttG57cM,7738
+atorch/rl/ds_hybrid_engine/replace_policy.py,sha256=D_d1czuRa9RJSsAdJhWjoJHTHUFruEQT-QFZyfV3ErA,235
+atorch/rl/ds_hybrid_engine/module_inject/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+atorch/rl/ds_hybrid_engine/module_inject/utils.py,sha256=zcdS_QCh7ibHDHprD0hGx8Lo6AJo37kIk24HgzXiwwg,632
+atorch/rl/ds_hybrid_engine/module_inject/containers/__init__.py,sha256=fu-mdfot8zaJN7rXiZVkv6X2db03BoG1Hi8t2r5Id1w,55
+atorch/rl/ds_hybrid_engine/module_inject/containers/llama.py,sha256=nX0cZ5-MIXjDqyhXpl3_Zqsq1wS0q6W3exfMLXqrxBA,6707
+atorch/rl/inference_backend/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+atorch/rl/inference_backend/vllm_backend.py,sha256=Wo-j-8B0LjdDsR3e1fZ0eh8rCoN9GANGzoLX2fH7ExM,1682
+atorch/rl/model_engine/__init__.py,sha256=uDupiAJd276yh4jb7ZXAgRVVQxVCfzxhk74IyNTLcq8,56
+atorch/rl/model_engine/model_engine.py,sha256=H4-y3fwbXUY8uRUcuAVL6vudLgm9KPbthFbrPd5E__g,21156
+atorch/rl/model_engine/strategy.py,sha256=b05v8BzpGd2NGLw2m0G6VeCUQDTduKBE_6OABS1hFgw,1138
+atorch/rl/model_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+atorch/rl/model_utils/llama2_utils.py,sha256=H6P5MIL4amzaWGTqdSjZ0XKTj_Arstpm2Tr54SBPE6g,6372
+atorch/rl/model_utils/load_init_model.py,sha256=GUD4g6vuJ0X8iXWam6suyDZ1EeGYIfd8apOZeQYJh1A,6291
+atorch/rl/model_utils/model_util.py,sha256=1UtBnIuozzmr9w92V_N-fjzrkqqa9tzrg6rsoRuSh6E,12237
+atorch/rl/model_utils/redis_util.py,sha256=Rr5Ly10mx4RqKxHYvGAs3w6W4A3iNlV9YB_RT-KWYpY,2144
+atorch/rl/ppo_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+atorch/rl/ppo_utils/ppo_util.py,sha256=mGa7UYHFNDQCx8S93bEymRY4hfMFPjem_hdC6OyEWb0,6842
+atorch/rl/replay_buffer/__init__.py,sha256=_Hh5PnQ5GBIoVBAwc78KtGsxo5gKiSPy9IOXsvT5uEY,40
+atorch/rl/replay_buffer/replay_buffer.py,sha256=C8VOnWn2RQO0q0RTh64NH4zifgE9g1uLVvUwKSx3eJI,1795
+atorch/rl/trainer/__init__.py,sha256=o1t5KLkzwRkFBB3nbg52yih82DFiYZRX93l_ekHjl-I,34
+atorch/rl/trainer/ppo_trainer.py,sha256=u30GMOz6PAxBFF3D5hGnSBU-ooKwyFSZ_mzC6ddrSv8,274
+atorch/rl/trainer/rl_trainer.py,sha256=S_ccwiN2YwwOk4wFwNd_Yrpus1PLN2RwYn45BboKxnc,3190
 atorch/service/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 atorch/service/coworker_data_service.py,sha256=0mkkj9vHibS6X9wQVoEk3CIwd323Vkr5WqtZG6iWYog,2208
 atorch/service/data_info_service.py,sha256=3mRykB5OMBnfIpi8M27peh-XmQY-vLe1Q37kRDj6ng8,1924
 atorch/service/rpc_clients.py,sha256=4tKfDLeWqa9zWEUGYpkfgdvmx-d7IFv8m459oFoR6eE,3238
 atorch/trainer/__init__.py,sha256=IeqSgO7h3mVQX6TrvFFPjlxsIkrQB939g4W_JVuRRFU,103
-atorch/trainer/atorch_args.py,sha256=HWRrItBXTXiDbVYrb1SFhfqE7U3Sx5oaCoZB-5R6A3M,9795
-atorch/trainer/atorch_trainer.py,sha256=BNwM2p9JftDhcQQuYH0SHSUB0Pz7kSkGiXqftql2Vk8,95605
+atorch/trainer/atorch_args.py,sha256=JfxFggF07xytT7osKDn4R8tdGTusirT-kQ9mFGLafcg,10651
+atorch/trainer/atorch_trainer.py,sha256=7yXAhnkk4Q3wrmovIBiD1XQN2O9zQszSDvNgZIWOGeE,98297
 atorch/utils/__init__.py,sha256=XdOjdSUeFYAxmhjAHSUqeoLsKkcTSu6e_m3Mw20p_3U,63
 atorch/utils/ds_pipe_utils.py,sha256=kb5wBRNrBCnSt7xRGq3PjizjHalJbvebBLramwVvT58,8524
-atorch/utils/fsdp_init_util.py,sha256=DI7kzhlLfRV5_0Q-Guxz11XLc09xDO484bppXfVh1MI,14073
-atorch/utils/fsdp_save_util.py,sha256=E4RjMMHU24fES02QzZUbykbQkySQjBt-ixyjnK0GlLM,40293
-atorch/utils/grad_scaler.py,sha256=J-C2fd-vxvum3tREvV2QLvbRxt3c0fgv0FVK60FKfkM,2690
+atorch/utils/fsdp_async_ckpt_util.py,sha256=FpczDvGyqt9wRFfTgFkZ234v-atsAEs-kVCE_ISTOTo,7784
+atorch/utils/fsdp_init_util.py,sha256=jcJBUuEfAxNBrA2MWmW1hQr1veuVYZQRG-CxUJmCKyk,14062
+atorch/utils/fsdp_save_util.py,sha256=E_eWDDGA0jnRzRJ6iVDRua5SYOFDIXe-1K7O9_Fz7Wk,41878
+atorch/utils/grad_scaler.py,sha256=VXkj2R7wQjewbioRtcNLFnCvZa8XBJep4nGnisiO9tw,2706
 atorch/utils/graph_transform_utils.py,sha256=9xm6n8ekjUbvyP-HC0tkhFYF5f_r_tiznozBQRWyXrc,5644
-atorch/utils/hooks.py,sha256=FoOO1z3MuC0Dns88Ftnej9R2CclFqLO9Yn2troQ2ITE,980
+atorch/utils/hooks.py,sha256=WDCvgA_Q43_ySZLPczqSnxx9a9DTMjXeLTYGgDbSBww,1021
 atorch/utils/ib_monitor.py,sha256=9X6n3T7mzZ2vDRATz90E3VVmSzZTKkbSuMRGfInQpJw,6940
-atorch/utils/import_util.py,sha256=8y2vPyqFV8ZoM5FQBUWKxFzBhwkhrdeb7qROGwWIiOU,1256
+atorch/utils/import_util.py,sha256=qMGtsKMrN2wqmm0_IAMTUooaq1ZjP9x4oalldKPr7I0,1428
 atorch/utils/manual_tp_utils.py,sha256=Kg8sWEZqrPciK7zt8t49OqfdZqg2bED9Tgpc8y5VdcA,10381
 atorch/utils/meta_model_utils.py,sha256=j1i4OkEacMF-904cv7RGuCqztMS3hgoPR2i6GoAunLk,34986
 atorch/utils/meta_overrides.py,sha256=nkaTKZ6siJ1b0J1FziJcn6b0hZ8f9oDDzU8Jacrkb98,11593
 atorch/utils/metric_util.py,sha256=aPCo5GqG7do-h_AH1PoOYZtpOJ8EYdnw7KSZRukpgcU,2267
-atorch/utils/numberic_checker.py,sha256=zjf2lasN9fuskeRrTQosd9pMsl-6sR9UVV9ENFTywTA,5781
+atorch/utils/numberic_checker.py,sha256=JlvqWzDjAbhMnnhElNDHaJLJ5Eoid2f5mNyms8ZCQwo,5781
 atorch/utils/parse_fsdp_mapping.py,sha256=5WsCSPFHMTDsJFdH6zDwv04wxoi2tflNAWrTDwOAFDc,9514
-atorch/utils/parse_trace_json.py,sha256=TZ6wZxQF63ayvXxq7dwRfB0TrkmB9k0PnZK3q17XNPA,10463
+atorch/utils/parse_trace_json.py,sha256=rGdUgPQ6I34SXtQGBcw25JE-d0s7tKTBnDo_MC-XJQo,10451
 atorch/utils/patch_fairscale.py,sha256=xnHugClneeeaW407fJvj2BS65WuSdo_JZX-vIir_H-M,3487
-atorch/utils/patch_te.py,sha256=F2nJSw-iDgAlfe1UdkTg0HZuvSlvaOKJccb2JzYBUwA,4751
+atorch/utils/patch_te.py,sha256=mb0KUoCvcX3x0y3LqbQwXPEWGxitKOIK-etQ_UwjSD8,4875
 atorch/utils/pipe_file_utils.py,sha256=dEKBb-YLRNBZc2Qzp039zn8s-VM9hUVlJpBTxn3hqnA,4188
-atorch/utils/prof.py,sha256=fqP0YYxAkOaKY6oZFHNHdCeHdKh9cZSbvpxB0ewwceA,43694
+atorch/utils/prof.py,sha256=FfH4w8h-JB7xHdF7zdD-m98bxcWUi5TcIQEy8Onl8cU,46954
 atorch/utils/shape_prop.py,sha256=J6qIbDc5TZgCFLCLdu_WTDybLW07GoIZyUerAA0kHm8,2839
 atorch/utils/sharding_spec.py,sha256=wLWHcIRM_OjB1H3sQZluOtUfmMFxz7VETlOYPBS9aS4,4281
 atorch/utils/sparse.py,sha256=ek0trMwZbdGQRo7v9g9UgAjESczZZxDDvC8X02GWCfI,2547
 atorch/utils/spec_prop.py,sha256=S9OEHpoXVOZQMEMaqKB6LhwsAOQEa5borPAh5F5lQoI,6342
 atorch/utils/timer.py,sha256=4_pZda7ZT_7vQ5cRBz4e-ZpYU9qaSivKxSZtGUbl1XM,2797
 atorch/utils/tracer.py,sha256=6VWBeLtW_BNyRBYVO3Q1HvbnFstg30qmdXYoguRoggo,24365
 atorch/utils/trainer_utils.py,sha256=gd4XcPGEDgzQ6VslrHGZBdTcI8CbBZm-x6lv7a5gd5M,2244
 atorch/utils/version.py,sha256=i71v6eiVb_IXQdDlWOwYWnyMok9j29nzLGh83Vjic5Y,1441
-atorch-0.1.7.data/data/acceleration.proto,sha256=spmYAqmckmV29X1XkmOSwajWgKMGrj7pn1nraL3TnW0,1046
-atorch-0.1.7.data/data/build_proto.sh,sha256=sbTOt_HHt_F-DyfgHY74m755redknL6nHeZwIUjswD4,224
-atorch-0.1.7.data/data/coworker.proto,sha256=hezllszC0XadStrgrgi6J9pmlZLJj2E50uTi9aqVamE,455
-atorch-0.1.7.data/data/requirements.txt,sha256=hPVeM3D7iB-3lDCo5JpR48JIFXp9cee5_8wW_cK_TPQ,267
-atorch-0.1.7.dist-info/METADATA,sha256=OStoKy95gVIDMX0QnEfLduC0pYoqM4qN0imNgdqW2aU,1171
-atorch-0.1.7.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-atorch-0.1.7.dist-info/top_level.txt,sha256=64BT5ChWxA_sdfYF3xxVLu_I8jhTEfSSOlK5WQ4zcH0,7
-atorch-0.1.7.dist-info/RECORD,,
+atorch-0.1.8.data/data/acceleration.proto,sha256=spmYAqmckmV29X1XkmOSwajWgKMGrj7pn1nraL3TnW0,1046
+atorch-0.1.8.data/data/build_proto.sh,sha256=sbTOt_HHt_F-DyfgHY74m755redknL6nHeZwIUjswD4,224
+atorch-0.1.8.data/data/coworker.proto,sha256=hezllszC0XadStrgrgi6J9pmlZLJj2E50uTi9aqVamE,455
+atorch-0.1.8.data/data/requirements.txt,sha256=6EcK-CwiZRCpwxiU3srZyvlvLESn0fF_NK8Xr2aj3JQ,273
+atorch-0.1.8.dist-info/METADATA,sha256=qDqP74juQzP0sbkOqvxT3HKN-nqSghepThIKl1t_mIo,1155
+atorch-0.1.8.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
+atorch-0.1.8.dist-info/top_level.txt,sha256=64BT5ChWxA_sdfYF3xxVLu_I8jhTEfSSOlK5WQ4zcH0,7
+atorch-0.1.8.dist-info/RECORD,,
```

