# Comparing `tmp/autoai_libs-1.17.2-125-cp310-cp310-win_amd64.whl.zip` & `tmp/autoai_libs-2.0.0-134-cp311-cp311-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,138 +1,138 @@
-Zip file size: 2047077 bytes, number of entries: 136
--rw-rw-rw-  2.0 fat      528 b- defN 24-Mar-14 12:02 autoai_libs/__init__.py
--rw-rw-rw-  2.0 fat    17408 b- defN 24-Mar-14 12:00 autoai_libs/version.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat      507 b- defN 24-Mar-14 11:36 autoai_libs/version.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/cognito/__init__.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/cognito/transforms/__init__.py
--rw-rw-rw-  2.0 fat    70656 b- defN 24-Mar-14 12:00 autoai_libs/cognito/transforms/sklearn_compat.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     4611 b- defN 24-Feb-20 10:55 autoai_libs/cognito/transforms/sklearn_compat.py
--rw-rw-rw-  2.0 fat    43008 b- defN 24-Mar-14 12:00 autoai_libs/cognito/transforms/textras_methods.cp310-win_amd64.pyd
+Zip file size: 2092196 bytes, number of entries: 136
+-rw-rw-rw-  2.0 fat      800 b- defN 24-Apr-09 09:39 autoai_libs/__init__.py
+-rw-rw-rw-  2.0 fat    16896 b- defN 24-Apr-09 09:37 autoai_libs/version.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      506 b- defN 24-Apr-09 09:30 autoai_libs/version.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/cognito/__init__.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/cognito/transforms/__init__.py
+-rw-rw-rw-  2.0 fat    72192 b- defN 24-Apr-09 09:37 autoai_libs/cognito/transforms/sklearn_compat.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     4559 b- defN 24-Apr-03 11:49 autoai_libs/cognito/transforms/sklearn_compat.py
+-rw-rw-rw-  2.0 fat    43520 b- defN 24-Apr-09 09:37 autoai_libs/cognito/transforms/textras_methods.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     1417 b- defN 24-Feb-20 10:55 autoai_libs/cognito/transforms/textras_methods.py
--rw-rw-rw-  2.0 fat   154112 b- defN 24-Mar-14 12:00 autoai_libs/cognito/transforms/transform_extras.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat    16913 b- defN 24-Mar-06 11:04 autoai_libs/cognito/transforms/transform_extras.py
--rw-rw-rw-  2.0 fat   606208 b- defN 24-Mar-14 12:00 autoai_libs/cognito/transforms/transform_utils.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat    88079 b- defN 24-Mar-14 11:36 autoai_libs/cognito/transforms/transform_utils.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/detectors/__init__.py
--rw-rw-rw-  2.0 fat    30208 b- defN 24-Mar-14 12:01 autoai_libs/detectors/general_detector.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   154624 b- defN 24-Apr-09 09:38 autoai_libs/cognito/transforms/transform_extras.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    16838 b- defN 24-Apr-09 09:30 autoai_libs/cognito/transforms/transform_extras.py
+-rw-rw-rw-  2.0 fat   622592 b- defN 24-Apr-09 09:38 autoai_libs/cognito/transforms/transform_utils.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    88058 b- defN 24-Apr-03 11:49 autoai_libs/cognito/transforms/transform_utils.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/detectors/__init__.py
+-rw-rw-rw-  2.0 fat    31232 b- defN 24-Apr-09 09:38 autoai_libs/detectors/general_detector.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat      760 b- defN 24-Feb-20 10:55 autoai_libs/detectors/general_detector.py
--rw-rw-rw-  2.0 fat    31232 b- defN 24-Mar-14 12:01 autoai_libs/detectors/small_data_detector.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat      833 b- defN 24-Feb-20 10:55 autoai_libs/detectors/small_data_detector.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/detectors/date_time/__init__.py
--rw-rw-rw-  2.0 fat    51712 b- defN 24-Mar-14 12:01 autoai_libs/detectors/date_time/date_time_detector.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     3276 b- defN 24-Feb-20 10:55 autoai_libs/detectors/date_time/date_time_detector.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/estimators/__init__.py
--rw-rw-rw-  2.0 fat    41472 b- defN 24-Mar-14 12:01 autoai_libs/estimators/xgboost.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     2133 b- defN 24-Feb-20 10:55 autoai_libs/estimators/xgboost.py
--rw-rw-rw-  2.0 fat     5059 b- defN 24-Mar-14 12:02 autoai_libs/lale/__init__.py
--rw-rw-rw-  2.0 fat    49664 b- defN 24-Mar-14 12:01 autoai_libs/lale/_common_schemas.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    33280 b- defN 24-Apr-09 09:38 autoai_libs/detectors/small_data_detector.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      891 b- defN 24-Apr-03 11:49 autoai_libs/detectors/small_data_detector.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/detectors/date_time/__init__.py
+-rw-rw-rw-  2.0 fat    53248 b- defN 24-Apr-09 09:38 autoai_libs/detectors/date_time/date_time_detector.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     3321 b- defN 24-Apr-03 11:49 autoai_libs/detectors/date_time/date_time_detector.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/estimators/__init__.py
+-rw-rw-rw-  2.0 fat    41984 b- defN 24-Apr-09 09:38 autoai_libs/estimators/xgboost.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     2174 b- defN 24-Apr-03 11:49 autoai_libs/estimators/xgboost.py
+-rw-rw-rw-  2.0 fat     5059 b- defN 24-Apr-09 09:39 autoai_libs/lale/__init__.py
+-rw-rw-rw-  2.0 fat    49664 b- defN 24-Apr-09 09:38 autoai_libs/lale/_common_schemas.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     6420 b- defN 24-Feb-20 10:55 autoai_libs/lale/_common_schemas.py
--rw-rw-rw-  2.0 fat    49664 b- defN 24-Mar-14 12:01 autoai_libs/lale/boolean2float.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    50688 b- defN 24-Apr-09 09:38 autoai_libs/lale/boolean2float.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4319 b- defN 24-Feb-20 10:55 autoai_libs/lale/boolean2float.py
--rw-rw-rw-  2.0 fat    65024 b- defN 24-Mar-14 12:01 autoai_libs/lale/cat_encoder.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    65024 b- defN 24-Apr-09 09:38 autoai_libs/lale/cat_encoder.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     9362 b- defN 24-Feb-20 10:55 autoai_libs/lale/cat_encoder.py
--rw-rw-rw-  2.0 fat    67072 b- defN 24-Mar-14 12:01 autoai_libs/lale/cat_imputer.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     8745 b- defN 24-Feb-20 10:55 autoai_libs/lale/cat_imputer.py
--rw-rw-rw-  2.0 fat    46592 b- defN 24-Mar-14 12:01 autoai_libs/lale/column_selector.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    67072 b- defN 24-Apr-09 09:38 autoai_libs/lale/cat_imputer.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     8706 b- defN 24-Apr-09 09:30 autoai_libs/lale/cat_imputer.py
+-rw-rw-rw-  2.0 fat    48128 b- defN 24-Apr-09 09:38 autoai_libs/lale/column_selector.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4009 b- defN 24-Feb-20 10:55 autoai_libs/lale/column_selector.py
--rw-rw-rw-  2.0 fat    47616 b- defN 24-Mar-14 12:01 autoai_libs/lale/compress_strings.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    48128 b- defN 24-Apr-09 09:38 autoai_libs/lale/compress_strings.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     5593 b- defN 24-Feb-20 10:55 autoai_libs/lale/compress_strings.py
--rw-rw-rw-  2.0 fat    50688 b- defN 24-Mar-14 12:01 autoai_libs/lale/date_transformer.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    51712 b- defN 24-Apr-09 09:38 autoai_libs/lale/date_transformer.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     6559 b- defN 24-Feb-20 10:55 autoai_libs/lale/date_transformer.py
--rw-rw-rw-  2.0 fat    49664 b- defN 24-Mar-14 12:01 autoai_libs/lale/float32_transform.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    51200 b- defN 24-Apr-09 09:38 autoai_libs/lale/float32_transform.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4286 b- defN 24-Feb-20 10:55 autoai_libs/lale/float32_transform.py
--rw-rw-rw-  2.0 fat    45568 b- defN 24-Mar-14 12:01 autoai_libs/lale/float_str2_float.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    47104 b- defN 24-Apr-09 09:38 autoai_libs/lale/float_str2_float.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4508 b- defN 24-Feb-20 10:55 autoai_libs/lale/float_str2_float.py
--rw-rw-rw-  2.0 fat    55296 b- defN 24-Mar-14 12:01 autoai_libs/lale/fs1.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    55296 b- defN 24-Apr-09 09:38 autoai_libs/lale/fs1.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4651 b- defN 24-Feb-20 10:55 autoai_libs/lale/fs1.py
--rw-rw-rw-  2.0 fat    54784 b- defN 24-Mar-14 12:01 autoai_libs/lale/fs2.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    54784 b- defN 24-Apr-09 09:38 autoai_libs/lale/fs2.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4797 b- defN 24-Feb-20 10:55 autoai_libs/lale/fs2.py
--rw-rw-rw-  2.0 fat    44544 b- defN 24-Mar-14 12:01 autoai_libs/lale/nsfa.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     4043 b- defN 24-Feb-20 10:55 autoai_libs/lale/nsfa.py
--rw-rw-rw-  2.0 fat    69120 b- defN 24-Mar-14 12:01 autoai_libs/lale/num_imputer.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     8435 b- defN 24-Feb-20 10:55 autoai_libs/lale/num_imputer.py
--rw-rw-rw-  2.0 fat    46080 b- defN 24-Mar-14 12:01 autoai_libs/lale/numpy_column_selector.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    45568 b- defN 24-Apr-09 09:38 autoai_libs/lale/nsfa.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     4043 b- defN 24-Apr-09 09:30 autoai_libs/lale/nsfa.py
+-rw-rw-rw-  2.0 fat    69120 b- defN 24-Apr-09 09:38 autoai_libs/lale/num_imputer.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     8396 b- defN 24-Apr-09 09:30 autoai_libs/lale/num_imputer.py
+-rw-rw-rw-  2.0 fat    47104 b- defN 24-Apr-09 09:38 autoai_libs/lale/numpy_column_selector.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     3807 b- defN 24-Feb-20 10:55 autoai_libs/lale/numpy_column_selector.py
--rw-rw-rw-  2.0 fat    45568 b- defN 24-Mar-14 12:01 autoai_libs/lale/numpy_permute_array.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    46080 b- defN 24-Apr-09 09:38 autoai_libs/lale/numpy_permute_array.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4054 b- defN 24-Feb-20 10:55 autoai_libs/lale/numpy_permute_array.py
--rw-rw-rw-  2.0 fat    45056 b- defN 24-Mar-14 12:01 autoai_libs/lale/numpy_replace_missing_values.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    45056 b- defN 24-Apr-09 09:39 autoai_libs/lale/numpy_replace_missing_values.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4303 b- defN 24-Feb-20 10:55 autoai_libs/lale/numpy_replace_missing_values.py
--rw-rw-rw-  2.0 fat    47104 b- defN 24-Mar-14 12:01 autoai_libs/lale/numpy_replace_unknown_values.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    47616 b- defN 24-Apr-09 09:39 autoai_libs/lale/numpy_replace_unknown_values.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     5290 b- defN 24-Feb-20 10:55 autoai_libs/lale/numpy_replace_unknown_values.py
--rw-rw-rw-  2.0 fat    46080 b- defN 24-Mar-14 12:01 autoai_libs/lale/opt_standard_scaler.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    47104 b- defN 24-Apr-09 09:39 autoai_libs/lale/opt_standard_scaler.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4898 b- defN 24-Feb-20 10:55 autoai_libs/lale/opt_standard_scaler.py
--rw-rw-rw-  2.0 fat    45056 b- defN 24-Mar-14 12:01 autoai_libs/lale/t_no_op.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    46080 b- defN 24-Apr-09 09:39 autoai_libs/lale/t_no_op.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     3887 b- defN 24-Feb-20 10:55 autoai_libs/lale/t_no_op.py
--rw-rw-rw-  2.0 fat    60928 b- defN 24-Mar-14 12:01 autoai_libs/lale/ta1.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    61440 b- defN 24-Apr-09 09:39 autoai_libs/lale/ta1.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     6329 b- defN 24-Feb-20 10:55 autoai_libs/lale/ta1.py
--rw-rw-rw-  2.0 fat    49152 b- defN 24-Mar-14 12:01 autoai_libs/lale/ta2.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    49664 b- defN 24-Apr-09 09:39 autoai_libs/lale/ta2.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4933 b- defN 24-Feb-20 10:55 autoai_libs/lale/ta2.py
--rw-rw-rw-  2.0 fat    46080 b- defN 24-Mar-14 12:01 autoai_libs/lale/tam.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    46592 b- defN 24-Apr-09 09:39 autoai_libs/lale/tam.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     3781 b- defN 24-Feb-20 10:55 autoai_libs/lale/tam.py
--rw-rw-rw-  2.0 fat    48128 b- defN 24-Mar-14 12:01 autoai_libs/lale/tb1.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    48640 b- defN 24-Apr-09 09:39 autoai_libs/lale/tb1.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4365 b- defN 24-Feb-20 10:55 autoai_libs/lale/tb1.py
--rw-rw-rw-  2.0 fat    49664 b- defN 24-Mar-14 12:01 autoai_libs/lale/tb2.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    50688 b- defN 24-Apr-09 09:39 autoai_libs/lale/tb2.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     5090 b- defN 24-Feb-20 10:55 autoai_libs/lale/tb2.py
--rw-rw-rw-  2.0 fat    47616 b- defN 24-Mar-14 12:01 autoai_libs/lale/text_transformer.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    49152 b- defN 24-Apr-09 09:39 autoai_libs/lale/text_transformer.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     5630 b- defN 24-Feb-20 10:55 autoai_libs/lale/text_transformer.py
--rw-rw-rw-  2.0 fat    52224 b- defN 24-Mar-14 12:01 autoai_libs/lale/tgen.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    53248 b- defN 24-Apr-09 09:39 autoai_libs/lale/tgen.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     6156 b- defN 24-Feb-20 10:55 autoai_libs/lale/tgen.py
--rw-rw-rw-  2.0 fat    34304 b- defN 24-Mar-14 12:01 autoai_libs/lale/util.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    35840 b- defN 24-Apr-09 09:39 autoai_libs/lale/util.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     1964 b- defN 24-Feb-20 10:55 autoai_libs/lale/util.py
--rw-rw-rw-  2.0 fat    49152 b- defN 24-Mar-14 12:01 autoai_libs/lale/word2vec_transformer.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    50688 b- defN 24-Apr-09 09:39 autoai_libs/lale/word2vec_transformer.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     6285 b- defN 24-Feb-20 10:55 autoai_libs/lale/word2vec_transformer.py
--rw-rw-rw-  2.0 fat    55296 b- defN 24-Mar-14 12:01 autoai_libs/lale/xgboost.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     3423 b- defN 24-Feb-20 10:55 autoai_libs/lale/xgboost.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/mixins/__init__.py
--rw-rw-rw-  2.0 fat    40448 b- defN 24-Mar-14 12:01 autoai_libs/mixins/optimization.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    52736 b- defN 24-Apr-09 09:39 autoai_libs/lale/xgboost.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     3312 b- defN 24-Apr-03 11:49 autoai_libs/lale/xgboost.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/mixins/__init__.py
+-rw-rw-rw-  2.0 fat    40960 b- defN 24-Apr-09 09:39 autoai_libs/mixins/optimization.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     2455 b- defN 24-Feb-20 10:55 autoai_libs/mixins/optimization.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/scorers/__init__.py
--rw-rw-rw-  2.0 fat    32768 b- defN 24-Mar-14 12:02 autoai_libs/scorers/scorers.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/scorers/__init__.py
+-rw-rw-rw-  2.0 fat    34304 b- defN 24-Apr-09 09:39 autoai_libs/scorers/scorers.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat      853 b- defN 24-Feb-20 10:55 autoai_libs/scorers/scorers.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/sklearn/__init__.py
--rw-rw-rw-  2.0 fat    52736 b- defN 24-Mar-14 12:00 autoai_libs/sklearn/custom_scorers.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     2984 b- defN 24-Feb-20 10:55 autoai_libs/sklearn/custom_scorers.py
--rw-rw-rw-  2.0 fat    79360 b- defN 24-Mar-14 12:00 autoai_libs/sklearn/fast_ordinal_encoder.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     6260 b- defN 24-Feb-20 10:55 autoai_libs/sklearn/fast_ordinal_encoder.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/transformers/__init__.py
--rw-rw-rw-  2.0 fat    52736 b- defN 24-Mar-14 12:00 autoai_libs/transformers/column_transformer.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/sklearn/__init__.py
+-rw-rw-rw-  2.0 fat    54272 b- defN 24-Apr-09 09:38 autoai_libs/sklearn/custom_scorers.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     2981 b- defN 24-Apr-09 09:30 autoai_libs/sklearn/custom_scorers.py
+-rw-rw-rw-  2.0 fat    78848 b- defN 24-Apr-09 09:38 autoai_libs/sklearn/fast_ordinal_encoder.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     6393 b- defN 24-Apr-09 09:30 autoai_libs/sklearn/fast_ordinal_encoder.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/transformers/__init__.py
+-rw-rw-rw-  2.0 fat    53248 b- defN 24-Apr-09 09:38 autoai_libs/transformers/column_transformer.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     2780 b- defN 24-Feb-20 10:55 autoai_libs/transformers/column_transformer.py
--rw-rw-rw-  2.0 fat   371712 b- defN 24-Mar-14 12:01 autoai_libs/transformers/exportable.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat    51909 b- defN 24-Mar-06 11:04 autoai_libs/transformers/exportable.py
--rw-rw-rw-  2.0 fat    35840 b- defN 24-Mar-14 12:01 autoai_libs/transformers/general_transformer.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   424960 b- defN 24-Apr-09 09:38 autoai_libs/transformers/exportable.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    52762 b- defN 24-Apr-09 09:30 autoai_libs/transformers/exportable.py
+-rw-rw-rw-  2.0 fat    35840 b- defN 24-Apr-09 09:38 autoai_libs/transformers/general_transformer.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     1197 b- defN 24-Feb-20 10:55 autoai_libs/transformers/general_transformer.py
--rw-rw-rw-  2.0 fat    52224 b- defN 24-Mar-14 12:01 autoai_libs/transformers/small_data_column_transformer.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     2224 b- defN 24-Feb-20 10:55 autoai_libs/transformers/small_data_column_transformer.py
--rw-rw-rw-  2.0 fat    37376 b- defN 24-Mar-14 12:01 autoai_libs/transformers/small_data_transformer.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     1103 b- defN 24-Feb-20 10:55 autoai_libs/transformers/small_data_transformer.py
--rw-rw-rw-  2.0 fat   179200 b- defN 24-Mar-14 12:01 autoai_libs/transformers/text_transformers.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat    21595 b- defN 24-Mar-13 09:53 autoai_libs/transformers/text_transformers.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/transformers/date_time/__init__.py
--rw-rw-rw-  2.0 fat    60416 b- defN 24-Mar-14 12:01 autoai_libs/transformers/date_time/date_time_transformer.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    52224 b- defN 24-Apr-09 09:38 autoai_libs/transformers/small_data_column_transformer.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     2269 b- defN 24-Apr-03 11:49 autoai_libs/transformers/small_data_column_transformer.py
+-rw-rw-rw-  2.0 fat    36864 b- defN 24-Apr-09 09:38 autoai_libs/transformers/small_data_transformer.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     1146 b- defN 24-Apr-03 11:49 autoai_libs/transformers/small_data_transformer.py
+-rw-rw-rw-  2.0 fat   179712 b- defN 24-Apr-09 09:38 autoai_libs/transformers/text_transformers.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    21595 b- defN 24-Apr-03 11:49 autoai_libs/transformers/text_transformers.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/transformers/date_time/__init__.py
+-rw-rw-rw-  2.0 fat    61440 b- defN 24-Apr-09 09:38 autoai_libs/transformers/date_time/date_time_transformer.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     7574 b- defN 24-Feb-20 10:55 autoai_libs/transformers/date_time/date_time_transformer.py
--rw-rw-rw-  2.0 fat    56832 b- defN 24-Mar-14 12:01 autoai_libs/transformers/date_time/date_time_utils.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     7096 b- defN 24-Feb-20 10:55 autoai_libs/transformers/date_time/date_time_utils.py
--rw-rw-rw-  2.0 fat    95744 b- defN 24-Mar-14 12:01 autoai_libs/transformers/date_time/small_time_transformers.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     4329 b- defN 24-Feb-20 10:55 autoai_libs/transformers/date_time/small_time_transformers.py
--rw-rw-rw-  2.0 fat      481 b- defN 24-Mar-14 12:02 autoai_libs/utils/__init__.py
--rw-rw-rw-  2.0 fat    51712 b- defN 24-Mar-14 12:02 autoai_libs/utils/data_utils.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     3014 b- defN 24-Feb-20 10:55 autoai_libs/utils/data_utils.py
--rw-rw-rw-  2.0 fat   336384 b- defN 24-Mar-14 12:02 autoai_libs/utils/exportable_utils.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat    60077 b- defN 24-Feb-20 10:55 autoai_libs/utils/exportable_utils.py
--rw-rw-rw-  2.0 fat    67072 b- defN 24-Mar-14 12:02 autoai_libs/utils/fc_methods.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     3880 b- defN 24-Feb-20 10:55 autoai_libs/utils/fc_methods.py
--rw-rw-rw-  2.0 fat   111616 b- defN 24-Mar-14 12:02 autoai_libs/utils/holdout_utils.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat    15540 b- defN 24-Feb-20 10:55 autoai_libs/utils/holdout_utils.py
--rw-rw-rw-  2.0 fat    29696 b- defN 24-Mar-14 12:02 autoai_libs/utils/intiger_ranges.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    60928 b- defN 24-Apr-09 09:38 autoai_libs/transformers/date_time/date_time_utils.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     7186 b- defN 24-Apr-03 11:49 autoai_libs/transformers/date_time/date_time_utils.py
+-rw-rw-rw-  2.0 fat    96768 b- defN 24-Apr-09 09:38 autoai_libs/transformers/date_time/small_time_transformers.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     4337 b- defN 24-Apr-09 09:30 autoai_libs/transformers/date_time/small_time_transformers.py
+-rw-rw-rw-  2.0 fat      481 b- defN 24-Apr-09 09:39 autoai_libs/utils/__init__.py
+-rw-rw-rw-  2.0 fat    54272 b- defN 24-Apr-09 09:39 autoai_libs/utils/data_utils.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     3137 b- defN 24-Apr-03 11:49 autoai_libs/utils/data_utils.py
+-rw-rw-rw-  2.0 fat   341504 b- defN 24-Apr-09 09:39 autoai_libs/utils/exportable_utils.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    60014 b- defN 24-Apr-09 09:30 autoai_libs/utils/exportable_utils.py
+-rw-rw-rw-  2.0 fat    70144 b- defN 24-Apr-09 09:39 autoai_libs/utils/fc_methods.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     4002 b- defN 24-Apr-09 09:30 autoai_libs/utils/fc_methods.py
+-rw-rw-rw-  2.0 fat   111616 b- defN 24-Apr-09 09:39 autoai_libs/utils/holdout_utils.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    15537 b- defN 24-Apr-09 09:30 autoai_libs/utils/holdout_utils.py
+-rw-rw-rw-  2.0 fat    30208 b- defN 24-Apr-09 09:39 autoai_libs/utils/intiger_ranges.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     1094 b- defN 24-Feb-20 10:55 autoai_libs/utils/intiger_ranges.py
--rw-rw-rw-  2.0 fat    56320 b- defN 24-Mar-14 12:02 autoai_libs/utils/outliers_mitigation.cp310-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    57344 b- defN 24-Apr-09 09:39 autoai_libs/utils/outliers_mitigation.cp311-win_amd64.pyd
 -rw-rw-rw-  2.0 fat     4849 b- defN 24-Feb-20 10:55 autoai_libs/utils/outliers_mitigation.py
--rw-rw-rw-  2.0 fat   113664 b- defN 24-Mar-14 12:02 autoai_libs/utils/parameter_types.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     9642 b- defN 24-Feb-20 10:55 autoai_libs/utils/parameter_types.py
--rw-rw-rw-  2.0 fat    60416 b- defN 24-Mar-14 12:02 autoai_libs/utils/sampling_utils.cp310-win_amd64.pyd
--rw-rw-rw-  2.0 fat     5911 b- defN 24-Feb-20 10:55 autoai_libs/utils/sampling_utils.py
--rw-rw-rw-  2.0 fat       82 b- defN 24-Mar-14 12:02 autoai_libs-1.17.2.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     4051 b- defN 24-Mar-14 12:02 autoai_libs-1.17.2.dist-info/METADATA
--rw-rw-rw-  2.0 fat      113 b- defN 24-Mar-14 12:02 autoai_libs-1.17.2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       12 b- defN 24-Mar-14 12:00 autoai_libs-1.17.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    13751 b- defN 24-Mar-14 12:02 autoai_libs-1.17.2.dist-info/RECORD
-136 files, 4996776 bytes uncompressed, 2024715 bytes compressed:  59.5%
+-rw-rw-rw-  2.0 fat   113152 b- defN 24-Apr-09 09:39 autoai_libs/utils/parameter_types.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     9717 b- defN 24-Apr-03 11:49 autoai_libs/utils/parameter_types.py
+-rw-rw-rw-  2.0 fat    59904 b- defN 24-Apr-09 09:39 autoai_libs/utils/sampling_utils.cp311-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     5876 b- defN 24-Apr-09 09:30 autoai_libs/utils/sampling_utils.py
+-rw-rw-rw-  2.0 fat       82 b- defN 24-Apr-09 09:39 autoai_libs-2.0.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     3422 b- defN 24-Apr-09 09:39 autoai_libs-2.0.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      113 b- defN 24-Apr-09 09:39 autoai_libs-2.0.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       12 b- defN 24-Apr-09 09:37 autoai_libs-2.0.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    13746 b- defN 24-Apr-09 09:39 autoai_libs-2.0.0.dist-info/RECORD
+136 files, 5113832 bytes uncompressed, 2069844 bytes compressed:  59.5%
```

## zipnote {}

```diff
@@ -1,409 +1,409 @@
 Filename: autoai_libs/__init__.py
 Comment: 
 
-Filename: autoai_libs/version.cp310-win_amd64.pyd
+Filename: autoai_libs/version.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/version.py
 Comment: 
 
 Filename: autoai_libs/cognito/__init__.py
 Comment: 
 
 Filename: autoai_libs/cognito/transforms/__init__.py
 Comment: 
 
-Filename: autoai_libs/cognito/transforms/sklearn_compat.cp310-win_amd64.pyd
+Filename: autoai_libs/cognito/transforms/sklearn_compat.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/cognito/transforms/sklearn_compat.py
 Comment: 
 
-Filename: autoai_libs/cognito/transforms/textras_methods.cp310-win_amd64.pyd
+Filename: autoai_libs/cognito/transforms/textras_methods.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/cognito/transforms/textras_methods.py
 Comment: 
 
-Filename: autoai_libs/cognito/transforms/transform_extras.cp310-win_amd64.pyd
+Filename: autoai_libs/cognito/transforms/transform_extras.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/cognito/transforms/transform_extras.py
 Comment: 
 
-Filename: autoai_libs/cognito/transforms/transform_utils.cp310-win_amd64.pyd
+Filename: autoai_libs/cognito/transforms/transform_utils.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/cognito/transforms/transform_utils.py
 Comment: 
 
 Filename: autoai_libs/detectors/__init__.py
 Comment: 
 
-Filename: autoai_libs/detectors/general_detector.cp310-win_amd64.pyd
+Filename: autoai_libs/detectors/general_detector.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/detectors/general_detector.py
 Comment: 
 
-Filename: autoai_libs/detectors/small_data_detector.cp310-win_amd64.pyd
+Filename: autoai_libs/detectors/small_data_detector.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/detectors/small_data_detector.py
 Comment: 
 
 Filename: autoai_libs/detectors/date_time/__init__.py
 Comment: 
 
-Filename: autoai_libs/detectors/date_time/date_time_detector.cp310-win_amd64.pyd
+Filename: autoai_libs/detectors/date_time/date_time_detector.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/detectors/date_time/date_time_detector.py
 Comment: 
 
 Filename: autoai_libs/estimators/__init__.py
 Comment: 
 
-Filename: autoai_libs/estimators/xgboost.cp310-win_amd64.pyd
+Filename: autoai_libs/estimators/xgboost.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/estimators/xgboost.py
 Comment: 
 
 Filename: autoai_libs/lale/__init__.py
 Comment: 
 
-Filename: autoai_libs/lale/_common_schemas.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/_common_schemas.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/_common_schemas.py
 Comment: 
 
-Filename: autoai_libs/lale/boolean2float.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/boolean2float.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/boolean2float.py
 Comment: 
 
-Filename: autoai_libs/lale/cat_encoder.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/cat_encoder.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/cat_encoder.py
 Comment: 
 
-Filename: autoai_libs/lale/cat_imputer.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/cat_imputer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/cat_imputer.py
 Comment: 
 
-Filename: autoai_libs/lale/column_selector.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/column_selector.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/column_selector.py
 Comment: 
 
-Filename: autoai_libs/lale/compress_strings.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/compress_strings.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/compress_strings.py
 Comment: 
 
-Filename: autoai_libs/lale/date_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/date_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/date_transformer.py
 Comment: 
 
-Filename: autoai_libs/lale/float32_transform.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/float32_transform.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/float32_transform.py
 Comment: 
 
-Filename: autoai_libs/lale/float_str2_float.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/float_str2_float.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/float_str2_float.py
 Comment: 
 
-Filename: autoai_libs/lale/fs1.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/fs1.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/fs1.py
 Comment: 
 
-Filename: autoai_libs/lale/fs2.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/fs2.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/fs2.py
 Comment: 
 
-Filename: autoai_libs/lale/nsfa.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/nsfa.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/nsfa.py
 Comment: 
 
-Filename: autoai_libs/lale/num_imputer.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/num_imputer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/num_imputer.py
 Comment: 
 
-Filename: autoai_libs/lale/numpy_column_selector.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/numpy_column_selector.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/numpy_column_selector.py
 Comment: 
 
-Filename: autoai_libs/lale/numpy_permute_array.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/numpy_permute_array.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/numpy_permute_array.py
 Comment: 
 
-Filename: autoai_libs/lale/numpy_replace_missing_values.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/numpy_replace_missing_values.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/numpy_replace_missing_values.py
 Comment: 
 
-Filename: autoai_libs/lale/numpy_replace_unknown_values.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/numpy_replace_unknown_values.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/numpy_replace_unknown_values.py
 Comment: 
 
-Filename: autoai_libs/lale/opt_standard_scaler.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/opt_standard_scaler.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/opt_standard_scaler.py
 Comment: 
 
-Filename: autoai_libs/lale/t_no_op.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/t_no_op.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/t_no_op.py
 Comment: 
 
-Filename: autoai_libs/lale/ta1.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/ta1.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/ta1.py
 Comment: 
 
-Filename: autoai_libs/lale/ta2.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/ta2.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/ta2.py
 Comment: 
 
-Filename: autoai_libs/lale/tam.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/tam.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/tam.py
 Comment: 
 
-Filename: autoai_libs/lale/tb1.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/tb1.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/tb1.py
 Comment: 
 
-Filename: autoai_libs/lale/tb2.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/tb2.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/tb2.py
 Comment: 
 
-Filename: autoai_libs/lale/text_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/text_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/text_transformer.py
 Comment: 
 
-Filename: autoai_libs/lale/tgen.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/tgen.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/tgen.py
 Comment: 
 
-Filename: autoai_libs/lale/util.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/util.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/util.py
 Comment: 
 
-Filename: autoai_libs/lale/word2vec_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/word2vec_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/word2vec_transformer.py
 Comment: 
 
-Filename: autoai_libs/lale/xgboost.cp310-win_amd64.pyd
+Filename: autoai_libs/lale/xgboost.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/lale/xgboost.py
 Comment: 
 
 Filename: autoai_libs/mixins/__init__.py
 Comment: 
 
-Filename: autoai_libs/mixins/optimization.cp310-win_amd64.pyd
+Filename: autoai_libs/mixins/optimization.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/mixins/optimization.py
 Comment: 
 
 Filename: autoai_libs/scorers/__init__.py
 Comment: 
 
-Filename: autoai_libs/scorers/scorers.cp310-win_amd64.pyd
+Filename: autoai_libs/scorers/scorers.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/scorers/scorers.py
 Comment: 
 
 Filename: autoai_libs/sklearn/__init__.py
 Comment: 
 
-Filename: autoai_libs/sklearn/custom_scorers.cp310-win_amd64.pyd
+Filename: autoai_libs/sklearn/custom_scorers.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/sklearn/custom_scorers.py
 Comment: 
 
-Filename: autoai_libs/sklearn/fast_ordinal_encoder.cp310-win_amd64.pyd
+Filename: autoai_libs/sklearn/fast_ordinal_encoder.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/sklearn/fast_ordinal_encoder.py
 Comment: 
 
 Filename: autoai_libs/transformers/__init__.py
 Comment: 
 
-Filename: autoai_libs/transformers/column_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/column_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/column_transformer.py
 Comment: 
 
-Filename: autoai_libs/transformers/exportable.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/exportable.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/exportable.py
 Comment: 
 
-Filename: autoai_libs/transformers/general_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/general_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/general_transformer.py
 Comment: 
 
-Filename: autoai_libs/transformers/small_data_column_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/small_data_column_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/small_data_column_transformer.py
 Comment: 
 
-Filename: autoai_libs/transformers/small_data_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/small_data_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/small_data_transformer.py
 Comment: 
 
-Filename: autoai_libs/transformers/text_transformers.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/text_transformers.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/text_transformers.py
 Comment: 
 
 Filename: autoai_libs/transformers/date_time/__init__.py
 Comment: 
 
-Filename: autoai_libs/transformers/date_time/date_time_transformer.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/date_time/date_time_transformer.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/date_time/date_time_transformer.py
 Comment: 
 
-Filename: autoai_libs/transformers/date_time/date_time_utils.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/date_time/date_time_utils.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/date_time/date_time_utils.py
 Comment: 
 
-Filename: autoai_libs/transformers/date_time/small_time_transformers.cp310-win_amd64.pyd
+Filename: autoai_libs/transformers/date_time/small_time_transformers.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/transformers/date_time/small_time_transformers.py
 Comment: 
 
 Filename: autoai_libs/utils/__init__.py
 Comment: 
 
-Filename: autoai_libs/utils/data_utils.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/data_utils.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/data_utils.py
 Comment: 
 
-Filename: autoai_libs/utils/exportable_utils.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/exportable_utils.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/exportable_utils.py
 Comment: 
 
-Filename: autoai_libs/utils/fc_methods.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/fc_methods.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/fc_methods.py
 Comment: 
 
-Filename: autoai_libs/utils/holdout_utils.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/holdout_utils.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/holdout_utils.py
 Comment: 
 
-Filename: autoai_libs/utils/intiger_ranges.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/intiger_ranges.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/intiger_ranges.py
 Comment: 
 
-Filename: autoai_libs/utils/outliers_mitigation.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/outliers_mitigation.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/outliers_mitigation.py
 Comment: 
 
-Filename: autoai_libs/utils/parameter_types.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/parameter_types.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/parameter_types.py
 Comment: 
 
-Filename: autoai_libs/utils/sampling_utils.cp310-win_amd64.pyd
+Filename: autoai_libs/utils/sampling_utils.cp311-win_amd64.pyd
 Comment: 
 
 Filename: autoai_libs/utils/sampling_utils.py
 Comment: 
 
-Filename: autoai_libs-1.17.2.dist-info/LICENSE.txt
+Filename: autoai_libs-2.0.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: autoai_libs-1.17.2.dist-info/METADATA
+Filename: autoai_libs-2.0.0.dist-info/METADATA
 Comment: 
 
-Filename: autoai_libs-1.17.2.dist-info/WHEEL
+Filename: autoai_libs-2.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: autoai_libs-1.17.2.dist-info/top_level.txt
+Filename: autoai_libs-2.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: autoai_libs-1.17.2.dist-info/RECORD
+Filename: autoai_libs-2.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## autoai_libs/__init__.py

```diff
@@ -3,8 +3,22 @@
 # OCO Source Materials
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2019-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
+import logging.config
+
 from autoai_libs.version import __version__
+
+logging_cfg = {
+    "version": 1,
+    "formatters": {},
+    "filters": {},
+    "handlers": {},
+    "loggers": {
+        "autoai_libs": {"propagate": False},  # top-level library logger
+    },
+}
+
+logging.config.dictConfig(logging_cfg)
```

## autoai_libs/version.py

```diff
@@ -3,8 +3,8 @@
 # OCO Source Materials
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2019-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
-__version__ = "1.17.2"
+__version__ = "2.0.0"
```

## autoai_libs/cognito/transforms/sklearn_compat.py

```diff
@@ -18,15 +18,14 @@
 
 class CognitoTransformer(TransformerMixin):
     def __init__(self):
         super().__init__()
         self.rng = numpy.random.default_rng(seed=SEED)
 
     def get_params(self, deep=True):
-        # print('we are in the custom get_params')
         klass = self.__class__
         key = "__" + klass.__name__ + "__"
         sig = inspect.signature(self.__init__)
         param_dict = {}
         for pname in sig.parameters:
             value = self.__dict__[pname]
             param_dict[pname] = value
```

## autoai_libs/cognito/transforms/transform_extras.py

```diff
@@ -4,33 +4,35 @@
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2019-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
 
-import pandas as pd
-import numpy as np
-import autoai_libs.utils.fc_methods as FC
 import uuid
 
-from autoai_libs.cognito.transforms.transform_utils import DataUtils
-
-from sklearn.preprocessing import LabelEncoder
-from autoai_libs.cognito.transforms.sklearn_compat import CognitoTransformer
-from sklearn.neighbors import KNeighborsClassifier
+import numpy as np
+import pandas as pd
 from sklearn.cluster import DBSCAN
-from sklearn.preprocessing import StandardScaler
 from sklearn.ensemble import IsolationForest
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.preprocessing import StandardScaler
+
+import autoai_libs.utils.fc_methods as FC
+from autoai_libs.cognito.transforms.sklearn_compat import CognitoTransformer
 
 try:
     from sklearn.preprocessing import Imputer
 except ImportError:
     from sklearn.impute import SimpleImputer as Imputer
 
+import logging
+
+logger = logging.getLogger("autoai_libs")
+
 
 class ImputerWrapper:
     def __init__(self):
         self.sklimputr = Imputer()
         self.name = "Imputer"
         self.uid = "TA2-" + str(self.name) + "_" + str(uuid.uuid4())
         self.long_name = self.uid
@@ -180,15 +182,14 @@
     def __init__(self):
         raise ValueError("Class def not complete")
 
     def fit(self, X, y=None):
         colname1 = X.columns[0]
         colname2 = X.columns[1]
         # self.hsh_ = X.groupby([colname])[colname].count()
-        # print(self.hsh_)
         return self
 
     def transform(self, X):
         # fun = lambda x: self.hsh_[x]
         X_tr = self.get_hsh(X.iloc[:, 0])
         return X_tr
 
@@ -200,15 +201,15 @@
     def fit(self, X, y=None):
         Xdf = pd.DataFrame(X)
         cnames = Xdf.columns
         try:
             self.aggs = Xdf.groupby(cnames[0]).mean()[cnames[1]]
             del Xdf
         except Exception as e:
-            print(X.columns)
+            logger.debug(X.columns)
             raise e
         return self
 
     def transform(self, X):
         Xdf = pd.DataFrame(X)
         # fun = lambda x: self.aggs[x]
         X_tr = self.get_val(Xdf.iloc[:, 0])
@@ -220,18 +221,18 @@
 
 
 class GroupByStd:
     def fit(self, X, y=None):
         Xdf = pd.DataFrame(X)
         cnames = Xdf.columns
         try:
-            self.aggs = Xdf.groupby(cnames[0]).std()[cnames[1]]
+            self.aggs = Xdf.groupby(cnames[0]).std(numeric_only=True)[cnames[1]]
             del Xdf
         except Exception as e:
-            print(X.columns)
+            logger.debug(X.columns)
             raise e
         return self
 
     def transform(self, X):
         Xdf = pd.DataFrame(X)
         # fun = lambda x: self.aggs[x]
         X_tr = self.get_val(Xdf.iloc[:, 0])
@@ -243,18 +244,18 @@
 
 
 class GroupByMedian:
     def fit(self, X, y=None):
         Xdf = pd.DataFrame(X)
         cnames = Xdf.columns
         try:
-            self.aggs = Xdf.groupby(cnames[0]).median()[cnames[1]]
+            self.aggs = Xdf.groupby(cnames[0]).median(numeric_only=True)[cnames[1]]
             del Xdf
         except Exception as e:
-            print(Xdf.columns)
+            logger.debug(Xdf.columns)
             raise e
         return self
 
     def transform(self, X):
         Xdf = pd.DataFrame(X)
         # fun = lambda x: self.aggs[x]
         X_tr = self.get_val(Xdf.iloc[:, 0])
@@ -269,15 +270,15 @@
     def fit(self, X, y=None):
         Xdf = pd.DataFrame(X)
         cnames = Xdf.columns
         try:
             self.aggs = Xdf.groupby(cnames[0]).min()[cnames[1]]
             del Xdf
         except Exception as e:
-            print(Xdf.columns)
+            logger.debug(Xdf.columns)
             raise e
         return self
 
     def transform(self, X):
         Xdf = pd.DataFrame(X)
         # fun = lambda x: self.aggs[x]
         X_tr = self.get_val(Xdf.iloc[:, 0])
@@ -292,15 +293,15 @@
     def fit(self, X, y=None):
         Xdf = pd.DataFrame(X)
         cnames = Xdf.columns
         try:
             self.aggs = Xdf.groupby(cnames[0]).max()[cnames[1]]
             del Xdf
         except Exception as e:
-            print(Xdf.columns)
+            logger.debug(Xdf.columns)
             raise e
         return self
 
     def transform(self, X):
         Xdf = pd.DataFrame(X)
         # fun = lambda x: self.aggs[x]
         X_tr = self.get_val(Xdf.iloc[:, 0])
@@ -376,15 +377,14 @@
 #         self.verbose = verbose
 #
 #         self.all_methods = ['best', 'majority', 'label', 'target', 'binary', 'onehot', 'backward-diff', 'sum',
 #                             'polynomial']
 #         self.all_encoders = ['label', 'target', 'binary', 'onehot', 'backward-diff', 'sum', 'polynomial']
 #
 #         if self.method not in self.all_methods:
-#             print('Not a recognizable method. Returning')
 #             return None
 #
 #     def fit(self, X, y, X_bigger=None):
 #         # X_bigger possibly includes X_train + X_test (in order to know all labels)
 #
 #         if self.method not in self.all_encoders:
 #             from cognito.eda import EDATools
```

## autoai_libs/cognito/transforms/transform_utils.py

```diff
@@ -4,43 +4,45 @@
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2019-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
 
-import pandas as pd
-import numpy as np
+import copy
+import inspect
+import logging
+import multiprocessing
+import operator
+import random
 import uuid
+from abc import ABC, abstractmethod
 
-from sklearn.feature_selection import SelectKBest, f_classif, f_regression
-import operator
-from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
+import numpy as np
+import pandas as pd
+from sklearn.cluster import FeatureAgglomeration
 from sklearn.decomposition import PCA, FastICA
+from sklearn.feature_selection import SelectKBest, f_classif, f_regression
 from sklearn.kernel_approximation import Nystroem
-from sklearn.cluster import FeatureAgglomeration
-import inspect
-import random
-import multiprocessing
-import copy
-from autoai_libs.cognito.transforms.sklearn_compat import CognitoTransformer
-from autoai_libs.utils.exportable_utils import WML_raise_exception
-import autoai_libs.utils.fc_methods as FC
-from sklearn.preprocessing import KBinsDiscretizer
+from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler, OneHotEncoder, StandardScaler
+
 import autoai_libs.cognito.transforms.textras_methods as TExtras
+import autoai_libs.utils.fc_methods as FC
+from autoai_libs.cognito.transforms.sklearn_compat import CognitoTransformer
 from autoai_libs.utils.data_utils import DataUtils
-
-from abc import ABC, abstractmethod
+from autoai_libs.utils.exportable_utils import WML_raise_exception
 
 JSON_FUNCTION_NAME_TOKEN = "functionName"
 JSON_PARAMETER_TOKEN = "parameter"
 JSON_TYPE_TOKEN = "type"
 JSON_TYPE_FEATURE_VALUE = "feature"
 JSON_TYPE_FUNCTION_VALUE = "function"
 
+logger = logging.getLogger("autoai_libs")
+
 
 def resolve_basic_datatypes(datatypes):
     basic_datatypes = []
     for dt in datatypes:
         dts = DataUtils.get_basic_types(dt)
         basic_datatypes.extend(dts)
     return basic_datatypes
@@ -189,15 +191,14 @@
                 else:
                     current_cumul_tree = self._compute_cumul_left_tree_size(
                         tree_desc, curr_node_id, current_cumul_tree, current_cumul_tree[first_node_id][0] + subtree_size
                     )
                     subtree_size += current_cumul_tree[curr_node_id][1]
         if subtree_size is None:
             current_cumul_tree[current_node_id] = (current_cumul, 0)
-            # print("ERROR")
         else:
             current_cumul_tree[current_node_id] = (current_cumul_tree[first_node_id][0], subtree_size)
 
         return current_cumul_tree
 
     def _get_node_id(self, cumul_tree, current_node_id, index):
         if len(self.matching_colids_by_arg) == len(current_node_id):
@@ -270,31 +271,31 @@
         if self.run_ is None:
             raise ValueError("MakeDFReady issue")
 
         try:
             X_tr = X.iloc[:, self.numeric_colids_]
             return X_tr
         except:
-            print("present columns: " + str(len(X.columns)))
-            print("numeric columns to keep" + str(self.numeric_colids_))
+            logger.error("present columns: " + str(len(X.columns)))
+            logger.error("numeric columns to keep" + str(self.numeric_colids_))
             raise Exception("Issue in MakeDFReady.transform")
 
     def fit(self, X, y):
         self.run_ = True
         df = pd.DataFrame(X)
         colnames = list(df.columns)
         colcount = len(colnames)
         self.numeric_colids_ = []
         for i in range(colcount):
             try:
                 if str(df.iloc[:, i].dtype) in DataUtils.NumericDataTypes():
                     self.numeric_colids_.append(i)
             except:
-                print(df.iloc[:, i])
-                print("colname=" + df.iloc[:, i].name)
+                logger.debug(df.iloc[:, i])
+                logger.debug("colname=" + df.iloc[:, i].name)
         return self
 
 
 class FS1(CognitoTransformer):
     def __init__(self, cols_ids_must_keep, additional_col_count_to_keep, ptype):
         super().__init__()
         self.long_name = "FS1-" + str(uuid.uuid4())
@@ -305,18 +306,18 @@
         self.ptype = ptype
 
     def transform(self, X, n_jobs=1):
         try:
             X_tr = X[:, self.cols_to_keep_final_]
             return X_tr
         except Exception as e:
-            print("Error in executing FS" + str(e))
-            print("columns to keep" + str(self.cols_to_keep_final_))
-            print("# of columns in df : " + str(X.shape[1]))
-            print("columns in fit  df : " + str(set(self.cols_in_base_ds_)))
+            logger.error("Error in executing FS", exc_info=e)
+            logger.debug("columns to keep" + str(self.cols_to_keep_final_))
+            logger.debug("# of columns in df : " + str(X.shape[1]))
+            logger.debug("columns in fit  df : " + str(set(self.cols_in_base_ds_)))
             raise e
 
     def fit(self, X, y):
         if self.ptype == "classification":
             skb = SelectKBest(f_classif, k="all")
         else:
             skb = SelectKBest(f_regression, k="all")
@@ -373,17 +374,17 @@
         self.eval_algo = eval_algo
 
     def transform(self, X, n_jobs=1):
         try:
             X_tr = X[:, self.cols_to_keep_final_]
             return X_tr
         except Exception as e:
-            print("Error in executing FS" + str(e))
-            print("columns to keep" + str(self.cols_to_keep_final_))
-            print("# of columns in df : " + str(X.shape[1]))
+            logger.error("Error in executing FS", exc_info=e)
+            logger.debug("columns to keep" + str(self.cols_to_keep_final_))
+            logger.debug("# of columns in df : " + str(X.shape[1]))
             raise e
 
     def fit(self, X, y):
         if inspect.isclass(self.eval_algo):
             self.eval_algo_ = self.eval_algo(random_state=7)
         else:
             self.eval_algo_ = copy.deepcopy(self.eval_algo)
@@ -413,15 +414,14 @@
             self.cols_to_keep_final_.append(ind)
             fs_scores[ind] = -np.inf
 
         for i in range(0, self.k_):
             max_index, max_value = max(enumerate(fs_scores), key=operator.itemgetter(1))
             if max_value == -np.inf:
                 break
-                # print('Max Val= -np.inf')
             self.cols_to_keep_final_.append(max_index)
             fs_scores[max_index] = -np.inf
 
         self.cols_to_keep_final_.sort()
 
 
 class FS3(CognitoTransformer):
@@ -532,15 +532,15 @@
     @staticmethod
     def all_feats_numeric(df):
         for colid in range(0, df.shape[1]):
             try:
                 if not df[:, colid].dtype in DataUtils.NumericDataTypes():
                     return False
             except Exception as e:
-                print(df[:, colid])
+                logger.debug(df[:, colid])
                 raise e
         return True
 
     @staticmethod
     def get_unique_column_name(proposed_name, existing_name_list):
         while proposed_name in existing_name_list:
             proposed_name = proposed_name + "-" + str(random.randint(0, 9))
@@ -622,15 +622,15 @@
 
         self.uid = "TA1-" + str(self.name) + "_" + str(uuid.uuid4())
         self.long_name = self.uid
 
     def transform(self, X, n_jobs=1, return_new_cols_only=False):
         assert isinstance(X, np.ndarray)
         if self.apply_all is False and X.shape[1] != 1:
-            print(
+            logger.warning(
                 " More than admissible number of columns provided for transform with apply_all=False for transform "
                 + self.name
             )
             return None
 
         if self.tgraph is not None and self.tgraph.multiprocessing is True:
             pool = multiprocessing.Pool(n_jobs)
@@ -670,16 +670,16 @@
         desc = CandidatesSpaceDescriptor()
 
         colids = []
         for colid in range(0, df.shape[1]):
             try:
                 ty = str(col_dtypes[colid])
             except Exception as e:
-                print(df.shape[1])
-                print(df[:, colid])
+                logger.debug(df.shape[1])
+                logger.debug(df[:, colid])
                 raise e
             # for allowedDT in self.datatypes:
             if ty in resolve_basic_datatypes(self.datatypes) and self.all_fc_satisifed(
                 df[:, colid], col_names[(len(col_names) - df.shape[1]) + colid]
             ):
                 colids.append(colid)
 
@@ -688,16 +688,16 @@
 
     def get_candidates(self, df, col_names, col_dtypes):
         colids = []
         for colid in range(0, df.shape[1]):
             try:
                 ty = str(col_dtypes[colid])
             except Exception as e:
-                print(df.shape[1])
-                print(df[:, colid])
+                logger.debug(df.shape[1])
+                logger.debug(df[:, colid])
                 raise e
             # for allowedDT in self.datatypes:
             if ty in resolve_basic_datatypes(self.datatypes) and self.all_fc_satisifed(df[:, colid], col_names[colid]):
                 colids.append(colid)
 
         desc = self.get_candidates_space_descriptor(df, col_names, col_dtypes)
         search_space_size = desc.get_size()
@@ -735,23 +735,22 @@
                     tree_desc, self.tgraph.max_feature_generate_one_node
                 )
             if self.colids_ is None:
                 self.colids_ = self.get_candidates(X, col_names, col_dtypes)
 
         else:
             if X.shape[1] != 1:
-                print("More columns than 1 provided for apply_all in transform " + self.name)
+                logger.warning("More columns than 1 provided for apply_all in transform " + self.name)
                 return None
             self.colids_ = [0]
 
         # if self.apply_all:
         #     colids = self.get_candidates(X, col_names, col_dtypes)
         # else:
         #     if X.shape[1] != 1:
-        #         print('More columns than 1 provided for apply_all in transform ' + self.name)
         #         return None
         #     colids = [0]
         #
         # self.colids_ = colids
         # if self.tgraph is not None and self.tgraph.max_feature_generate_one_node is not None:
         #     self.colids_ = self.reduce_count_of_candidates(self.colids_, self.tgraph.max_feature_generate_one_node)
 
@@ -863,16 +862,16 @@
         desc = CandidatesSpaceDescriptor()
 
         matching_colids1 = []
         for colid1 in range(0, df.shape[1]):
             try:
                 ty1 = str(col_dtypes[colid1])
             except Exception as e:
-                print(col_names)
-                print(df[:, colid1])
+                logger.debug(col_names)
+                logger.debug(df[:, colid1])
                 raise e
             if ty1 in resolve_basic_datatypes(self.datatypes1) and self.all_fc1_satisifed(
                 df[:, colid1], col_names[colid1]
             ):
                 matching_colids1.append(colid1)
 
         matching_colids2 = []
@@ -889,16 +888,16 @@
 
     def get_candidates(self, df, col_names, col_dtypes):
         col_pair_ids = []
         for colid1 in range(0, df.shape[1]):
             try:
                 ty1 = str(col_dtypes[colid1])
             except Exception as e:
-                print(col_names)
-                print(df[:, colid1])
+                logger.debug(col_names)
+                logger.debug(df[:, colid1])
                 raise e
 
             if ty1 in resolve_basic_datatypes(self.datatypes1) and self.all_fc1_satisifed(
                 df[:, colid1], col_names[colid1]
             ):
                 for colid2 in range(0, df.shape[1]):
                     if colid1 == colid2:
@@ -1406,15 +1405,15 @@
             self.feat_constraints = feat_constraints
 
         self.uid = "TB1-" + str(name) + "_" + str(uuid.uuid4())
         self.long_name = self.uid
 
     def transform(self, X, n_jobs=1, return_new_cols_only=False):
         if self.apply_all is False and X.shape[1] != 1:
-            print(
+            logger.warning(
                 " More than admissible number of columns provided for transform with apply_all=False for transform "
                 + self.name
             )
             return None
 
         new_col_dtypes = []
         new_col_names = []
@@ -1544,23 +1543,22 @@
                     tree_desc, self.tgraph.max_feature_generate_one_node
                 )
             if self.colids_ is None:
                 self.colids_ = self.get_candidates(X, col_names, col_dtypes)
 
         else:
             if X.shape[1] != 1:
-                print("More columns than 1 provided for apply_all in transform " + self.name)
+                logger.warning("More columns than 1 provided for apply_all in transform " + self.name)
                 return None
             self.colids_ = [0]
 
         # if self.apply_all:
         #     self.colids_ = self.get_candidates(X, col_names, col_dtypes)
         # else:
         #     if X.shape[1] != 1:
-        #         print('More columns than 1 provided for apply_all in transform ' + self.name)
         #         return None
         #
         #     self.colids_ = [0]
         #
         # if self.tgraph is not None and self.tgraph.max_feature_generate_one_node is not None:
         #     self.colids_ = self.reduce_count_of_candidates(self.colids_, self.tgraph.max_feature_generate_one_node)
 
@@ -1669,15 +1667,17 @@
                         + ")"
                     )
                 new_full_name = DataUtils.get_unique_column_name(new_full_name, df1_.columns)
                 df1_[new_full_name] = new_col.values
 
         df1_ = df1_.replace([np.nan, np.inf, -np.inf], 0)
         if df1_.isnull().any().any():
-            print("Null values in newly transformed df through %s : %s " % (self.name, str(df1_.isnull().any().any())))
+            logger.debug(
+                "Null values in newly transformed df through %s : %s " % (self.name, str(df1_.isnull().any().any()))
+            )
 
         del df_
         return df1_
 
     def get_candidates_space_descriptor(self, df, col_names, col_dtypes):
         desc = CandidatesSpaceDescriptor()
 
@@ -1954,24 +1954,24 @@
     @staticmethod
     def GetCommutativeTransformNames():
         return ["product", "min", "max", "sum"]
 
     @staticmethod
     def GetTransformObj(trName, tgraph=None, apply_all=True):
         from autoai_libs.cognito.transforms.transform_extras import (
+            NXOR,
+            ClusterDBSCAN,
             Frequency,
-            Pair,
+            GroupByMax,
             GroupByMean,
-            GroupByStd,
             GroupByMedian,
-            GroupByMax,
             GroupByMin,
-            NXOR,
-            ClusterDBSCAN,
+            GroupByStd,
             IsolationForestAnomaly,
+            Pair,
         )
 
         if trName == "sqrt":
             # return TGen(np.sqrt, 'sqrt', 1, [['numeric']], [[FC.is_non_negative]])
             return TA1(
                 np.sqrt,
                 "sqrt",
```

## autoai_libs/detectors/small_data_detector.py

```diff
@@ -6,17 +6,19 @@
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 import logging
 
 from .general_detector import AutoAIDetector
 
+logger = logging.getLogger("autoai_libs")
+
 
 class SmallDataDetector(AutoAIDetector):
     def is_valid(self, *args, **kwargs) -> bool:
         try:
             self.detect(*args, **kwargs)
-        except:
-            logging.error("The detector is invalid.", exc_info=True)
+        except Exception as e:
+            logger.warning("The detector is invalid.", exc_info=e)
             return False
 
         return True
```

## autoai_libs/detectors/date_time/date_time_detector.py

```diff
@@ -9,21 +9,24 @@
 import logging
 from typing import List
 
 import numpy as np
 import pandas as pd
 
 from autoai_libs.utils.exportable_utils import (
-    setValueOrDefault,
+    FCplus,
     global_missing_values_reference_list,
     numpy_whatis,
-    FCplus,
+    setValueOrDefault,
 )
+
 from ..small_data_detector import SmallDataDetector
 
+logger = logging.getLogger("autoai_libs")
+
 
 class DateDatasetDetector(SmallDataDetector):
     """DateDatasetDetector class for detecting columns with date.
 
     Parameters
     ----------
     X: np.ndarray, required
@@ -73,24 +76,24 @@
             if self.date_columns_indices:
                 return self.X
         else:
             return self.X[:, self.date_columns_indices]
 
     def detect(self) -> bool:
         """Find out which columns are date columns. Returns True if date column is detected otherwise returns False."""
-        logging.debug("DateDatasetDetector: Starting detection of columns with date values")
+        logger.debug("DateDatasetDetector: Starting detection of columns with date values")
 
         for j in range(self.num_columns):
             if self.num_columns == 1:
                 x_col = self.X
             else:
                 x_col = self.X[:, j]
 
             misslist, dtype_str, stats = numpy_whatis(x_col, self.missing_values_reference_list, return_stats_flag=True)
             dfc = pd.DataFrame(x_col)
             if FCplus.is_column_string_in_datetime_format(dfc[0]) and stats["datetime_column_flag"]:
                 self.flag = True
                 self.date_columns_indices.append(j)
 
-        logging.debug("DateDatasetDetector: Ending detection of columns with date values")
+        logger.debug("DateDatasetDetector: Ending detection of columns with date values")
 
         return self.flag
```

## autoai_libs/estimators/xgboost.py

```diff
@@ -2,24 +2,30 @@
 # IBM Confidential
 # OCO Source Materials
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2022-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
+
+import logging
+
+from sklearn.preprocessing import LabelEncoder
+
+logger = logging.getLogger("autoai_libs")
+
 try:
     from xgboost import XGBClassifier as XGBClassifierBase
-except ImportError as error:
-    from logging import warning
+except ImportError as e:
 
-    warning(
-        "{}: autoai_libs.estimators.XGBClassifier will be unavailable. To install, run:\n"
-        "pip install 'autoai-libs[xgboost-wrapper]'".format(error)
+    logger.warning(
+        "autoai_libs.estimators.XGBClassifier will be unavailable. To install, run:\n"
+        "pip install 'autoai-libs[xgboost-wrapper]'",
+        exc_info=e,
     )
-from sklearn.preprocessing import LabelEncoder
 
 
 class XGBClassifier(XGBClassifierBase):
     """
     This is wrapper for XGBClassifier from xgboost package.
     Starting from version 1.6, pure XGBClassifier removes internal LabelEncoder.
     For reference:
```

## autoai_libs/lale/cat_imputer.py

```diff
@@ -149,21 +149,19 @@
 
 CatImputer = lale.operators.make_operator(_CatImputerImpl, _combined_schemas)
 
 autoai_libs_version_str = getattr(autoai_libs, "__version__", None)
 if isinstance(autoai_libs_version_str, str):  # beware sphinx _MockModule
     import typing
 
-    from packaging import version
-
     from lale.schemas import AnyOf, Array, Enum, Float, Not, Null, Object, String
 
-    autoai_libs_version = version.parse(autoai_libs_version_str)
+    autoai_libs_version = tuple(map(int, autoai_libs_version_str.split(".")))
 
-    if autoai_libs_version >= version.Version("1.12.18"):
+    if autoai_libs_version >= (1, 12, 18):
         CatImputer = typing.cast(
             lale.operators.PlannedIndividualOp,
             CatImputer.customize_schema(
                 set_as_available=True,
                 constraint=[
                     AnyOf(
                         desc="fill_value and fill_values cannot both be specified",
```

## autoai_libs/lale/num_imputer.py

```diff
@@ -127,21 +127,19 @@
 
 NumImputer = lale.operators.make_operator(_NumImputerImpl, _combined_schemas)
 
 autoai_libs_version_str = getattr(autoai_libs, "__version__", None)
 if isinstance(autoai_libs_version_str, str):  # beware sphinx _MockModule
     import typing
 
-    from packaging import version
-
     from lale.schemas import AnyOf, Array, Enum, Float, Not, Null, Object, String
 
-    autoai_libs_version = version.parse(autoai_libs_version_str)
+    autoai_libs_version = tuple(map(int, autoai_libs_version_str.split(".")))
 
-    if autoai_libs_version >= version.Version("1.12.18"):
+    if autoai_libs_version >= (1, 12, 18):
         NumImputer = typing.cast(
             lale.operators.PlannedIndividualOp,
             NumImputer.customize_schema(
                 set_as_available=True,
                 constraint=[
                     AnyOf(
                         desc="fill_value and fill_values cannot both be specified",
```

## autoai_libs/lale/xgboost.py

```diff
@@ -6,30 +6,24 @@
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
 import warnings
 from typing import TYPE_CHECKING
 
-import numpy as np
-import pandas as pd
-
 import lale.docstrings
 import lale.operators
 
 import autoai_libs.estimators.xgboost
 
 try:
     from lale.lib.xgboost.xgb_classifier import XGBClassifier as XGBClassifier_lale
-except ImportError as error:
-    from logging import warning
-
-    warning(
-        "{}: autoai_libs.lale.XGBClassifier will be unavailable. To install, run:\n"
-        "pip install 'autoai-libs[xgboost-wrapper]'".format(error)
+except ImportError:
+    warnings.warn(
+        "autoai_libs.lale.XGBClassifier will be unavailable. To install, run:\npip install 'autoai-libs[xgboost-wrapper]'"
     )
 
 try:
     import xgboost  # type: ignore
 
     xgboost_installed = True
 except ImportError:
```

## autoai_libs/sklearn/custom_scorers.py

```diff
@@ -50,15 +50,15 @@
     def root_mean_squared_error(y_true, y_pred, sample_weight=None, multioutput="uniform_average"):
         mse = mean_squared_error(y_true, y_pred, sample_weight=sample_weight, multioutput=multioutput)
         return mse**0.5
 
     @staticmethod
     def gini(actual, pred):
         assert len(actual) == len(pred)
-        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)
+        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=float)
         all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
         totalLosses = all[:, 0].sum()
         giniSum = all[:, 0].cumsum().sum() / totalLosses
 
         giniSum -= (len(actual) + 1) / 2
         return giniSum / len(actual)
```

## autoai_libs/sklearn/fast_ordinal_encoder.py

```diff
@@ -97,22 +97,29 @@
         self.ordinalEncodingTables_ = {}
         for i in range(len(self.categories_)):
             tmpTable = {val: k for k, val in enumerate(self.categories_[i])}
             self.ordinalEncodingTables_[i] = tmpTable
 
         return self
 
-    def _transform(self, X, handle_unknown="error", force_all_finite=True):
+    def _transform(
+            self,
+            X,
+            handle_unknown="error",
+            force_all_finite=True,
+            warn_on_unknown=False,
+            ignore_category_indices=None,
+    ):
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         X_list, n_samples, n_features = self._check_X(X)
 
-        X_int = np.zeros((n_samples, n_features), dtype=np.int)
-        X_mask = np.ones((n_samples, n_features), dtype=np.bool)
+        X_int = np.zeros((n_samples, n_features), dtype=int)
+        X_mask = np.ones((n_samples, n_features), dtype=bool)
 
         if n_features != len(self.categories_):
             raise ValueError(
                 "The number of features in X is different to the number of "
                 "features of the fitted data. The fitted data had {} features "
                 "and the X has {} features.".format(
                     len(
```

## autoai_libs/transformers/exportable.py

```diff
@@ -3,48 +3,52 @@
 # OCO Source Materials
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2019-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
+import logging
+import warnings
 from time import time
+
 import numpy as np
 import sklearn
-import warnings
 from sklearn.base import BaseEstimator, TransformerMixin
-from sklearn.preprocessing import StandardScaler
 from sklearn.impute import SimpleImputer
+from sklearn.preprocessing import StandardScaler
 from sklearn.utils.validation import check_array
 
 from autoai_libs.utils.exportable_utils import (
-    numpy_replace_values,
-    numpy_permute_array,
-    numpy_floatstr2float,
-    setValueOrDefault,
-    numpy_boolean2float,
-    convert_float32,
-    numpy_whatis,
-    numpy_select_columns,
     compress_str_column,
+    convert_float32,
     global_missing_values_reference_list,
+    numpy_boolean2float,
+    numpy_floatstr2float,
+    numpy_permute_array,
+    numpy_replace_values,
+    numpy_select_columns,
+    numpy_whatis,
+    setValueOrDefault,
 )
 
 sklearn_version_list = sklearn.__version__.split(".")
 global_sklearn_version_family = sklearn_version_list[1]
 if sklearn_version_list[0] == "1":
     global_sklearn_version_family = sklearn_version_list[0]
 
 debug_transform_return = False
 debug = False
 debug_timings = False
 debug_catnum = False
 
 debug_date_transformer = False
 
+logger = logging.getLogger("autoai_libs")
+
 
 class ColumnSelector(BaseEstimator, TransformerMixin):
     """
     Selects a subset of columns for a given numpy array or subset of elements of a list
     """
 
     def __init__(self, columns_indices_list, activate_flag=True):
@@ -59,17 +63,17 @@
 
     def fit(self, X, y=None):
         assert X.ndim == 2
         self._check_n_features(X, reset=True)
 
         if debug:
             if isinstance(X, list):
-                print("ColumnSelector: Starting fit(" + str(len(X)) + "x" + str(1) + ")")
+                logger.debug("ColumnSelector: Starting fit(" + str(len(X)) + "x" + str(1) + ")")
             else:
-                print(
+                logger.debug(
                     "ColumnSelector: Starting fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")"
                 )
             if debug_timings:
@@ -79,36 +83,36 @@
             # do fit here
             a = 1
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
                 if isinstance(X, list):
-                    print(
+                    logger.debug(
                         "ColumnSelector: Ending fit("
                         + str(len(X))
                         + "x"
                         + str(1)
                         + "), elapsed_time (s): "
                         + str(elapsed_time)
                     )
                 else:
-                    print(
+                    logger.debug(
                         "ColumnSelector: Ending fit("
                         + str(X.shape[0])
                         + "x"
                         + str(X.reshape(X.shape[0], -1).shape[1])
                         + "), elapsed_time (s): "
                         + str(elapsed_time)
                     )
             else:
                 if isinstance(X, list):
-                    print("ColumnSelector: Ending fit(" + str(len(X)) + "x" + str(1) + ")")
+                    logger.debug("ColumnSelector: Ending fit(" + str(len(X)) + "x" + str(1) + ")")
                 else:
-                    print(
+                    logger.debug(
                         "ColumnSelector: Ending fit("
                         + str(X.shape[0])
                         + "x"
                         + str(X.reshape(X.shape[0], -1).shape[1])
                         + ")"
                     )
 
@@ -120,17 +124,17 @@
         )
 
         if hasattr(self, "n_features_in_") and self.activate_flag:
             self._check_n_features(X, reset=False)
 
         if debug:
             if isinstance(X, list):
-                print("ColumnSelector: Starting transform(" + str(len(X)) + "x" + str(1) + ")")
+                logger.debug("ColumnSelector: Starting transform(" + str(len(X)) + "x" + str(1) + ")")
             else:
-                print(
+                logger.debug(
                     "ColumnSelector: Starting transform("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")"
                 )
             if debug_timings:
@@ -142,45 +146,45 @@
             self.columns_selected_flag = False
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
                 if isinstance(X, list):
-                    print(
+                    logger.debug(
                         "ColumnSelector: Ending transform("
                         + str(len(X))
                         + "x"
                         + str(1)
                         + "), elapsed_time (s): "
                         + str(elapsed_time)
                     )
                 else:
-                    print(
+                    logger.debug(
                         "ColumnSelector: Ending transform("
                         + str(Y.shape[0])
                         + "x"
                         + str(Y.reshape(Y.shape[0], -1).shape[1])
                         + "), elapsed_time (s): "
                         + str(elapsed_time)
                     )
             else:
                 if isinstance(X, list):
-                    print("ColumnSelector: Ending transform(" + str(len(X)) + "x" + str(1) + ")")
+                    logger.debug("ColumnSelector: Ending transform(" + str(len(X)) + "x" + str(1) + ")")
                 else:
-                    print(
+                    logger.debug(
                         "ColumnSelector: Ending transform("
                         + str(Y.shape[0])
                         + "x"
                         + str(Y.reshape(Y.shape[0], -1).shape[1])
                         + ")"
                     )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class NumpyColumnSelector(BaseEstimator, TransformerMixin):
     """
     Selects a subset of columns of a numpy array
     """
@@ -201,15 +205,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "NumpyColumnSelector: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -220,32 +224,32 @@
             Y = X[:, self.columns]
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "NumpyColumnSelector: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "NumpyColumnSelector: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class NumpyApplyAlongAxis(BaseEstimator, TransformerMixin):
     """
     Transformer that applies a function to 1-D slices along the given axis on a subset of rows or columns
     """
@@ -274,15 +278,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "NumpyApplyAlongAxis: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
 
@@ -295,24 +299,24 @@
                     X_slice = X[self.index_list, :]
 
                 Y = np.apply_along_axis(self.func1d, self.axis, X_slice)
 
         else:
             Y = X
         if debug:
-            print(
+            logger.debug(
                 "NumpyApplyAlongAxis: Ending transform("
                 + str(Y.shape[0])
                 + "x"
                 + str(Y.reshape(Y.shape[0], -1).shape[1])
                 + ")"
             )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class NumpyReplaceMissingValues(BaseEstimator, TransformerMixin):
     """
     Given a numpy array and a reference list of missing values for it,
     replaces missing values with a special value (typically a special missing value such as np.nan).
@@ -344,15 +348,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "NumpyReplaceMissingValues: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -361,33 +365,33 @@
         Y = numpy_replace_values(
             X, filling_value=self.filling_values, reference_values_list=self.missing_values, invert_flag=False
         )
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "NumpyReplaceMissingValues: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "NumpyReplaceMissingValues: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class NumpyReplaceUnknownValues(BaseEstimator, TransformerMixin):
     """
     Given a numpy array and a reference list of known values for each column,
     replaces values that are not part of a reference list with a special value
@@ -442,15 +446,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "NumpyReplaceUnknownValues: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -459,34 +463,34 @@
         Y = numpy_replace_values(
             X, filling_value=self.filling_values, reference_values_list=self.known_values_list, invert_flag=True
         )
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "NumpyReplaceUnknownValues: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "NumpyReplaceUnknownValues: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                     + "\n"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class NumpyPermuteArray(BaseEstimator, TransformerMixin):
     """
     Rearranges columns or rows of a numpy array based on a list of indices
     """
@@ -516,49 +520,49 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "NumpyPermuteArray: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
                 start_time = time()
 
         Y = numpy_permute_array(X, self.permutation_indices, self.axis)
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "NumpyPermuteArray: Ending transform("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "NumpyPermuteArray: Ending transform("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")\n"
                 )
 
         Y = Y.reshape(Y.shape[0], -1)
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class OptStandardScaler(BaseEstimator, TransformerMixin):
     """
     This transformer implements an optional StandardScaler.
     It acts as a StandardScaler() if use_scaler_flag is True.
@@ -600,15 +604,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "OptStandardScaler: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -618,33 +622,33 @@
             Y = self.scaler.transform(X)
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "OptStandardScaler: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "OptStandardScaler: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class CatImputer(BaseEstimator, TransformerMixin):
     """
     This is a wrapper for categorical imputer
     """
@@ -665,47 +669,51 @@
         self.imputer = SimpleImputer(strategy=strategy, missing_values=missing_values)
 
     def fit(self, X, y=None):
         assert X.ndim == 2
         self._check_n_features(X, reset=True)
 
         if debug:
-            print("CatImputer: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")")
+            logger.debug(
+                "CatImputer: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
+            )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
             self.imputer.fit(X, y)
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "CatImputer: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print("CatImputer: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")")
+                logger.debug(
+                    "CatImputer: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
+                )
 
         return self
 
     def transform(self, X):
         check_array(
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "CatImputer: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -715,33 +723,33 @@
             Y = self.imputer.transform(X)
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "CatImputer: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "CatImputer: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class CatEncoder(BaseEstimator, TransformerMixin):
     """
     This is a template for classes
     """
@@ -790,48 +798,52 @@
             #     self.encoder = LabelEncoder()
 
     def fit(self, X, y=None):
         assert X.ndim == 2
         self._check_n_features(X, reset=True)
 
         if debug:
-            print("CatEncoder: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")")
+            logger.debug(
+                "CatEncoder: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
+            )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
             Y = self.encoder.fit(X, y)
             self.categories_found = self.encoder.categories_
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "CatEncoder: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print("CatEncoder: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")")
+                logger.debug(
+                    "CatEncoder: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
+                )
 
         return self
 
     def transform(self, X):
         check_array(
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "CatEncoder: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -859,33 +871,33 @@
                 self.encoder.handle_unknown = temp_handle_unknown
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "CatEncoder: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "CatEncoder: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 def is_all_missing(x, bad_vals):
     try:  # Handle bad_vals as atomic
         std_bad = [v for v in bad_vals if not np.isnan(v)]
     except:
@@ -894,15 +906,15 @@
 
     assert len(std_bad) + 1 >= len(bad_vals)
     test_nan = len(std_bad) < len(bad_vals)
     if not test_nan:
         return np.isin(x, std_bad).all()
     else:  # All nans or mixed
         it = (np.isnan(float(cell)) or np.isin(cell, std_bad) for cell in x)
-        return np.fromiter(it, np.float).all()
+        return np.fromiter(it, float).all()
 
 
 class NumImputer(BaseEstimator, TransformerMixin):
     """
     This is a wrapper for numerical imputer
     """
 
@@ -912,15 +924,17 @@
         self.activate_flag = activate_flag
         self.imputer = SimpleImputer(strategy=strategy, missing_values=missing_values)
 
     def fit(self, X, y=None):
         self._check_n_features(X, reset=True)
 
         if debug:
-            print("NumImputer: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")")
+            logger.debug(
+                "NumImputer: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
+            )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
             # We need to record which columns are made up of only missing values
             # if the strategy is not 'constant' since these columns will be DISCARDED
             # when we call transform afterwards.
@@ -929,48 +943,50 @@
                     [c for c in range(X.shape[1]) if is_all_missing(X[:, c], self.missing_values)]
                 )
             self.imputer.fit(X, y)
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "NumImputer: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print("NumImputer: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")")
+                logger.debug(
+                    "NumImputer: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
+                )
 
         return self
 
     def transform(self, X):
         check_array(
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "NumImputer: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
-            Y = X.astype(np.float)
+            Y = X.astype(float)
             Y = self.imputer.transform(Y)
             if self.strategy != "constant":
                 # Place a try here so that pipelines pickled before the
                 # introduction of self.bad_columns will still hopefully
                 # work even though they don't have a bad_columns field.
                 # Yes, this is ugly!
                 # TODO: Remove this try/except when we can!
@@ -981,68 +997,68 @@
                     pass
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "NumImputer: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "NumImputer: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         assert X.shape == Y.shape
         return Y
 
 
 class AllPassPreprocessingTransformer(BaseEstimator, TransformerMixin):
     def __init__(self):
         pass
 
     def fit(self, X, y=None):
         self._check_n_features(X, reset=True)
 
         if debug:
-            print(
+            logger.debug(
                 "AllPassPreprocessingTransformer: Starting fit("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
                 start_time = time()
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "AllPassPreprocessingTransformer: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "AllPassPreprocessingTransformer: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")"
                 )
 
@@ -1054,15 +1070,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "AllPassPreprocessingTransformer: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -1070,33 +1086,33 @@
 
         # Y = X.copy()
         Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "AllPassPreprocessingTransformer: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "AllPassPreprocessingTransformer: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class CompressStrings(BaseEstimator, TransformerMixin):
     """
     Removes spaces and special characters from string columns of a numpy array
     """
@@ -1127,37 +1143,37 @@
         else:
             self.missing_values_reference_list = missing_values_reference_list
 
     def fit(self, X, y=None):
         self._check_n_features(X, reset=True)
 
         if debug:
-            print(
+            logger.debug(
                 "CompressStrings: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
             )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
             # do fit here
             a = 1
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "CompressStrings: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "CompressStrings: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")"
                 )
 
@@ -1169,15 +1185,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "CompressStrings: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -1203,44 +1219,43 @@
                 # FIXME: reverted temporarily to old slow code that does not use cache.
                 execute_numpywhatis_flag = False
                 # FIXME: reverted temporarily to old slow code that does not use cache.
                 # bug comes in HOUSE_PRICING column 34, row 320
                 if execute_numpywhatis_flag:
                     misslist, dtype_str = numpy_whatis(Xcol, self.missing_values_reference_list)
                 else:
-                    # print("Using cached dtype and misslist")
                     dtype_str = self.dtypes_list[j]
                     misslist = self.misslist_list[j]
                 if dtype_str == "char_str":
                     Y[:, j] = compress_str_column(Xcol, misslist, self.compress_type)
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "CompressStrings: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "CompressStrings: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class FloatStr2Float(BaseEstimator, TransformerMixin):
     def __init__(self, dtypes_list, missing_values_reference_list=None, activate_flag=True):
         self.dtypes_list = dtypes_list
         self.missing_values_reference_list = setValueOrDefault(
@@ -1250,37 +1265,37 @@
         self.activate_flag = activate_flag
 
     def fit(self, X, y=None):
         assert X.ndim == 2
         self._check_n_features(X, reset=True)
 
         if debug:
-            print(
+            logger.debug(
                 "FloatStr2Float: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
             )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
             # do fit here
             a = 1
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "FloatStr2Float: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "FloatStr2Float: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")"
                 )
 
@@ -1291,15 +1306,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "FloatStr2Float: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -1319,33 +1334,33 @@
                     Y[:, j] = X[:, j].copy()
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "FloatStr2Float: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "FloatStr2Float: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class float32_transform(BaseEstimator, TransformerMixin):
     """
     Transforms a float64 numpy array to float32
     """
@@ -1353,15 +1368,15 @@
     def __init__(self, activate_flag=True):
         self.activate_flag = activate_flag
 
     def fit(self, X, y=None):
         self._check_n_features(X, reset=True)
 
         if debug:
-            print(
+            logger.debug(
                 "float32_transform: Starting fit("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -1370,24 +1385,24 @@
         if self.activate_flag:
             # do fit here
             a = 1
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "float32_transform: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "float32_transform: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + ")"
                 )
 
@@ -1399,15 +1414,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "float32_transform: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -1417,33 +1432,33 @@
             Y = convert_float32(X)
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "float32_transform: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "float32_transform: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
 
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
 
 
 class boolean2float(BaseEstimator, TransformerMixin):
     """
     This is a template for classes
     """
@@ -1451,37 +1466,37 @@
     def __init__(self, activate_flag=True):
         self.activate_flag = activate_flag
 
     def fit(self, X, y=None):
         self._check_n_features(X, reset=True)
 
         if debug:
-            print(
+            logger.debug(
                 "boolean2float: Starting fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
             )
             if debug_timings:
                 start_time = time()
 
         if self.activate_flag:
             # do fit here
             a = 1
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "boolean2float: Ending fit("
                     + str(X.shape[0])
                     + "x"
                     + str(X.reshape(X.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "boolean2float: Ending fit(" + str(X.shape[0]) + "x" + str(X.reshape(X.shape[0], -1).shape[1]) + ")"
                 )
 
         return self
 
     def transform(self, X):
         assert X.ndim == 2
@@ -1489,15 +1504,15 @@
             X, ensure_min_features=1, ensure_min_samples=1, dtype=None, force_all_finite="allow-nan", accept_sparse=True
         )
 
         if hasattr(self, "n_features_in_"):
             self._check_n_features(X, reset=False)
 
         if debug:
-            print(
+            logger.debug(
                 "boolean2float: Starting transform("
                 + str(X.shape[0])
                 + "x"
                 + str(X.reshape(X.shape[0], -1).shape[1])
                 + ")"
             )
             if debug_timings:
@@ -1510,26 +1525,26 @@
             a = 1
         else:
             Y = X
 
         if debug:
             if debug_timings:
                 elapsed_time = time() - start_time
-                print(
+                logger.debug(
                     "boolean2float: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + "), elapsed_time (s): "
                     + str(elapsed_time)
                 )
             else:
-                print(
+                logger.debug(
                     "boolean2float: Ending transform("
                     + str(Y.shape[0])
                     + "x"
                     + str(Y.reshape(Y.shape[0], -1).shape[1])
                     + ")"
                 )
         if debug_transform_return:
-            print(f"{self.__class__.__name__}.transform({X})->{Y}")
+            logger.debug(f"{self.__class__.__name__}.transform({X})->{Y}")
         return Y
```

## autoai_libs/transformers/small_data_column_transformer.py

```diff
@@ -3,37 +3,40 @@
 # OCO Source Materials
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2021-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 import abc
-import numpy as np
 import logging
 
+import numpy as np
+
 from .column_transformer import ColumnTransformer
 from .small_data_transformer import SmallDataTransformer
 
+logger = logging.getLogger("autoai_libs")
+
 
 class SmallDataColumnTransformer(ColumnTransformer, SmallDataTransformer):
     @abc.abstractmethod
     def __init__(self, func, *args, **kwargs):
         self.func = func
         super().__init__(*args, **kwargs)
 
     def is_colref_valid(self, X, column_ref):
         try:
             self.perform_transformation(X, column_ref)
             return True
         except Exception as e:
-            logging.error(
+            logger.warning(
                 "Error accessing column reference {0}, X has type: {1}, error='{2}'".format(
                     column_ref, type(X).__name__, e
                 ),
-                exc_info=True,
+                exc_info=e,
             )
             return False
 
     def perform_transformation(self, X, column_ref):
         if self.pass_x_and_col_ref_only:
             transformed = self.func(X, column_ref)
         else:
```

## autoai_libs/transformers/small_data_transformer.py

```diff
@@ -7,24 +7,26 @@
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 import numpy as np
 import logging
 
 from .general_transformer import AutoAITransformer
 
+logger = logging.getLogger("autoai_libs")
+
 
 class SmallDataTransformer(AutoAITransformer):
     def __init__(self):
         super().__init__()
 
     def is_valid(self, X: np.ndarray) -> bool:
         try:
             self.fit_transform(X)
             return True
         except Exception as e:
-            logging.error(
+            logger.warning(
                 "Transfomer {0}, error in fit_transform, type(X): {1}, error={2!s}".format(
                     self.__class__.__name__, type(X), e
                 ),
-                exc_info=True,
+                exc_info=e,
             )
             return False
```

## autoai_libs/transformers/date_time/date_time_utils.py

```diff
@@ -4,36 +4,39 @@
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2021-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 __all__ = ["apply_date_aggregations"]
 
-from typing import Tuple, List
+import logging
+from typing import List, Tuple
 
 import numpy as np
 
 from autoai_libs.transformers.date_time.small_time_transformers import (
+    DatetimeExtractTransformer,
+    DateToFloatTimestampTransformer,
+    DateToTimestampTransformer,
+    DayExtractTransformer,
     DayOfWeekExtractTransformer,
-    MinuteExtractTransformer,
-    SecondExtractTransformer,
-    YearExtractTransformer,
-    MonthExtractTransformer,
-    WeekExtractTransformer,
     DayOfYearExtractTransformer,
-    HourExtractTransformer,
-    DayExtractTransformer,
-    DateToTimestampTransformer,
-    DateToFloatTimestampTransformer,
-    TimestampExtractTransformer,
     FloatTimestampExtractTransformer,
-    DatetimeExtractTransformer,
     FloatTimestampExtractTransformer32,
+    HourExtractTransformer,
+    MinuteExtractTransformer,
+    MonthExtractTransformer,
+    SecondExtractTransformer,
+    TimestampExtractTransformer,
+    WeekExtractTransformer,
+    YearExtractTransformer,
 )
 
+logger = logging.getLogger("autoai_libs")
+
 
 def apply_date_aggregations(
     X: np.ndarray,
     date_column_indices: List[int],
     options: List[str],
     delete_source_columns: bool = True,
     column_headers_list: List[str] = None,
@@ -112,19 +115,19 @@
                 #     agg_counter=agg_counter-4
             else:  # Find the aggregations that are valid
                 agg_counter = 0
                 for elt in options:
                     if elt in supported_options:
                         agg_counter = agg_counter + 1
                     else:
-                        print("\n" + elt + ": Invalid aggregation")
+                        logger.warning("\n" + elt + ": Invalid aggregation")
                 if agg_counter == 0:
-                    print("\nValid date aggregations: \n")
-                    print(supported_options)
-                    print("\nNo valid date aggregations were found in options. No transforms are applied")
+                    logger.warning("Valid date aggregations:")
+                    logger.warning(supported_options)
+                    logger.warning("No valid date aggregations were found in options. No transforms are applied")
                     return X, column_headers_list_copy
         else:
             l_delete_source_columns = False
             agg_counter = -1  # agg_counter has no effect in this case
 
         supported_functions_dict = {}
         supported_functions_dict["Datetime"] = DatetimeExtractTransformer
```

## autoai_libs/transformers/date_time/small_time_transformers.py

```diff
@@ -32,15 +32,15 @@
 class DayOfYearExtractTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
         super().__init__(lambda x: pd.to_datetime(x).dayofyear, *args, **kwargs)
 
 
 class WeekExtractTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
-        super().__init__(lambda x: pd.to_datetime(x).week, *args, **kwargs)
+        super().__init__(lambda x: pd.to_datetime(x).isocalendar().week, *args, **kwargs)
 
 
 class MonthExtractTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
         super().__init__(lambda x: pd.to_datetime(x).month, *args, **kwargs)
 
 
@@ -74,30 +74,30 @@
             *args,
             **kwargs,
         )
 
 
 class DateToFloatTimestampTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
-        super().__init__(lambda x: (pd.to_datetime(x).values.astype(np.float)), *args, **kwargs)
+        super().__init__(lambda x: (pd.to_datetime(x).values.astype(float)), *args, **kwargs)
 
 
 class DateToTimestampTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
         super().__init__(lambda x: (pd.to_datetime(x).values.astype(np.int64)), *args, **kwargs)
 
 
 class TimestampExtractTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
         super().__init__(lambda x: (pd.to_datetime(x).asi8), *args, **kwargs)
 
 
 class FloatTimestampExtractTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
-        super().__init__(lambda x: (pd.to_datetime(x).asi8.astype(np.float)), *args, **kwargs)
+        super().__init__(lambda x: (pd.to_datetime(x).asi8.astype(float)), *args, **kwargs)
 
 
 class DatetimeExtractTransformer(SmallDataColumnTransformer):
     def __init__(self, *args, **kwargs):
         super().__init__(lambda x: (pd.to_datetime(x)), *args, **kwargs)
```

## autoai_libs/utils/data_utils.py

```diff
@@ -3,17 +3,21 @@
 # OCO Source Materials
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2020-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
-import numpy as np
+import logging
 import random
 
+import numpy as np
+
+logger = logging.getLogger("autoai_libs")
+
 
 class DataUtils:
     @staticmethod
     def NumericDataTypes():
         return [
             "intc",
             "intp",
@@ -88,16 +92,17 @@
     @staticmethod
     def all_feats_numeric(df):
         for col in df.columns:
             try:
                 if not df[col].dtype in DataUtils.NumericDataTypes():
                     return False
             except Exception as e:
-                print(df.columns)
-                print(df[col])
+                logger.error("", exc_info=e)
+                logger.debug(df.columns)
+                logger.debug(df[col])
                 raise e
         return True
 
     @staticmethod
     def get_unique_column_name(proposed_name, existing_name_list):
         while proposed_name in existing_name_list:
             proposed_name = proposed_name + "-" + str(random.randint(0, 9))
```

## autoai_libs/utils/exportable_utils.py

```diff
@@ -21,15 +21,15 @@
 import six
 
 import logging
 import hashlib
 
 global_missing_values_reference_list = ("?", "", "-", np.nan)
 
-logger = logging.getLogger()
+logger = logging.getLogger("autoai_libs")
 
 
 def numpy_select_columns(X, columns_indices_list):
     """
     Selects columns from numpy array (doesnt work with Pandas objects).
     """
     if columns_indices_list is not None and isinstance(columns_indices_list, list) and columns_indices_list:
@@ -256,16 +256,14 @@
             Y[i] = np.nan
         else:
             if not isfloat(X[i]):
                 try:
                     Y[i] = float(X[i])
                 except Exception as e:
                     Y[i] = np.nan
-                    # print(e)
-                    # print('Setting value ' + str(X[i]) + ' to NaN')
     # Convert type from object to float
     Z = Y.astype(float)
     return Z
 
 
 def setValueOrDefault(variable, def_value):
     if variable is None:
@@ -316,15 +314,14 @@
 def compress_str_column(X, misslist, compress_type="string"):
     """
     Compresses a column of strings to a column of strings without whitespaces or a column of int hashes
     :param Xcol:
     :param compress_type: 'string' or 'hash'
     :return: Compressed column
     """
-    # print('compress_str_column '+compress_type)
     if isinstance(X, list):
         Xcol = np.asarray(X)
     else:
         Xcol = X
 
     if Xcol.dtype.kind not in "OSUV":
         return Xcol  # Do not perform compression on data
@@ -355,15 +352,14 @@
 
     return Ycol
 
 
 def convert_float32(X, force_flag=False):
     if X.dtype == "float64" or force_flag:
         Y = X.astype("float32")
-        # Y=np.float32(X)
     else:  # this includes the case where X.dtype == 'float32'
         Y = X
 
     return Y
 
 
 def numpy_whatis(
@@ -382,15 +378,15 @@
 
     :param X: 1-d numpy array of floats, ints, or strings
     :param missing_values_reference_list: list containing the discovered missing values
     :return:
     """
     if debug:
         row_limit = min(X.shape[0], 50)
-        print("numpy_whatis(): Starting. Column: " + str(X[list(range(row_limit))]) + "\n\n")
+        logger.debug("numpy_whatis(): Starting. Column: " + str(X[list(range(row_limit))]) + "\n\n")
         start_time = time()
 
     X = numpy_flatten_column(X)
     if missing_values_reference_list is None:
         missing_values_list = []
     else:
         missing_values_list = missing_values_reference_list
@@ -488,15 +484,15 @@
     weird_new_missing_values_list3 = []
     start_missing_string_values_list3 = []
     dtype_str3_limit = 2
     dtype_str_found = "missing"  # initialize the value before checking the types
 
     if debug:
         dtype_start_time = time()
-        print("numpy_whatis():" + "Start finding dtype on" + str(XX.shape[0]) + " rows")
+        logger.debug("numpy_whatis():" + "Start finding dtype on" + str(XX.shape[0]) + " rows")
 
     for i in range(XX.shape[0]):
         elt = XX[i]
         # if elt not in missing_values_set: #missing_values_list:
         if isinstance(elt, six.string_types):  # this is a string
             if (
                 found_nonmissing_flag
@@ -533,15 +529,15 @@
                 found_string_flag = True
                 # a string in a float_str or int_str column can be treated as missing value
                 if found_float_str_flag or found_int_str_flag:
                     if elt not in start_missing_string_values_list:  # new_missing_values_list:
                         start_missing_string_values_list.append(elt)
 
         else:
-            if type(elt) is float or isinstance(elt, np.float):
+            if isinstance(elt, float):
                 if elt.is_integer():
                     dtype_str_found = "float_int_num"
                     found_nonmissing_flag = True
                     if dtype_str != "float_num":  # if I found at least one float_num stick to it
                         dtype_str = "float_int_num"
 
                 else:
@@ -585,15 +581,15 @@
             dtype_str3 == "float_str"
             and dtypes_cnt_dict[dtype_str3] > dtype_str3_limit
             and (dtypes_cnt_dict["missing"] > 0 or weird_new_missing_values_list3)
         ):  # found at least one missing value
             dtype_str3_stop_flag = True
 
     if debug:
-        print(
+        logger.debug(
             "numpy_whatis():"
             + "Ending finding dtype on"
             + str(XX.shape[0])
             + " rows"
             + "\nelapsed_time: numpy_isin_elapsed_end(s): "
             + str(time() - dtype_start_time)
         )
@@ -644,54 +640,54 @@
         )
     else:
         new_missing_values_list = missing_reference_values_exist_list + weird_new_missing_values_list
 
     check_limit = min(XX.shape[0], 50)
 
     if debug:
-        print("numpy_whatis():" + "Starting checking datetime property  on" + str(check_limit) + " rows")
+        logger.debug("numpy_whatis():" + "Starting checking datetime property  on" + str(check_limit) + " rows")
         datetime_start_time = time()
 
     datetime_column_flag = FCplus.is_column_string_in_datetime_format(XX[list(range(check_limit))]) and (
         dtype_str == "char_str" or dtype_str == "date_datetime"
     )
 
     if debug:
-        print(
+        logger.debug(
             "numpy_whatis():"
             + "Ending checking datetime property  on"
             + str(check_limit)
             + " rows"
             + "\nelapsed_time(s): "
             + str(time() - datetime_start_time)
         )
 
     check_limit = min(X_non_missing.shape[0], 50)
     if debug:
-        print("numpy_whatis():" + "Starting checking monotonic property  on " + str(check_limit) + " rows")
+        logger.debug("numpy_whatis():" + "Starting checking monotonic property  on " + str(check_limit) + " rows")
         monotonic_start_time = time()
 
     monotonic_column_flag = False
     if False:  # do not check monotonic property for the time being
         monotonic_column_flag = numpy_is_column_monotonic_increasing(
             X_non_missing[list(range(check_limit))]
         ) or numpy_is_column_monotonic_decreasing(X_non_missing[list(range(check_limit))])
 
     if debug:
-        print(
+        logger.debug(
             "numpy_whatis():"
             + "Ending checking monotonic property on "
             + str(check_limit)
             + " rows"
             + "\nelapsed_time(s): "
             + str(time() - monotonic_start_time)
         )
 
     if debug:
-        print("numpy_whatis():" + "Starting checking contiguous property  on " + str(check_limit) + " rows")
+        logger.debug("numpy_whatis():" + "Starting checking contiguous property  on " + str(check_limit) + " rows")
         contiguous_start_time = time()
 
     contiguous_column_flag = False
     if False:  # do not check contiguous property for the time being
         if dtype_str == "int_num" and unique_values_column_flag:
             # check if these integers are contiguous
             X_non_missing_sorted = np.sort(X_non_missing)
@@ -702,25 +698,25 @@
         # max_elt = np.max(X_non_missing)
         # min_elt = np.min(X_non_missing)
         # diff=max_elt-min_elt
         # if diff == X_non_missing.shape[0]-1: #this is a consecutive set of integers
         #     contiguous_column_flag=True
 
     if debug:
-        print(
+        logger.debug(
             "numpy_whatis():"
             + "Ending checking contiguous property on "
             + str(check_limit)
             + " rows"
             + "\nelapsed_time(s): "
             + str(time() - contiguous_start_time)
         )
 
     if debug:
-        print("numpy_whatis():Ending_" + "\nelapsed_time(s): " + str(time() - start_time))
+        logger.debug("numpy_whatis():Ending_" + "\nelapsed_time(s): " + str(time() - start_time))
 
     if return_stats_flag:
         stats_dict = {}
         stats_dict["dtype_str"] = dtype_str_final
         stats_dict["missing_values"] = new_missing_values_list
         stats_dict["unique_values"] = XX
         stats_dict["unique_values_counts"] = xx_xounts
@@ -828,33 +824,33 @@
 
 def numpy_compute_missing_indicator(X, missing_values_list, stop_at_one_missing_value_flag=False, debug=False):
     missing_masks_list = []
     missing_reference_values_exist_list = []
 
     if debug:
         row_limit = min(X.shape[0], 50)
-        print("numpy_compute_missing_indicator(): Column: " + str(X[list(range(row_limit))]) + "\n\n")
+        logger.debug("numpy_compute_missing_indicator(): Column: " + str(X[list(range(row_limit))]) + "\n\n")
 
     for i, missing_value in enumerate(missing_values_list):
         if debug:
             numpy_isin_start = time()
-            print("\n\nnumpy_compute_missing_indicator():Checking for missing_value=" + str(missing_value))
+            logger.debug("\n\nnumpy_compute_missing_indicator():Checking for missing_value=" + str(missing_value))
 
         missing_mask = numpy_isin(X, [missing_value])
 
         missing_value_found = False
         if np.any(missing_mask):
             missing_value_found = True
             missing_reference_values_exist_list.append(missing_value)
             missing_masks_list.append(missing_mask)
             if stop_at_one_missing_value_flag:
                 break
 
         if debug:
-            print(
+            logger.debug(
                 "numpy_compute_missing_indicator():"
                 + "missing_value="
                 + str(missing_value)
                 + " found: "
                 + str(missing_value_found)
                 + "\nelapsed_time: numpy_isin_elapsed_end(s): "
                 + str(time() - numpy_isin_start)
@@ -880,15 +876,15 @@
     :param X:
     :param values_reference_list:
     :return:
     """
 
     if debug:
         limit = min(X.shape[0], 50)
-        print("Starting numpy_isin(): Starting\n X column: " + str(X[list(range(limit))]) + "\n")
+        logger.debug("Starting numpy_isin(): Starting\n X column: " + str(X[list(range(limit))]) + "\n")
         start_time = time()
 
     l_X = numpy_flatten_column(X)
     l_values_reference_list = values_reference_list
 
     nan_missing_mask = pd.isnull(l_values_reference_list)
     if np.any(nan_missing_mask):  # if nan is in the values reference list
@@ -896,26 +892,26 @@
         if not non_nan_values_reference_list:  # nan was the only reference value
             result = pd.isnull(l_X)
         else:
             nan_cond = pd.isnull(l_X)
             set_non_nan_values_reference_list = set(non_nan_values_reference_list)
 
             if debug:
-                print(l_X[list(range(limit))])
-                print(set_non_nan_values_reference_list)
+                logger.debug(l_X[list(range(limit))])
+                logger.debug(set_non_nan_values_reference_list)
 
             non_nan_cond = indicator_mask(set_non_nan_values_reference_list, l_X)
             result = nan_cond | non_nan_cond
     else:
         set_reference_values_list_col = set(l_values_reference_list)
         result = indicator_mask(set_reference_values_list_col, l_X)
 
     if debug:
         np_isin_time = time()
-        print("Ending numpy_isin(): Ending, elapsed time (s)" + str(np_isin_time - start_time))
+        logger.debug("Ending numpy_isin(): Ending, elapsed time (s)" + str(np_isin_time - start_time))
 
     return result
 
 
 def indicator_mask(reference_set: set, l):
     is_in_reference = np.vectorize(lambda value: value in reference_set, otypes=[bool])
     return is_in_reference(l)
@@ -1010,17 +1006,17 @@
         Y = X
         for i in range(X.shape[0]):
             elt = Y[i]
             if not isinstance(elt, str):
                 if pd.isnull(elt):
                     elt_i = "?"
                 else:
-                    if isinstance(elt, np.float):
+                    if isinstance(elt, float):
                         if elt.is_integer():
-                            elt_i = str(np.int(elt))
+                            elt_i = str(int(elt))
                         else:
                             elt_i = str(elt)
                     else:
                         elt_i = str(elt)
                 Y[i] = elt_i
     return Y
 
@@ -1075,18 +1071,18 @@
         return result
 
     @staticmethod
     def is_num_column_categorical(dfc, uni_max=100, uni_ratio=0.1):
         try:
             uni = np.unique(dfc)
         except Exception as e:
-            print("exception " + str(e))
-            print(type(dfc))
-            print(dfc)
-            print(dfc.isnull().any())
+            logger.error("exception ", exc_info=e)
+            logger.debug(type(dfc))
+            logger.debug(dfc)
+            logger.debug(dfc.isnull().any())
             raise e
         r = float(len(uni)) / float(len(dfc))
         return (len(uni) < uni_max and r < uni_ratio) or len(uni) == 2 or (len(uni) < 5) and len(dfc) < 30
 
     @staticmethod
     def is_column_categorical(y: np.ndarray, missing_values_reference_list=None) -> bool:
         # if isinstance(y, (list, pd.core.series.Series, np.ndarray, pd.DataFrame)):
@@ -1441,22 +1437,22 @@
         return flag
 
     @staticmethod
     def is_column_positive(dfc) -> bool:
         if isinstance(dfc.values[0, 0], str):
             return False
 
-        return FC.is_positive(dfc).bool()
+        return FC.is_positive(dfc)
 
     @staticmethod
     def is_column_non_negative(dfc):
         if isinstance(dfc.values[0, 0], str):
             return False
 
-        return FC.is_non_negative(dfc).bool()
+        return FC.is_non_negative(dfc)
 
     @staticmethod
     def is_column_not_all_non_negative(dfc):
         if isinstance(dfc.values[0, 0], str):
             return False
 
         return FC.is_not_all_non_negative(dfc)
```

## autoai_libs/utils/fc_methods.py

```diff
@@ -4,54 +4,60 @@
 # 5737-H76, 5725-W78, 5900-A1R, 5737-L65
 # (c) Copyright IBM Corp. 2020-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 
 
-from autoai_libs.utils.data_utils import DataUtils
+import logging
+
 import numpy as np
 import pandas as pd
 
+from autoai_libs.utils.data_utils import DataUtils
+
+logger = logging.getLogger("autoai_libs")
+
 
 def is_positive(dfc):
     return np.min(dfc) > 0
 
 
 def is_non_negative(dfc):
     return np.min(dfc) >= 0
 
 
 def is_not_all_non_negative(dfc):
-    return not is_non_negative(dfc).bool()
+    return not is_non_negative(dfc)
 
 
 def is_categorical(dfc):
     try:
         uni = np.unique(dfc)
     except Exception as e:
-        print("exception " + str(e))
-        print(type(dfc))
-        print(dfc)
-        print(dfc.isnull().any())
+        logger.error("exception ", exc_info=e)
+
+        logger.debug(type(dfc))
+        logger.debug(dfc)
+        logger.debug(dfc.isnull().any())
         raise e
     # return dfc.dtype in DataUtils.IntDataTypes() and len(uni) < 20 and len(uni)/len(dfc) < 0.1
     # return len(uni) < 20 and len(uni)/len(dfc) < 0.1
     r = float(len(uni)) / float(len(dfc))
     return (len(uni) < 20 and r < 0.1) or len(uni) == 2
 
 
 def is_lt80pc_unique_int(dfc):
     try:
         uni = np.unique(dfc)
     except Exception as e:
-        print("exception " + str(e))
-        print(type(dfc))
-        print(dfc)
-        print(dfc.isnull().any())
+        logger.error("exception ", exc_info=e)
+        logger.debug(type(dfc))
+        logger.debug(dfc)
+        logger.debug(dfc.isnull().any())
         raise e
     # return dfc.dtype in DataUtils.IntDataTypes() and len(uni) < 20 and len(uni)/len(dfc) < 0.1
     # return len(uni) < 20 and len(uni)/len(dfc) < 0.1
     r = float(len(uni)) / float(len(dfc))
     return r < 0.8
```

## autoai_libs/utils/holdout_utils.py

```diff
@@ -264,15 +264,15 @@
     if not (isinstance(y, pd.DataFrame) or isinstance(y, np.ndarray) or isinstance(y, pd.Series)):
         raise ValueError(f"y is not of type: pd.DataFrame or np.array. y type: {type(y)}")
 
     if ref_values is None or not list(ref_values):
         return []
 
     if output_type == "int":
-        ref_values_indicator = np.zeros(y.shape[0], dtype=np.int)
+        ref_values_indicator = np.zeros(y.shape[0], dtype=int)
         ref_values_indicator[np.isin(y, ref_values, invert=output_non_reference_indicator_flag)] = 1
 
     elif output_type == "bool":
         ref_values_indicator = np.isin(y, ref_values, invert=output_non_reference_indicator_flag)
 
     else:
         ref_values_indicator = np.where(np.isin(y, ref_values, invert=output_non_reference_indicator_flag))[0]
```

## autoai_libs/utils/parameter_types.py

```diff
@@ -5,14 +5,17 @@
 # (c) Copyright IBM Corp. 2021-2024. All Rights Reserved.
 # The source code for this program is not published or otherwise divested of its trade secrets,
 # irrespective of what has been deposited with the U.S. Copyright Office.
 ################################################################################
 from autoai_libs.utils.intiger_ranges import uniform_integers
 
 from scipy.stats import uniform
+import logging
+
+logger = logging.getLogger("autoai_libs")
 
 
 class Parameter:
     def __init__(self, name=None):
         self.type = None
         self.name = name
         self.vmin = None
@@ -219,15 +222,16 @@
             if len(self.list) > 0:
                 alist = []
                 try:
                     for el in sorted(self.list):
                         if el != self.default:
                             alist.append(el)
                 except Exception as e:
-                    print("handled exception " + str(e))
+                    logger.warning("handled exception ", exc_info=e)
+
                 alist.append(self.default)
                 self.list = alist
                 self.vmax = int(len(alist) - 1)
 
     def add(self, value):
         # FIXME this is a hack to remove spurious empty strings, leaving no way to have an intentionally empty string
         if value == "":
```

## autoai_libs/utils/sampling_utils.py

```diff
@@ -57,15 +57,15 @@
     """
     num_rows = X.shape[0]
     indices = np.arange(num_rows)
 
     # Note: check if 'test_size' parameter is correct, it should be between 0 and 1 (float)
     # or between 0 and max num of 'X' rows (int)
     if test_size is not None:
-        if isinstance(test_size, float) or isinstance(test_size, np.float):
+        if isinstance(test_size, float):
             if not (0 < test_size < 1):
                 raise ValueError(
                     f"Parameter 'test_size' is of type: {type(test_size)}."
                     f"It should be between 0 and 1. Its current value is: {test_size}"
                 )
 
         if isinstance(test_size, int) or isinstance(test_size, np.integer) or isinstance(test_size, numbers.Integral):
```

## Comparing `autoai_libs-1.17.2.dist-info/METADATA` & `autoai_libs-2.0.0.dist-info/METADATA`

 * *Files 23% similar despite different names*

```diff
@@ -1,31 +1,31 @@
 Metadata-Version: 2.1
 Name: autoai-libs
-Version: 1.17.2
+Version: 2.0.0
 Summary: A library of transformers to support portable representations of AutoAI pipelines
 Author: IBM
 Author-email: Lukasz Cmielowski <lukasz.cmielowski@pl.ibm.com>, Daniel Ryszka <daniel.ryszka@pl.ibm.com>
 Maintainer-email: Ulvi Movsum-Zada <ulvi.movsumzada@ibm.com>, Jakub Walaszczyk <jakub.walaszczyk@ibm.com>
 License: See: https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYY6S5
 Project-URL: homepage, https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-lib-python.html
 Keywords: AI,Watson,IBM,AutoAI,SDK,API,IBM Cloud,Machine Learning
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Operating System :: MacOS :: MacOS X
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: POSIX :: Linux
 Classifier: Intended Audience :: Science/Research
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Information Technology
 Classifier: License :: Other/Proprietary License
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
-Requires-Python: <3.11,>=3.10
+Requires-Python: <3.12,>=3.11
 Description-Content-Type: text/markdown
 License-File: licenses\LA_cs
 License-File: licenses\LA_de
 License-File: licenses\LA_el
 License-File: licenses\LA_en
 License-File: licenses\LA_es
 License-File: licenses\LA_fr
@@ -55,41 +55,27 @@
 License-File: licenses\LI_pl
 License-File: licenses\LI_pt
 License-File: licenses\LI_ru
 License-File: licenses\LI_sl
 License-File: licenses\LI_tr
 License-File: licenses\LI_zh
 License-File: licenses\LI_zh_TW
-Requires-Dist: gensim (==4.1.2)
-Requires-Dist: importlib-metadata
-Requires-Dist: numpy (<1.24,>=1.20.3)
-Requires-Dist: lale (<0.8,>=0.6.11)
-Requires-Dist: packaging
-Requires-Dist: pandas (<1.6,>=0.24.2)
-Requires-Dist: parameterized (==0.8.1)
-Requires-Dist: psutil
-Requires-Dist: scikit-learn (<1.2,>=1.0.2)
-Requires-Dist: smart-open (<7.0.0)
+Requires-Dist: gensim (==4.3.*)
+Requires-Dist: numpy (==1.26.*)
+Requires-Dist: lale (==0.8.0)
+Requires-Dist: pandas (==2.1.*)
+Requires-Dist: scikit-learn (==1.3.*)
 Provides-Extra: code-check
-Requires-Dist: black (>=24.1) ; extra == 'code-check'
+Requires-Dist: black ; extra == 'code-check'
 Provides-Extra: dev
 Requires-Dist: autoai-libs[test] ; extra == 'dev'
 Requires-Dist: autoai-libs[code-check] ; extra == 'dev'
 Provides-Extra: test
-Requires-Dist: coverage ; extra == 'test'
-Requires-Dist: ibm-watson-machine-learning ; extra == 'test'
-Requires-Dist: pyarrow ; extra == 'test'
 Requires-Dist: pytest ; extra == 'test'
-Requires-Dist: pytest-cov ; extra == 'test'
-Requires-Dist: typing-extensions ; extra == 'test'
-Requires-Dist: urllib3 (<2) ; extra == 'test'
-Requires-Dist: xgboost (>=1.6.1) ; extra == 'test'
-Provides-Extra: xgboost-wrapper
-Requires-Dist: xgboost (>=1.6.1) ; extra == 'xgboost-wrapper'
-Requires-Dist: typing-extensions ; extra == 'xgboost-wrapper'
+Requires-Dist: xgboost (==2.0.*) ; extra == 'test'
 
 # autoai_libs
 
 A library of transformers to support portable representations of AutoAI pipelines.
 
 ## Documentation
```

## Comparing `autoai_libs-1.17.2.dist-info/RECORD` & `autoai_libs-2.0.0.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,136 +1,136 @@
-autoai_libs/__init__.py,sha256=JcC3FNW5HQag7roEYQ79IzgH-xTML8W1q5VqF4nfOb4,528
-autoai_libs/version.cp310-win_amd64.pyd,sha256=8WhaWNM9iRKGjGoI4YW0RoXP9MSLk8EBM94ewc99lbI,17408
-autoai_libs/version.py,sha256=dVCuYEaAlsmp4plEOXKJXu6Jf1lRotU8B79ER73JTF0,507
+autoai_libs/__init__.py,sha256=s9rtUg47zQqsa2RGh1oYUHfps00NUi3VpeInTmLDlvo,800
+autoai_libs/version.cp311-win_amd64.pyd,sha256=0uvIU3NCJnYu4qjnfJBlR9hFSAnQaUCwdxowQ1XHk2A,16896
+autoai_libs/version.py,sha256=y_7TEq3oNSOBk5EFbTfdmg7fu37ECBQL2ahebvK774o,506
 autoai_libs/cognito/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
 autoai_libs/cognito/transforms/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/cognito/transforms/sklearn_compat.cp310-win_amd64.pyd,sha256=hHm4d-7IFImDtErJeOsg3DynktHq1a_EtI_Q7l4s4iE,70656
-autoai_libs/cognito/transforms/sklearn_compat.py,sha256=S-n769yQy2kq3P2t5PdTh37E8UNfCy0IrYNhxys8ZlA,4611
-autoai_libs/cognito/transforms/textras_methods.cp310-win_amd64.pyd,sha256=JcOnOINU1Dlcrv0mBIvoOX4Wm0H_p0pG_ld6B5QHLts,43008
+autoai_libs/cognito/transforms/sklearn_compat.cp311-win_amd64.pyd,sha256=VFxtw8xeZioQl4HikDktlGOd11dO7_ErRBSGJlAMZbw,72192
+autoai_libs/cognito/transforms/sklearn_compat.py,sha256=2Pc7qJ4-5hWaFlS6b-bE3k4XvzF-g6qJhzOm8_647bs,4559
+autoai_libs/cognito/transforms/textras_methods.cp311-win_amd64.pyd,sha256=mZP6qZb4sz8wjxJUAgBSGLUG-T_zg_cxSUHHazLz-9U,43520
 autoai_libs/cognito/transforms/textras_methods.py,sha256=t5RXlF1du7u4_FKTv68Vh_zgtyixyvaqm8ydVz6kllA,1417
-autoai_libs/cognito/transforms/transform_extras.cp310-win_amd64.pyd,sha256=O_Iqh9dHyTc9kpi9LtwJRkxTdMTyM_VTy6o_b2UzObw,154112
-autoai_libs/cognito/transforms/transform_extras.py,sha256=maogb0q-wzAVHYgcfdEJHYfN0i59KkUCCWclxg5JjlA,16913
-autoai_libs/cognito/transforms/transform_utils.cp310-win_amd64.pyd,sha256=2T4EcgdEAowxXOnnGJrKN_HAX8lduur6DO6TcwkbMrU,606208
-autoai_libs/cognito/transforms/transform_utils.py,sha256=6nCBvc0KYI3HCAGVIY0QhksCCqXmNQxwTs5Cg6iulhA,88079
+autoai_libs/cognito/transforms/transform_extras.cp311-win_amd64.pyd,sha256=chnsHl3MNoR7ynssnk9sRVdUqG0OGOZQFMJAgPbCi_w,154624
+autoai_libs/cognito/transforms/transform_extras.py,sha256=ElN7fh83Epxw2WCrLxylty2Oeefvfb4nIP2iND8_LE0,16838
+autoai_libs/cognito/transforms/transform_utils.cp311-win_amd64.pyd,sha256=vWQHNiOydJwVx629o4y-PVCueSjaz9cmmYgZlkUi-GQ,622592
+autoai_libs/cognito/transforms/transform_utils.py,sha256=m4C3WLdFNNBVjtIafpTpX2gUSX0f5ZeBapXpGHsj00M,88058
 autoai_libs/detectors/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/detectors/general_detector.cp310-win_amd64.pyd,sha256=I4V2ipSvl1CbyxEro24zyw4WXwQ66RdIveprXSj7MS0,30208
+autoai_libs/detectors/general_detector.cp311-win_amd64.pyd,sha256=9e_FMwi2d6FOH6uGWy9QLlotYLnx8uX59wojPeS79PY,31232
 autoai_libs/detectors/general_detector.py,sha256=v4hLI12iVaql98ImR4TGHW80p32hUl-Zsj4KPPM_aaE,760
-autoai_libs/detectors/small_data_detector.cp310-win_amd64.pyd,sha256=uJpKyNzNANwzQ29Engp-Q52ZvIj_YUEPcrH1QiTvwEs,31232
-autoai_libs/detectors/small_data_detector.py,sha256=QrPWXOLMEnT-_auEZ0nbpQCeDNOBTx39GG_ff2X7-go,833
+autoai_libs/detectors/small_data_detector.cp311-win_amd64.pyd,sha256=SPrZUhGvuPPpyxKJZpABzH5AI7OIiWCMV8d75N7BLfo,33280
+autoai_libs/detectors/small_data_detector.py,sha256=He4S1QUWZX8F8KJ0eA-Uk4GwyV2IglJAeNFeUIvZkFE,891
 autoai_libs/detectors/date_time/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/detectors/date_time/date_time_detector.cp310-win_amd64.pyd,sha256=WOLyR9IG9YiYFy-C3zk_Y5ds4cWwaCBWYvQ95Ia4kGU,51712
-autoai_libs/detectors/date_time/date_time_detector.py,sha256=Il91cKooKmaN7YteyRknNr47jLvJ8ppETfH27LxmTlQ,3276
+autoai_libs/detectors/date_time/date_time_detector.cp311-win_amd64.pyd,sha256=_ct9SVIh1BXzLuvf-LUbfrUprd74SkkhM6EbERlsjiY,53248
+autoai_libs/detectors/date_time/date_time_detector.py,sha256=DPQjtra1fYs8QcVLgQj7OCa9tOjGmCU2ipToAv8pcHo,3321
 autoai_libs/estimators/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/estimators/xgboost.cp310-win_amd64.pyd,sha256=lXsxcTM104FmICpXMtJzoFnJ94M_l1nnieqXdgKxMiE,41472
-autoai_libs/estimators/xgboost.py,sha256=HdPF5CKtItRExTkLPU7GeWJUIk1kAbgyMilt8WkDY9A,2133
+autoai_libs/estimators/xgboost.cp311-win_amd64.pyd,sha256=sN1W0MYp5V1XE-eMXWNCbcyAgnNZav0zMri1VWnZhxI,41984
+autoai_libs/estimators/xgboost.py,sha256=qqCKozCRfmjme5lW6A9Eyh1jXkIstJMMQGe8q-1HTdU,2174
 autoai_libs/lale/__init__.py,sha256=vsUXwywGx-DhICgoLe9Pj1pnoJte1e9U6H1xvjK66P0,5059
-autoai_libs/lale/_common_schemas.cp310-win_amd64.pyd,sha256=WU89xdqtucKiazCnd9jYK8hV6NDCQeo1N8AW1PzcBtQ,49664
+autoai_libs/lale/_common_schemas.cp311-win_amd64.pyd,sha256=LZcqICCxNxnsnkGzI7OeaSX8yXrPD9QzSC82JxZI8xM,49664
 autoai_libs/lale/_common_schemas.py,sha256=scWhmBDlMEgk5NyyjeeX1_hyw5Q-R-Me9PpvnyRobQQ,6420
-autoai_libs/lale/boolean2float.cp310-win_amd64.pyd,sha256=pqNfl9fLHJBbvXSVau1N7Od8ct1ZF38A0i4XsE1EsIg,49664
+autoai_libs/lale/boolean2float.cp311-win_amd64.pyd,sha256=xGohwJxD_l5JdV1bNYFf8Dlgk1asiZrzJGr5OD4t9nw,50688
 autoai_libs/lale/boolean2float.py,sha256=-uInYQwG-RuZ8OpCeSXe2ZEIfu5yXlePV1MGGXPgcwM,4319
-autoai_libs/lale/cat_encoder.cp310-win_amd64.pyd,sha256=zKxGMc0ulFXI8B-1AuTtlSGkaqoQ-pLeWZPW957gdt4,65024
+autoai_libs/lale/cat_encoder.cp311-win_amd64.pyd,sha256=YSYh_8438trgLbf0hlZ-mI_xcX6brV8gI51d5C037NM,65024
 autoai_libs/lale/cat_encoder.py,sha256=dhYbenbGDldGXq3DHwT8BE-UriuGN8etnTvg63K_eN4,9362
-autoai_libs/lale/cat_imputer.cp310-win_amd64.pyd,sha256=OA2tNPJKsnlMOZqWLUMJWk6qUVgtcHmKizgH94XPg5Q,67072
-autoai_libs/lale/cat_imputer.py,sha256=NVJQxh46oUkByPl1FqU58curKbGHOfKkjZyMDhwAKGI,8745
-autoai_libs/lale/column_selector.cp310-win_amd64.pyd,sha256=ceLB95BBkkhW3KG5CsqP7-UzQDfnLGbNfnRnzGyc_Ik,46592
+autoai_libs/lale/cat_imputer.cp311-win_amd64.pyd,sha256=_qdAQB3KQSi9nEwcdXlV8IMcvTRoeNwZkaJ2GeYMj4Q,67072
+autoai_libs/lale/cat_imputer.py,sha256=APAp4TiccfmM8BCvMlw-kxPKrKdLXWcDDpxHCpit38o,8706
+autoai_libs/lale/column_selector.cp311-win_amd64.pyd,sha256=QspiTqp32BpRSDiaAgJBh7eMkN4GH8MeRxtDWtrSwNE,48128
 autoai_libs/lale/column_selector.py,sha256=2Qrrk5_R_I6OC6cV5vyvYe2ys3sNVXGbIkPeCwGUQqA,4009
-autoai_libs/lale/compress_strings.cp310-win_amd64.pyd,sha256=XNebdVS0E-0CSOhWrziFYiVruLPI0ONuJ-0hJfT3YfY,47616
+autoai_libs/lale/compress_strings.cp311-win_amd64.pyd,sha256=R7z183ON2bzIwgFegSflZdjzFZJNFaFJmuqZAJy9MWs,48128
 autoai_libs/lale/compress_strings.py,sha256=3mc48zZexEdZlprIsHGQb_M9h7okHyMlO2HCBKg-7pc,5593
-autoai_libs/lale/date_transformer.cp310-win_amd64.pyd,sha256=U9VUHHv5qEuRFJ5jhsFAaPNh3SY6MpeVQ20GW9qRTCQ,50688
+autoai_libs/lale/date_transformer.cp311-win_amd64.pyd,sha256=-hhVdlRdKGI5NdtNRyN3Bc66dnGqiUoNtaIAtcNkqqU,51712
 autoai_libs/lale/date_transformer.py,sha256=VyuzZWmSa9WBud7qfS2hradfs9iioXwi9ekihw6bkMM,6559
-autoai_libs/lale/float32_transform.cp310-win_amd64.pyd,sha256=Dm10P0EXGd9EqlQSMJPgBUic7wUZyrdGnn9W-HmNa-k,49664
+autoai_libs/lale/float32_transform.cp311-win_amd64.pyd,sha256=J7Mi3LQSQCFKFTLfMELrIwcIhcCuwfzP4oyeIgMFb_w,51200
 autoai_libs/lale/float32_transform.py,sha256=dBWNiwrzes6n9HlGJFPTmOmGAmeuKihGSzwHjxvN9hI,4286
-autoai_libs/lale/float_str2_float.cp310-win_amd64.pyd,sha256=FdZ111so4SfSG-cs5dATqmG6BLbf4IHJzGQyPX6UYz4,45568
+autoai_libs/lale/float_str2_float.cp311-win_amd64.pyd,sha256=Mvr-iYAjKVFwggbzpXPhQJeBMiXclHm1TAYMs-WdLDs,47104
 autoai_libs/lale/float_str2_float.py,sha256=H60FkvcNUjYAEFovue-bnbmm1d2kH1BaD24AUXU_Nwg,4508
-autoai_libs/lale/fs1.cp310-win_amd64.pyd,sha256=KPl61JtOfDp-Avi3B2K19_SBSIf79P1GMVUoIJZfEjM,55296
+autoai_libs/lale/fs1.cp311-win_amd64.pyd,sha256=G1ZnFeqQ97-L1Vw0XyM3EfjxSW6zD_F6HZDPxhXumu4,55296
 autoai_libs/lale/fs1.py,sha256=xodlg4MAfBXKXZRsZ1ayNdFNM94FV6l0xZnNkwhpEA8,4651
-autoai_libs/lale/fs2.cp310-win_amd64.pyd,sha256=SPVOxSrZ_QVF5w_UrITX0LHU0pKamasMTMpvEK60AyU,54784
+autoai_libs/lale/fs2.cp311-win_amd64.pyd,sha256=7yVwhsbo5nN65bmoYwxVPrzMClxjbn9l-bsYPTzwwI8,54784
 autoai_libs/lale/fs2.py,sha256=xYw9SQVMqnL4vZYlKF0I-Z9Ih274E2FmtLybkP2tCrQ,4797
-autoai_libs/lale/nsfa.cp310-win_amd64.pyd,sha256=z1pi2XZu1sLnR8eqN7Grp_T22Tz0ziBGm_unea7GvXU,44544
+autoai_libs/lale/nsfa.cp311-win_amd64.pyd,sha256=COXeykFCwkhcq38kkWZWzIbQEk4W3xUdF1nEaxSNOzk,45568
 autoai_libs/lale/nsfa.py,sha256=VjSaXGSkUEP2aZ--h7c3tTXgE_g29VsbjEriHLm3PGY,4043
-autoai_libs/lale/num_imputer.cp310-win_amd64.pyd,sha256=hgHPOLovJVmHwoA8GMboVbSJTIMK5paE3-alu4by_6c,69120
-autoai_libs/lale/num_imputer.py,sha256=6c8ppO5FgaSQUTsQQZdPE81iNlNwzPgBm7u3nrCjuTM,8435
-autoai_libs/lale/numpy_column_selector.cp310-win_amd64.pyd,sha256=Vc3MKCR5HOqcAdjBrqhqmPYtMkFKJxIyWLzb8afZLZQ,46080
+autoai_libs/lale/num_imputer.cp311-win_amd64.pyd,sha256=Oef-TMHJC1ObEYZDhgmsc08jpYfr1nptSEdUEckBqgE,69120
+autoai_libs/lale/num_imputer.py,sha256=bAr71ecbOJsarnOfhyTJvEIDNNC9fZ1qyrdJA_Nj2VA,8396
+autoai_libs/lale/numpy_column_selector.cp311-win_amd64.pyd,sha256=VRzHSSZUXdQaLl-G09rOxo2VDjxnyifIFGMgk4dPDzg,47104
 autoai_libs/lale/numpy_column_selector.py,sha256=Vg3nA01U1tuGD90sx7z2vbKmeSDLsCHdTGSopXydHiI,3807
-autoai_libs/lale/numpy_permute_array.cp310-win_amd64.pyd,sha256=Cyqp3OncAGv91DaZPGsl3rjJ077hAAAJy44S-rRsFWE,45568
+autoai_libs/lale/numpy_permute_array.cp311-win_amd64.pyd,sha256=3horbGi4I40i41Xov4otUW6JbUiAc7fXm1qPClmmOvg,46080
 autoai_libs/lale/numpy_permute_array.py,sha256=E-FPInbnIVleaV0DHlMIzJFYgT0Zf4V5o52wWI_zxtI,4054
-autoai_libs/lale/numpy_replace_missing_values.cp310-win_amd64.pyd,sha256=OgMNTBkcrfJc_XcP1gPw8MaXpSpKUsckNrPWF5xEb4c,45056
+autoai_libs/lale/numpy_replace_missing_values.cp311-win_amd64.pyd,sha256=F0GXFlr6Z4rmx4hk7trHqXJQfw07uEd6OoxEf1ltmjI,45056
 autoai_libs/lale/numpy_replace_missing_values.py,sha256=HZ35ShCeldxNJnUwONn53vZ_u7fbE_HrmvO9ChWLeYg,4303
-autoai_libs/lale/numpy_replace_unknown_values.cp310-win_amd64.pyd,sha256=OaVts1cyPhn5ErG1d3JH0kdGB1Fitlu_xZSlt64fVJY,47104
+autoai_libs/lale/numpy_replace_unknown_values.cp311-win_amd64.pyd,sha256=FHCpMdNj-bpBGi4De6VIFvvhs-VXJW4uy46xCYW-GNw,47616
 autoai_libs/lale/numpy_replace_unknown_values.py,sha256=Q0boV7asGet0rPQ04pmJ5u2xnkFtygT-UV2CcAsHcOs,5290
-autoai_libs/lale/opt_standard_scaler.cp310-win_amd64.pyd,sha256=LpMD_jFctfFNH_ASRp3xc0fuLHn2EUzSL8sLpwHmlVU,46080
+autoai_libs/lale/opt_standard_scaler.cp311-win_amd64.pyd,sha256=1WG_T6S2x6j1fdOm60o8dk2CvpC8fqFPCs_HPIHtHPM,47104
 autoai_libs/lale/opt_standard_scaler.py,sha256=avObAmJxjxAFBqS76eMZhaqc0EJFM0hawg6iODoubM4,4898
-autoai_libs/lale/t_no_op.cp310-win_amd64.pyd,sha256=JPPH8afm7lK7a2MRvjLDmoMSFFd_zWE6BThkbw7vGgE,45056
+autoai_libs/lale/t_no_op.cp311-win_amd64.pyd,sha256=jEQkaqsX8XgINaf9pZrBLLH095JcDQySN_Zi0UsYRTI,46080
 autoai_libs/lale/t_no_op.py,sha256=GWrgIgRIELDtB7bCZdPIpHdG-nCOGp9UlScdpyyc9lg,3887
-autoai_libs/lale/ta1.cp310-win_amd64.pyd,sha256=fkk5HMGd-Nt7MmVDug6qLWErFpkj3EaDyFDCuPUaIso,60928
+autoai_libs/lale/ta1.cp311-win_amd64.pyd,sha256=FsnuPNHGc9Ujt5qIHxwJOnG2xeRryAaej9VUPGrmFFU,61440
 autoai_libs/lale/ta1.py,sha256=HBqR8Ozjc05jBMP63CrKlCE7HTOSvGW2PAfS9m9Jk9Q,6329
-autoai_libs/lale/ta2.cp310-win_amd64.pyd,sha256=Sg3kaS2jxP4VrFegqbxqV4KF6e75jLbgj5z9c1F616E,49152
+autoai_libs/lale/ta2.cp311-win_amd64.pyd,sha256=oqB-atnd7jQcf1sO1OLdH5_KHEHGL5dJ9r2fxY391Aw,49664
 autoai_libs/lale/ta2.py,sha256=mcpNnUvjHGFt2fCr8vyumq4c1FZkEwQI1Vo0-2xFU94,4933
-autoai_libs/lale/tam.cp310-win_amd64.pyd,sha256=T05vrXZkN1fxH0d-GBtwjG_BZ2XSDW6UfczR-2gCKRs,46080
+autoai_libs/lale/tam.cp311-win_amd64.pyd,sha256=1a0Ii8BmjcQWGcUJAjbAPs47q4Um1u3ndKzP09jeMbk,46592
 autoai_libs/lale/tam.py,sha256=q1wAne2jq41qlkiBTkqeuZBQCxPDS4yg9DIwgeVo5lo,3781
-autoai_libs/lale/tb1.cp310-win_amd64.pyd,sha256=xmKOmJSoRJtZRZMuivCG2FdAkF5yCoCDDExq2hptosw,48128
+autoai_libs/lale/tb1.cp311-win_amd64.pyd,sha256=QdqhuheFqQ3YpmYLS9UAvwoznlVmTcmKkYq5-P-ysU8,48640
 autoai_libs/lale/tb1.py,sha256=PIlkV2vOcvN_Oq9U-Q6mouH7iIGBzg-bQxtBMSfRMoY,4365
-autoai_libs/lale/tb2.cp310-win_amd64.pyd,sha256=k4U8p5meAt2Z7_vMNezNNrTW8etVNcRUeMO13MiF66I,49664
+autoai_libs/lale/tb2.cp311-win_amd64.pyd,sha256=8Vasj3j6DJueUkTC2eojVjDp9j0_EWWRrP8CjvnSROw,50688
 autoai_libs/lale/tb2.py,sha256=kt958ZiBvw3Bs8V8ZblBDcUytvuDNIrwpoFPKRfxXw4,5090
-autoai_libs/lale/text_transformer.cp310-win_amd64.pyd,sha256=A9DvOsie5yQTNQ4LEksN4p_8gcb93njpbTikxAkpfNU,47616
+autoai_libs/lale/text_transformer.cp311-win_amd64.pyd,sha256=cP6L9Ww0m3vkqYNzmWT_SX7GCta5X_a-NCRxq10DQp8,49152
 autoai_libs/lale/text_transformer.py,sha256=QQYMFeluijk8yc32oHpYdjb_KD6CcCnUnyU7zeWGGb0,5630
-autoai_libs/lale/tgen.cp310-win_amd64.pyd,sha256=VMMv1D-iPQMJE_9ZmnN8pn1OSjJXj2T_BmJDfFipfSs,52224
+autoai_libs/lale/tgen.cp311-win_amd64.pyd,sha256=CAilGRSvKHGd989QqHhpdjPpFDwO3u47U6RC1HyxcvE,53248
 autoai_libs/lale/tgen.py,sha256=J3OQ89cI5--0rvVJ8fDdcn7T8F-at_-WiygCbOwbwtk,6156
-autoai_libs/lale/util.cp310-win_amd64.pyd,sha256=v9Wif3VZuBklngbg10NBw2WCjFTC-2HvMV4qJHZg-1o,34304
+autoai_libs/lale/util.cp311-win_amd64.pyd,sha256=HWoJMIAjBSbFftlBJUsdLLD9qewEq7rpytpVAr7IcR4,35840
 autoai_libs/lale/util.py,sha256=mjsFQ1lRHDnWwHX4NtDIPKGQhx-oDJKnpE7aUdPcdBc,1964
-autoai_libs/lale/word2vec_transformer.cp310-win_amd64.pyd,sha256=L6YshmsCr4w4emt4QUA4LmI7rDQy4g29zZbQo63OErI,49152
+autoai_libs/lale/word2vec_transformer.cp311-win_amd64.pyd,sha256=407ibRUxb2lctvY36Me7xBSaULfodEm2Ek8XJVLIbNg,50688
 autoai_libs/lale/word2vec_transformer.py,sha256=kGDTiV1knCliYd6tDjP-EY7YcE9aCKMnVqgDdwzaDpY,6285
-autoai_libs/lale/xgboost.cp310-win_amd64.pyd,sha256=zJsHaXKbLJkaCA2TNNS9_NBlfQGjf0ubVZQDdP8Gegw,55296
-autoai_libs/lale/xgboost.py,sha256=j-wfucGN0h2oN0FBt87aip4ds84OXIeSsP1EPw8u0v0,3423
+autoai_libs/lale/xgboost.cp311-win_amd64.pyd,sha256=zENWLinrLcU7zamiw5-2RKgF36GnrSKOQDyYIrLPexs,52736
+autoai_libs/lale/xgboost.py,sha256=98Fjg-SJupJSLvGCWKjBcinoLGrgRv5U3DMgjCpe0aE,3312
 autoai_libs/mixins/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/mixins/optimization.cp310-win_amd64.pyd,sha256=BfzHBU0u5OdxMD-udO6IQWa10h4G2IGpqih1FzUbV1g,40448
+autoai_libs/mixins/optimization.cp311-win_amd64.pyd,sha256=rPQnp-bwvzXkW_FCM_4yY4fFKlN4Wn0FNwlXtliH8f4,40960
 autoai_libs/mixins/optimization.py,sha256=rUTnd1iFE9dIhqaSOfx22PYfU9UY4rN0dIMMxxspxhE,2455
 autoai_libs/scorers/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/scorers/scorers.cp310-win_amd64.pyd,sha256=v1HmW5R4yfhPSYlN2qlZAclyJ4QtDldFTtQO1auF6-U,32768
+autoai_libs/scorers/scorers.cp311-win_amd64.pyd,sha256=P5eEDx4NxmS8nMLbvrnl5R0bDkzrxY9JTdF8RJGBj48,34304
 autoai_libs/scorers/scorers.py,sha256=ryvWUdWgJKs8WzBEPTM1WGMo6cf9PB8CVQrrnFWts-I,853
 autoai_libs/sklearn/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/sklearn/custom_scorers.cp310-win_amd64.pyd,sha256=VUUnY0cD7kXSqLWR3VBAd8k0udw-2ZgrPCan4SY9J_w,52736
-autoai_libs/sklearn/custom_scorers.py,sha256=rF8d7BXqG9meEjhaVPjrkYRYSdrFaUjX2wWz_Lkdh0E,2984
-autoai_libs/sklearn/fast_ordinal_encoder.cp310-win_amd64.pyd,sha256=Xf3U8se0RMmAJvhkNrtaWOMBk0YvLHuXhqmJGotJa1s,79360
-autoai_libs/sklearn/fast_ordinal_encoder.py,sha256=1nkGNTYR8BbXi_bXjLU4hzW9rr8Pdp7qbUyd04n96Ew,6260
+autoai_libs/sklearn/custom_scorers.cp311-win_amd64.pyd,sha256=SomNBV_Fiy9J5ykoXzVti8YGYYriTtfXfZ_9Kjt1jv0,54272
+autoai_libs/sklearn/custom_scorers.py,sha256=rhTHYYWhaajCCiL3CT1-hvm-1gkdGqMOE9O2X3aDS9I,2981
+autoai_libs/sklearn/fast_ordinal_encoder.cp311-win_amd64.pyd,sha256=IaehMRTInfl1n0OmrHseroF6njVahS3VuFUbgxqez5s,78848
+autoai_libs/sklearn/fast_ordinal_encoder.py,sha256=fbulFEECC5dLaYixvK3r6Cp8DrNXBrtOHf-ZAWxHRu0,6393
 autoai_libs/transformers/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/transformers/column_transformer.cp310-win_amd64.pyd,sha256=aHvQDiQnBcrqEghgPpk8tEguRr-s7UAxo_VuWSkZxys,52736
+autoai_libs/transformers/column_transformer.cp311-win_amd64.pyd,sha256=V--smWD1KWsIJKZHOpuTYf_1IDv0yJXbd4yNecXrzFw,53248
 autoai_libs/transformers/column_transformer.py,sha256=r5-O8O-uTVsA-T29F9xFT3o3v8OcyODd3fSjv_y1yWs,2780
-autoai_libs/transformers/exportable.cp310-win_amd64.pyd,sha256=o-buCSFqP_dBZlwFJ5nbB2m5FyfBGlm-ZYR0-eIVM8E,371712
-autoai_libs/transformers/exportable.py,sha256=WBtKPmgzA7oLUmAlaXpoBMTUhAMfOn0SebgAPRTyifs,51909
-autoai_libs/transformers/general_transformer.cp310-win_amd64.pyd,sha256=bug3pu5PJ4cSTtBrOw43eRVn_YvD7gFh9Vd3T2w_hm4,35840
+autoai_libs/transformers/exportable.cp311-win_amd64.pyd,sha256=3axnov9FemTl31S1KvpbnKdLLI-C8GLzo8Rd-QK5KBQ,424960
+autoai_libs/transformers/exportable.py,sha256=O3Mr8QpZCX1TFcoMWihcxhymK2GJkZHEj9de7-tljjo,52762
+autoai_libs/transformers/general_transformer.cp311-win_amd64.pyd,sha256=HGGgUuP5eN77pU_1DnQXQSPMwJydgomaqxgFdfAy1ak,35840
 autoai_libs/transformers/general_transformer.py,sha256=35Rvl-CZIXwBXr_JiybO_Ut-ol88PO312wTuVkiLkQo,1197
-autoai_libs/transformers/small_data_column_transformer.cp310-win_amd64.pyd,sha256=ieS-X1hjAupegwdiNCra626XyzXs2inlkshH3o55X8E,52224
-autoai_libs/transformers/small_data_column_transformer.py,sha256=atpwaiaulwNujAfwqwuJwoTm1isjpJKW67ydP-44y4s,2224
-autoai_libs/transformers/small_data_transformer.cp310-win_amd64.pyd,sha256=ylFVyCfODPMB2z-rVKjcNsU8IMftXE5BpvPx_LKOLeA,37376
-autoai_libs/transformers/small_data_transformer.py,sha256=AeitZflHRqZk-T7zpqWz8EKL8oVV-tdxwlJD0IYF2ec,1103
-autoai_libs/transformers/text_transformers.cp310-win_amd64.pyd,sha256=5x_m_c8YbmqqH9U6sboE9Go19GiyqeaLIkJTbX1SwNg,179200
+autoai_libs/transformers/small_data_column_transformer.cp311-win_amd64.pyd,sha256=O5D4DzEOD55VDkQS7gz8Vos8XbHitlmUbyggA1MoxFY,52224
+autoai_libs/transformers/small_data_column_transformer.py,sha256=P41p6C7s18-rgHlIkabz5ChwtfNpL05e_CdA5xTz3ns,2269
+autoai_libs/transformers/small_data_transformer.cp311-win_amd64.pyd,sha256=aT97iSMYMGboQhQNbbhFC7r64GzyeBXHBZmtOGeKvFI,36864
+autoai_libs/transformers/small_data_transformer.py,sha256=C6my709OAvYRTNlz_x_QdDjD74AIPRowH9PPU60Rjk4,1146
+autoai_libs/transformers/text_transformers.cp311-win_amd64.pyd,sha256=FEtQqqXe4Ok6e6pRjpxt6voxmh2RucNm2yg3XuViLUU,179712
 autoai_libs/transformers/text_transformers.py,sha256=X2xZVYBUi6X-UigHXlMToMNJaKmfRKtzXV1I4hjW9uE,21595
 autoai_libs/transformers/date_time/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/transformers/date_time/date_time_transformer.cp310-win_amd64.pyd,sha256=n20xkAxkP2h_-AqaS0jaaIJt9eN3KGND8kHqJFBqU4A,60416
+autoai_libs/transformers/date_time/date_time_transformer.cp311-win_amd64.pyd,sha256=bym3DBkhvbBbYieId3sHOzClmUvSnOzSVlLvq_qiIS8,61440
 autoai_libs/transformers/date_time/date_time_transformer.py,sha256=to0z8xqvsZcpQdfz-SRnf7yTH6neCWaLLC2inreDbHE,7574
-autoai_libs/transformers/date_time/date_time_utils.cp310-win_amd64.pyd,sha256=75WR0za5K9Q74iXrntsRAOAasSZxSmkkDIYMZ2x-vcY,56832
-autoai_libs/transformers/date_time/date_time_utils.py,sha256=FrgYOWkG0XflHiFHbpa_4mLpwaKQHivVbRFzcSiLquM,7096
-autoai_libs/transformers/date_time/small_time_transformers.cp310-win_amd64.pyd,sha256=Age-GSXnO4kphqCSFn482eu55luTeSZdcsmc8Duw000,95744
-autoai_libs/transformers/date_time/small_time_transformers.py,sha256=oWjqOQ76p2am3tWuB0vGg8_1NoZfnPG3VebT67gg0wM,4329
+autoai_libs/transformers/date_time/date_time_utils.cp311-win_amd64.pyd,sha256=Yj2XLmz3gMksXR-KJzQtntObOKdmlYZ-_H-do6cbI6E,60928
+autoai_libs/transformers/date_time/date_time_utils.py,sha256=_WpFJCCBOFVNhCtTkuphcU1W5mNDBsbiX1dzwFI1EmI,7186
+autoai_libs/transformers/date_time/small_time_transformers.cp311-win_amd64.pyd,sha256=B81fjUIw2SJlLvDw2uwgbgz8gd4Y0P3Q5iwQkn-H7JU,96768
+autoai_libs/transformers/date_time/small_time_transformers.py,sha256=JEW6RyEmLJpG7gXuw1QiL5fHXoS8GgRPe_yCE09sq9U,4337
 autoai_libs/utils/__init__.py,sha256=iOftjqyiH_hbmNHHN_OnZ8eiJc0oMd6YCcfnBS0y4nw,481
-autoai_libs/utils/data_utils.cp310-win_amd64.pyd,sha256=zNo1dQhwSQnPXNZYatXIklJDaJsdSqokVn4GfPSIO8w,51712
-autoai_libs/utils/data_utils.py,sha256=aWPClYiKtYh7daLKy1UipLKowXpiR7gww1xhy4CktZs,3014
-autoai_libs/utils/exportable_utils.cp310-win_amd64.pyd,sha256=xL2aN_7DOagjOMa-tCVsBsvX5d_QeuFC0lN_zlNYH5k,336384
-autoai_libs/utils/exportable_utils.py,sha256=k8v8pM8mrw0hj5zyBfXQcGA6WTF6Cgz5BT0uJ0-7EI8,60077
-autoai_libs/utils/fc_methods.cp310-win_amd64.pyd,sha256=UqP0JxzbZZtiAQ3WpqPV5c4I1KzKuDCuO76682ztsjM,67072
-autoai_libs/utils/fc_methods.py,sha256=Ge3a4PWC4zwf0nzvFOt19_j_vkLhjf-zqZyk3XbJVh0,3880
-autoai_libs/utils/holdout_utils.cp310-win_amd64.pyd,sha256=wzdQ8haJB8z_-hfTEWUq7skDUGqKKUI6yCePT08FMvc,111616
-autoai_libs/utils/holdout_utils.py,sha256=9R0xA4VUyyuGogsuYCKSjrMvBgQo1C01QavE8XtsTx0,15540
-autoai_libs/utils/intiger_ranges.cp310-win_amd64.pyd,sha256=0hnkBJvMXZ44-QLCufpqUpj8JtcI-gV8EKQ0EYAj5iY,29696
+autoai_libs/utils/data_utils.cp311-win_amd64.pyd,sha256=c64RhMs7OnImlUgAMAfd2RcrP_dd8qkrFSnx27IPxh0,54272
+autoai_libs/utils/data_utils.py,sha256=nGKgspvKVHc8n2upf2LqP1MciysNS0-8o-IxmnqUvz8,3137
+autoai_libs/utils/exportable_utils.cp311-win_amd64.pyd,sha256=8cqZkz-DYfDBTboEhN5UyKup6xMBnJpHoxo22kWpod0,341504
+autoai_libs/utils/exportable_utils.py,sha256=ZAyK5y9LBFXR-w8g5MRyD97vzTkmhcp3gv55s3QfcF0,60014
+autoai_libs/utils/fc_methods.cp311-win_amd64.pyd,sha256=5Xd8-qxI1lWzh4xpwzH8hKXyIlwBGjbFCV1rIv5Krjk,70144
+autoai_libs/utils/fc_methods.py,sha256=XJKpxl208GCKkIPfVI8P-1i454q2ddAfaXeSoVhRZgI,4002
+autoai_libs/utils/holdout_utils.cp311-win_amd64.pyd,sha256=5FIkPTHjPkqWiroxkuVH_69CpPJ9yBVMYTuT-3PRPTQ,111616
+autoai_libs/utils/holdout_utils.py,sha256=IJeK9DPLzh7aot3RWArMKkBCstSdSMFiBsa3--fTwQc,15537
+autoai_libs/utils/intiger_ranges.cp311-win_amd64.pyd,sha256=9CG28rCIpNVx1wr-nqDSBjjl8B2AznLCM20EWBpuCkg,30208
 autoai_libs/utils/intiger_ranges.py,sha256=kMzaAxc2b8_XU2acI3Obx7v3064AwcUvVkaL1ANnD1w,1094
-autoai_libs/utils/outliers_mitigation.cp310-win_amd64.pyd,sha256=y0GwWgdmMHc02XZslDfD5QeTMyA4NtRH2wRtj8vlZhQ,56320
+autoai_libs/utils/outliers_mitigation.cp311-win_amd64.pyd,sha256=oUntDqoVn3omCAHkGUxZ7DI3kn5_dEFxzxY0S4xZI80,57344
 autoai_libs/utils/outliers_mitigation.py,sha256=M1192P97IoB02UyvqnxLwsudFKsDg6gpEKdNAley5Ik,4849
-autoai_libs/utils/parameter_types.cp310-win_amd64.pyd,sha256=KYtmUGvDftY2h2jGmxVL57vWP2f4Fb3xuW0uclg7qy8,113664
-autoai_libs/utils/parameter_types.py,sha256=_DEASYFzCkAn6DzGdyRC3wKLaL3Ga3IVePOPhawmmWA,9642
-autoai_libs/utils/sampling_utils.cp310-win_amd64.pyd,sha256=Scjs2mjn1lRhaJwJfCGo1C3egagH4UKOocvhddppUd8,60416
-autoai_libs/utils/sampling_utils.py,sha256=0GjQaksS-ijlCn2QgXZ3_GF2LK8J4S7BrXnKbhyGLgM,5911
-autoai_libs-1.17.2.dist-info/LICENSE.txt,sha256=eveRdh-AGYP_pNXAZ6RhyBTNtAAtcDyyhnIWr0MKXpo,82
-autoai_libs-1.17.2.dist-info/METADATA,sha256=9uZ1Ampw_ssmvBUWoTNDvML8sgLhTQN5aCKkEZ8JlcA,4051
-autoai_libs-1.17.2.dist-info/WHEEL,sha256=DeC8giwgiyugiqTA49TdhK5TDiCztXAFCYpvQvCcKIE,113
-autoai_libs-1.17.2.dist-info/top_level.txt,sha256=1PNCYB-_xvPvkAnKm-_kFt11uzb546Tdyu2vv2ktgig,12
-autoai_libs-1.17.2.dist-info/RECORD,,
+autoai_libs/utils/parameter_types.cp311-win_amd64.pyd,sha256=iz4YdepwOjVw6XXFjxoMLoMrVQ4vU8NhJXfNtKpxOSs,113152
+autoai_libs/utils/parameter_types.py,sha256=o5WLy42fyvrzAjI1k1xevJjcdhHKgdHAfzXbX4TFNRo,9717
+autoai_libs/utils/sampling_utils.cp311-win_amd64.pyd,sha256=7bFEZQlTsIW0pAjNxd1jAPyrMjLpMuStsDQt0sZxVQA,59904
+autoai_libs/utils/sampling_utils.py,sha256=91f74dckKfg26IskH0dLoNXVvh9at9DTvk-U37e-2pA,5876
+autoai_libs-2.0.0.dist-info/LICENSE.txt,sha256=eveRdh-AGYP_pNXAZ6RhyBTNtAAtcDyyhnIWr0MKXpo,82
+autoai_libs-2.0.0.dist-info/METADATA,sha256=H5baGqnKhrs_537pbL_B2ZqwvJN1EY6NxPiD1FcxrTY,3422
+autoai_libs-2.0.0.dist-info/WHEEL,sha256=-PnLe-anGV5wQjvE4mZqitUFFS2vS9nwfuYKPUWhZ80,113
+autoai_libs-2.0.0.dist-info/top_level.txt,sha256=1PNCYB-_xvPvkAnKm-_kFt11uzb546Tdyu2vv2ktgig,12
+autoai_libs-2.0.0.dist-info/RECORD,,
```

